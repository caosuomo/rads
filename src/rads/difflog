diff --git a/.gitignore b/.gitignore
index a53488c..a9eec43 100644
--- a/.gitignore
+++ b/.gitignore
@@ -41,4 +41,3 @@ build
 
 # mac crap
 .DS_store
-Icon*
diff --git "a/Icon\r" "b/Icon\r"
new file mode 100644
index 0000000..e69de29
diff --git a/README b/README
index c21fd41..1f919af 100644
--- a/README
+++ b/README
@@ -3,5 +3,4 @@ To build:
 1. Copy a suitable config_*.py file to config.py
 2. Edit entries of config.py to match your system
 3. Run makeit in the base directory
-4. Compiled files should now appear in build/lib
-
+4. Compiled files should now appear in build/lib
\ No newline at end of file
diff --git a/__init__.py b/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/config_jjb.py b/config_jjb.py
index 4709c06..3a92309 100644
--- a/config_jjb.py
+++ b/config_jjb.py
@@ -3,12 +3,12 @@ exe = {
 	'cython': 'cython --cplus'.split(), 
 	'c++': 'g++',
 	'c': 'gcc',
-       }
+	}
 
 # CAPD include and lib directories are loaded unsing the capd-config script
 dirs = {
 	'base': '/Users/jberwald/github/local/caja-matematica/rads/',
-	'capd_config': '/Users/jberwald/src/capd/bin/capd-config ', # used with Popen call along with `--cflags --libs`'
+	'capd_config': '/Users/jberwald/src/capd/bin/capd-config ', #--cflags --libs`'
 	'capd':  '/Users/jberwald/src/capd/'
         }
 
diff --git a/config_raf.py b/config_raf.py
index 187046e..95b7bfa 100644
--- a/config_raf.py
+++ b/config_raf.py
@@ -1,47 +1,32 @@
 
 exe = {
-	'cython': 'cython --cplus'.split(),	  # raf: was just 'cython'
+	'cython': 'cython',
 	'c++': 'g++',
-	'c': 'gcc'
+	'c': 'gcc',
 }
 
-# CAPD include and lib directories are loaded unsing the capd-config script
 dirs = {
 	'base': '/home/raf/projects/rads/',
-# used with Popen call along with `--cflags --libs`'
-	'capd_config': '/home/raf/projects/capd/bin/capd-config ',
-	'capd':  '/home/raf/projects/capd/'
+	'profil': '/home/raf/projects/rads/Profil-2.0.8/',
 }
 
 include = {
 	'sage': '/usr/local/share/sage-4.2-linux-ubuntu9.10-i686-Linux/devel/sage-main/',
 	'sage c': '/usr/local/share/sage-4.2-linux-ubuntu9.10-i686-Linux/devel/sage-main/c_lib/include/',
+	'profil': dirs['profil']+'include/',
 	'python': '/usr/include/python2.7',
-	'cython': '/usr/lib/pymodules/python2.7/Cython/Includes/',
-	'numpy': '/usr/lib/python2.7/dist-packages/numpy/core/include/',
-	'capd': '/home/raf/projects/capd/capdAlg/include/'
+	'cython': '/usr/local/lib/python2.7/dist-packages/Cython/Includes/',
+	'numpy': '/usr/local/lib/python2.7/dist-packages/numpy/core/include/',
 }
 
-
 link = {
-	'capd': dirs['capd'],
-	'c++ cython': '-lpython2.7'.split(),
-	'c++': '-lpython2.7'.split()
+	'profil': dirs['profil']+'lib/',
+	'c++ cython': '-lProfil -llr -lBias -o'.split(),
+	'c++': '-lProfil -llr -lBias -o'.split(),
 }
 
- 
 flags = {
 	'c': '-pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC'.split(),
 	'c++ cython': '-pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions'.split(),
 	'c++': '',
 }
-
-
-# From Jesse's
-# flags = {
-# 	'c': '-fno-strict-aliasing -fno-common -arch x86_64 -DNDEBUG -O1'.split(),
-# 	 'c++ cython': '-arch x86_64 -bundle -undefined dynamic_lookup'.split()
-#         }
-
-
-
diff --git a/makeit_jjb b/makeit_jjb
index bbda476..0377ca7 100755
--- a/makeit_jjb
+++ b/makeit_jjb
@@ -16,15 +16,12 @@
 from fabricate import *
 from subprocess import Popen, PIPE, STDOUT
 import sys, os, stat, commands
-import config_jjb as config    ## <<------------- Here goes your personalized config_* file!
+import config_jjb as config
 from shutil import copy2,copytree, ignore_patterns
 ### EXAMPLE: copytree(source, destination, ignore=ignore_patterns('*.pyc', 'tmp*'))
 
-
-################################################
-## Setup paths, includes, libs and other deps
-################################################
-
+# We might have to find the OS for the proper extension. There is no
+# Windows option.
 extension = '.so'
 
 dependencies = { # dependencies for cython (or c++!) files
@@ -99,7 +96,6 @@ p_libs = Popen( config.dirs['capd']+'/bin/capd-config --libs',
 capd_flags = p_flags.stdout.read().split()
 capd_libs = p_libs.stdout.read().split()
 
-## For debugging purposes
 print "capd_flags"
 print capd_flags
 print ""
@@ -108,14 +104,12 @@ print capd_libs
 print ""
 
 # now split the output, cython does not like D__USE_FILIB flag
-# Using all of these is overkill, but I'm not going to parse the output for the few that we need.
 capd_flags = [ i for i in capd_flags ]
-capd_flags.append( '-I/Users/jberwald/src/capd/capdAlg/include/capd/intervals' )
-capd_libs = capd_libs
+#capd_links = capd_libs[-1]
+capd_libs = capd_libs #[ i for i in capd_libs ]#.append( capd_libs[:-2][:] )
+
+					 #sys.exit(0)
 
-##################################
-## End setup, begin build funcs
-##################################
 
 def compile_cpp(inputs,output):
 	print "g++ compiling inputs: ", inputs
@@ -245,7 +239,7 @@ def build_map(sourcepath):
 	cpp_o = cpp_object_dir+filename+'_cpp_mapfile.o'
 	compile_cython(sourcepath+'.pyx', cython_cpp)
 	print ""
-	print "done with cython map files, compiling c++..."
+	print "done with cython files, compiling c++..."
 	print ""
 	compile_cpp(cython_cpp, cython_o)
 	compile_cpp(sourcepath+'_cpp.cpp', cpp_o)
diff --git a/makeit_jjb.py b/makeit_jjb.py
deleted file mode 100755
index bbda476..0000000
--- a/makeit_jjb.py
+++ /dev/null
@@ -1,314 +0,0 @@
-#!/usr/bin/python
-
-######################################################################
-#
-# makeit -- build RADS
-#
-# Right now, the directory structure is relatively flat:
-# 
-# src/
-# src/rads -- all cython and python files
-# src/rads/maps -- where the maps go
-# src/cpp -- all c++ files
-#
-######################################################################
-
-from fabricate import *
-from subprocess import Popen, PIPE, STDOUT
-import sys, os, stat, commands
-import config_jjb as config    ## <<------------- Here goes your personalized config_* file!
-from shutil import copy2,copytree, ignore_patterns
-### EXAMPLE: copytree(source, destination, ignore=ignore_patterns('*.pyc', 'tmp*'))
-
-
-################################################
-## Setup paths, includes, libs and other deps
-################################################
-
-extension = '.so'
-
-dependencies = { # dependencies for cython (or c++!) files
-	'cyboxset': ['box','boxset'],
-	'cytree': ['tree','box','boxset','treedata'],
-	'cyutils': ['box'],
-	'cymapper': ['mapper','box','boxset'],
-	'cycombenc': ['tree','treedata','mapper','box','boxset'],
-	'treetest': ['tree','treedata','box','boxset'],
-	'debugtree': ['tree','treedata','box','boxset'],
-}
-
-cpp_progs = ['treetest','debugtree'] # c++ programs
-
-tmp_dir = 'build/tmp/'
-lib_dir = 'build/lib/'
-map_dir = 'src/rads/maps'
-cpp_source_dir = 'src/cpp/' # look for c++ files here (in the current dir)
-cpp_object_dir = tmp_dir+'cpp/' # compile them to object files here
-
-				
-def list_dirs(path):
-	"""Returns a list of all top-level subdirectories in directory 'path'"""
-	return [ name for name in os.listdir(path)
-			 if os.path.isdir(os.path.join(path, name)) ]
-
-def copydirs(src, dst, ext=''):
-	"""
-	Recursively copies all files with extension 'ext' from src to dst,
-	creating the directories in dst as necessary.
-	"""
-	names = os.listdir(src)
-	try:
-		os.makedirs(dst)
-	except OSError:
-		pass
-	errors = []
-	for name in names:
-		srcname = os.path.join(src, name)
-		dstname = os.path.join(dst, name)
-		try:
-			if os.path.isdir(srcname):	# directory: recurse
-				copydirs(srcname, dstname, ext)
-			elif name.endswith(ext):	# file.ext: copy
-				print srcname, '-->', dstname
-				copy2(srcname, dstname)
-		except (IOError, os.error) as why:
-			errors.append((srcname, dstname, str(why)))
-		# catch the Error from the recursive copydirs so that we can
-		# continue with other files
-		except Exception as err:
-			errors.extend(err.args[0])
-	if errors:
-		raise Exception(errors)	
-
-# top-level directories in rads
-rads_dirs = ['src/rads/'+d for d in list_dirs('src/rads')+['','../cpp/']]
-# all include directories!
-# removed config.include['capd'] from list, since this should be handled by capd-config
-includes = [config.include['cython']+'libc/',
-	    config.include['cython']+'libcpp/',
-	    config.include['numpy'],
-	    config.include['python']] + rads_dirs
-	    #	    config.include['capd']] + rads_dirs
-
-# grab CAPD cflags and lib paths
-p_flags = Popen( config.dirs['capd']+'/bin/capd-config --cflags',
-		 shell=True, stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)
-p_libs = Popen( config.dirs['capd']+'/bin/capd-config --libs',
-		shell=True, stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)
-
-capd_flags = p_flags.stdout.read().split()
-capd_libs = p_libs.stdout.read().split()
-
-## For debugging purposes
-print "capd_flags"
-print capd_flags
-print ""
-print "capd_libs"
-print capd_libs
-print ""
-
-# now split the output, cython does not like D__USE_FILIB flag
-# Using all of these is overkill, but I'm not going to parse the output for the few that we need.
-capd_flags = [ i for i in capd_flags ]
-capd_flags.append( '-I/Users/jberwald/src/capd/capdAlg/include/capd/intervals' )
-capd_libs = capd_libs
-
-##################################
-## End setup, begin build funcs
-##################################
-
-def compile_cpp(inputs,output):
-	print "g++ compiling inputs: ", inputs
-	print "g++ outputs: ", output
-	run(config.exe['c'],config.flags['c'],
-		['-I'+i for i in includes],
-		capd_flags, '-w',
-		'-c', inputs,'-o', output )
-
-def compile_cython(inputs,output):
-	run(config.exe['cython'], ['-I'+i for i in includes],
-		'-a', '--cplus', inputs, '-o', output)
-	
-def link_cython(inputs,output):
-	print "linking inputs", inputs
-	print "linking ouput", output
-	print ""
-	run(config.exe['c++'],
-	    config.flags['c++ cython'],
-	    '-o', output,
-	    ['-g'],
-	    inputs,
-	    capd_libs,
-	    config.link['c++ cython'])#+ [capd_links] )
-		
-def link_cpp(inputs,output):
-	"""
-	When using CAPD, we remove the linker flags, since the CAPD
-	capd-config script does this automagically(?).
-	"""
-	run(config.exe['c++'], #config.flags['c++'], # cannot be empty (!?)
-			       #config.link['c++ cython'],
-	    config.link['c++'],
-	    '-o', output,
-	    ['-g'],
-	    capd_flags,
-	    capd_libs,
-	    config.flags['c++ cython'],
-            inputs)
-		
-
-def scandir(dir, files=[], ext='.py'):
-	"""
-	Return all paths (dir/dir2/dir3/file) of files in 'dir' (including
-	subdirectories) with extension 'ext'
-	"""
-	for file in os.listdir(dir):
-		path = os.path.join(dir, file)
-		if os.path.isfile(path) and path.endswith( ext ):
-			# print path
-			# files.append(path.replace(os.path.sep, '.')[:-len(ext)-1])
-			files.append(path[:-len(ext)]) # kill extension
-		elif os.path.isdir(path):
-			scandir(path, files, ext)
-	return files
-
-def build_cpp_deps(f):
-	"""
-	Builds each dependency of f (not including f).	Returns the
-	list of destinations so that the linker can find where these ended
-	up.
-	"""
-	name = f.split('/')[-1]				# name.cpp (or name.pyx)
-	if name not in dependencies:
-		return []							# nothing to do here...
-
-	for dep in dependencies[name]:
-		compile_cpp(cpp_source_dir+dep+'.cpp',cpp_object_dir+dep+'.o')
-	objects = [cpp_object_dir + d for d in [f]+dependencies[name]]
-	return objects # the destinations, include f here
-
-
-def build_cyfile(sourcepath):
-	"""
-	NOTE: using a flat namespace for Cython for right now to easy the dependencies...
-	1. Compile (Cython)
-		 src/rads/...../file.pyx --> <cpp_source_dir>/file_from_cython.cpp
-		 
-	2. Compile (C++)
-		 <cpp_source_dir>/file_from_cython.cpp --> <cpp_object_dir>/file.o
-		 
-	3. Look up dependencies[file] and compile each of those
-		 <cpp_object_dir>/dep.o
-		 
-	4. Finally, link all of the above
-		 <lib_dir>/rads/...../file.so
-	"""
-	filename = sourcepath.split(os.path.sep)[-1]			   # filename.pyx
-	tempfile = tmp_dir+filename+'_from_cython.cpp' # the temp cpp file name
-	finalpath = lib_dir+sourcepath.replace('src/','') # the final resting place = rads/../..
-	# compile to temp dir, but flat (notice tempfile instead of sourcepath)
-	compile_cython(sourcepath+'.pyx', tempfile)
-
-	print ""
-	print "compiled cython file, compiling cpp file..."
-	print ""
-	
-	compile_cpp(tempfile, cpp_object_dir+filename+'.o')
-	deps = build_cpp_deps(filename) # c++ dependencies, including self
-
-	print ""
-	print "linking object files"
-	print "finalpath:", finalpath+'.so'
-	print ""
-	
-	objects = [d+'.o' for d in deps]
-	link_cython(objects, finalpath + extension )
-
-
-def build_map(sourcepath):
-	"""
-	NOTE: using a flat namespace for Cython for right now to easy the dependencies...
-	1. Compile (Cython, C++)
-		 src/rads/maps/map.pyx --> <cpp_source_dir>/map_cython_mapfile.cpp
-		 <cpp_source_dir>/map_cython_mapfile.cpp --> <cpp_object_dir>/map_cython_mapfile.o
-
-	2. Compile (C++)
-		 src/rads/maps/map_cpp.cpp --> <cpp_object_dir>/map_cpp_mapfile.o
-
-	3. Finally, link all of the above
-		 <lib_dir>/rads/maps/map.so
-	"""
-	filename = sourcepath.split(os.path.sep)[-1]			   # filename.pyx
-	finalpath = lib_dir+sourcepath.replace('src/','') # the final resting place = rads/../..
-	cython_cpp = tmp_dir+filename+'_cython_mapfile.cpp'
-	cython_o = cpp_object_dir+filename+'_cython_mapfile.o'
-	cpp_o = cpp_object_dir+filename+'_cpp_mapfile.o'
-	compile_cython(sourcepath+'.pyx', cython_cpp)
-	print ""
-	print "done with cython map files, compiling c++..."
-	print ""
-	compile_cpp(cython_cpp, cython_o)
-	compile_cpp(sourcepath+'_cpp.cpp', cpp_o)
-
-	link_cython([cython_o, cpp_o], finalpath + extension )
-
-
-def build_cpp(name):
-	"""Build a c++ file."""
-	compile_cpp(cpp_source_dir+name+'.cpp', cpp_object_dir+name+'.o')
-	print ""
-	print "  building deps..."
-	print ""
-	deps = build_cpp_deps(name)
-	print ""
-	print "  now linking..."
-	print ""
-	link_cpp([d+'.o' for d in deps],lib_dir+name)
-
-
-def build():
-	# copy python files over, preserving directory structure
-	copydirs('src/rads/', lib_dir+'rads/', ext='.py')	
-	# os.chdir('src' )
-	# run('python ../buildpy.py build --build-base=../build'.split())
-	# os.chdir('..')
-
-	# make temp directories for objects, etc
-	try:
-		os.makedirs(cpp_object_dir)
-		os.makedirs(tmp_dir+'src/')
-	except OSError:
-		pass
-
-	# all cython files to compile
-	files = scandir('src/rads',ext='.pyx')
-
-	print "FILES", files
-
-	for path in files:					# for each cython file
-		print ""
-		print "path:"
-		print path
-		print ""
-		if path.startswith(map_dir):	# this is a user-defined map
-			build_map(path)				# treat maps differently
-		else:
-			build_cyfile(path)			# normal cython file
-
-	for name in cpp_progs:				# c++ programs...
-		print "file name", name
-		print "building cpp progs..."
-		build_cpp(name)
-
-def test():
-	build()
-	os.chdir(lib_dir)
-	run('python', 'rads/test/test_graphs.py')
-	#run('ipython', '-pylab', 'rads/test/test_tree.py')
-	run('ipython', '-pylab', 'rads/test/test_henon.py')
-	
-def clean():
-	run('rm -r build'.split())
-	autoclean()
-
-main()
diff --git a/sandbox/figures/henon_scc/henon_symbol_map_scc0.png b/sandbox/figures/henon_scc/henon_symbol_map_scc0.png
deleted file mode 100644
index 0935407..0000000
Binary files a/sandbox/figures/henon_scc/henon_symbol_map_scc0.png and /dev/null differ
diff --git a/sandbox/figures/henon_scc/henon_symbol_map_scc1.png b/sandbox/figures/henon_scc/henon_symbol_map_scc1.png
deleted file mode 100644
index ef5f79c..0000000
Binary files a/sandbox/figures/henon_scc/henon_symbol_map_scc1.png and /dev/null differ
diff --git a/sandbox/figures/henon_scc/henon_symbol_map_scc2.png b/sandbox/figures/henon_scc/henon_symbol_map_scc2.png
deleted file mode 100644
index efc119f..0000000
Binary files a/sandbox/figures/henon_scc/henon_symbol_map_scc2.png and /dev/null differ
diff --git a/sandbox/figures/henon_scc/henon_symbol_map_scc3.png b/sandbox/figures/henon_scc/henon_symbol_map_scc3.png
deleted file mode 100644
index 4cab1a9..0000000
Binary files a/sandbox/figures/henon_scc/henon_symbol_map_scc3.png and /dev/null differ
diff --git a/sandbox/figures/henon_scc/henon_symbol_map_scc4.png b/sandbox/figures/henon_scc/henon_symbol_map_scc4.png
deleted file mode 100644
index 780899a..0000000
Binary files a/sandbox/figures/henon_scc/henon_symbol_map_scc4.png and /dev/null differ
diff --git a/sandbox/figures/henon_symbol_map_scc0.png b/sandbox/figures/henon_symbol_map_scc0.png
deleted file mode 100644
index 0935407..0000000
Binary files a/sandbox/figures/henon_symbol_map_scc0.png and /dev/null differ
diff --git a/sandbox/figures/henon_symbol_map_scc1.png b/sandbox/figures/henon_symbol_map_scc1.png
deleted file mode 100644
index ef5f79c..0000000
Binary files a/sandbox/figures/henon_symbol_map_scc1.png and /dev/null differ
diff --git a/sandbox/figures/henon_symbol_map_scc2.png b/sandbox/figures/henon_symbol_map_scc2.png
deleted file mode 100644
index efc119f..0000000
Binary files a/sandbox/figures/henon_symbol_map_scc2.png and /dev/null differ
diff --git a/sandbox/figures/henon_symbol_map_scc3.png b/sandbox/figures/henon_symbol_map_scc3.png
deleted file mode 100644
index 4cab1a9..0000000
Binary files a/sandbox/figures/henon_symbol_map_scc3.png and /dev/null differ
diff --git a/sandbox/figures/henon_symbol_map_scc4.png b/sandbox/figures/henon_symbol_map_scc4.png
deleted file mode 100644
index 780899a..0000000
Binary files a/sandbox/figures/henon_symbol_map_scc4.png and /dev/null differ
diff --git a/sandbox/henon_best_entropy.png b/sandbox/henon_best_entropy.png
deleted file mode 100644
index b10d1dc..0000000
Binary files a/sandbox/henon_best_entropy.png and /dev/null differ
diff --git a/sandbox/henon_gens.mat b/sandbox/henon_gens.mat
deleted file mode 100644
index 003909e..0000000
Binary files a/sandbox/henon_gens.mat and /dev/null differ
diff --git a/sandbox/henon_hom.mat b/sandbox/henon_hom.mat
deleted file mode 100644
index 3d82a6b..0000000
Binary files a/sandbox/henon_hom.mat and /dev/null differ
diff --git a/sandbox/henon_index.mat b/sandbox/henon_index.mat
deleted file mode 100644
index dd14639..0000000
Binary files a/sandbox/henon_index.mat and /dev/null differ
diff --git a/sandbox/henon_regions.png b/sandbox/henon_regions.png
deleted file mode 100644
index c9cfaf9..0000000
Binary files a/sandbox/henon_regions.png and /dev/null differ
diff --git a/sandbox/leslie_best_entropy.png b/sandbox/leslie_best_entropy.png
deleted file mode 100644
index 364b682..0000000
Binary files a/sandbox/leslie_best_entropy.png and /dev/null differ
diff --git a/sandbox/leslie_gens.mat b/sandbox/leslie_gens.mat
deleted file mode 100644
index 3e8adcb..0000000
Binary files a/sandbox/leslie_gens.mat and /dev/null differ
diff --git a/sandbox/leslie_hom.mat b/sandbox/leslie_hom.mat
deleted file mode 100644
index c7b1ce9..0000000
Binary files a/sandbox/leslie_hom.mat and /dev/null differ
diff --git a/sandbox/leslie_index.mat b/sandbox/leslie_index.mat
deleted file mode 100644
index 810c052..0000000
Binary files a/sandbox/leslie_index.mat and /dev/null differ
diff --git a/sandbox/leslie_regions.png b/sandbox/leslie_regions.png
deleted file mode 100644
index db6d34a..0000000
Binary files a/sandbox/leslie_regions.png and /dev/null differ
diff --git a/sandbox/loadmat_test.py b/sandbox/loadmat_test.py
deleted file mode 100644
index 9783fce..0000000
--- a/sandbox/loadmat_test.py
+++ /dev/null
@@ -1,34 +0,0 @@
-import scipy.io as spio
-
-def loadmat(filename):
-    '''
-    this function should be called instead of direct spio.loadmat
-    as it cures the problem of not properly recovering python dictionaries
-    from mat files. It calls the function check keys to cure all entries
-    which are still mat-objects
-    '''
-    data = spio.loadmat(filename, struct_as_record=False, squeeze_me=True)
-    return _check_keys(data)
-
-def _check_keys(dict):
-    '''
-    checks if entries in dictionary are mat-objects. If yes
-    todict is called to change them to nested dictionaries
-    '''
-    for key in dict:
-        if isinstance(dict[key], spio.matlab.mio5_params.mat_struct):
-            dict[key] = _todict(dict[key])
-    return dict        
-
-def _todict(matobj):
-    '''
-    A recursive function which constructs from matobjects nested dictionaries
-    '''
-    dict = {}
-    for strg in matobj._fieldnames:
-        elem = matobj.__dict__[strg]
-        if isinstance(elem, spio.matlab.mio5_params.mat_struct):
-            dict[strg] = _todict(elem)
-        else:
-            dict[strg] = elem
-    return dict
diff --git a/sandbox/make_ricker.py b/sandbox/make_ricker.py
deleted file mode 100644
index bc32dd7..0000000
--- a/sandbox/make_ricker.py
+++ /dev/null
@@ -1,8 +0,0 @@
-from distutils.core import setup
-from Cython.Build import cythonize
-
-setup(ext_modules = cythonize(
-           "ricker.pyx",                 # our Cython source
-           sources=["ricker_cpp.cpp"],  # additional source file(s)
-           language="c++",             # generate C++ code
-      ))
diff --git a/sandbox/ricker.c b/sandbox/ricker.c
deleted file mode 100644
index 752eab0..0000000
--- a/sandbox/ricker.c
+++ /dev/null
@@ -1,2022 +0,0 @@
-/* Generated by Cython 0.16 on Tue Mar 26 16:26:58 2013 */
-
-#define PY_SSIZE_T_CLEAN
-#include "Python.h"
-#ifndef Py_PYTHON_H
-    #error Python headers needed to compile C extensions, please install development version of Python.
-#elif PY_VERSION_HEX < 0x02040000
-    #error Cython requires Python 2.4+.
-#else
-#include <stddef.h> /* For offsetof */
-#ifndef offsetof
-#define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
-#endif
-
-#if !defined(WIN32) && !defined(MS_WINDOWS)
-  #ifndef __stdcall
-    #define __stdcall
-  #endif
-  #ifndef __cdecl
-    #define __cdecl
-  #endif
-  #ifndef __fastcall
-    #define __fastcall
-  #endif
-#endif
-
-#ifndef DL_IMPORT
-  #define DL_IMPORT(t) t
-#endif
-#ifndef DL_EXPORT
-  #define DL_EXPORT(t) t
-#endif
-
-#ifndef PY_LONG_LONG
-  #define PY_LONG_LONG LONG_LONG
-#endif
-
-#ifndef Py_HUGE_VAL
-  #define Py_HUGE_VAL HUGE_VAL
-#endif
-
-#ifdef PYPY_VERSION
-#define CYTHON_COMPILING_IN_PYPY 1
-#define CYTHON_COMPILING_IN_CPYTHON 0
-#else
-#define CYTHON_COMPILING_IN_PYPY 0
-#define CYTHON_COMPILING_IN_CPYTHON 1
-#endif
-
-#if CYTHON_COMPILING_IN_PYPY
-  #define __Pyx_PyCFunction_Call PyObject_Call
-#else
-  #define __Pyx_PyCFunction_Call PyCFunction_Call
-#endif
-
-#if PY_VERSION_HEX < 0x02050000
-  typedef int Py_ssize_t;
-  #define PY_SSIZE_T_MAX INT_MAX
-  #define PY_SSIZE_T_MIN INT_MIN
-  #define PY_FORMAT_SIZE_T ""
-  #define PyInt_FromSsize_t(z) PyInt_FromLong(z)
-  #define PyInt_AsSsize_t(o)   __Pyx_PyInt_AsInt(o)
-  #define PyNumber_Index(o)    PyNumber_Int(o)
-  #define PyIndex_Check(o)     PyNumber_Check(o)
-  #define PyErr_WarnEx(category, message, stacklevel) PyErr_Warn(category, message)
-  #define __PYX_BUILD_PY_SSIZE_T "i"
-#else
-  #define __PYX_BUILD_PY_SSIZE_T "n"
-#endif
-
-#if PY_VERSION_HEX < 0x02060000
-  #define Py_REFCNT(ob) (((PyObject*)(ob))->ob_refcnt)
-  #define Py_TYPE(ob)   (((PyObject*)(ob))->ob_type)
-  #define Py_SIZE(ob)   (((PyVarObject*)(ob))->ob_size)
-  #define PyVarObject_HEAD_INIT(type, size) \
-          PyObject_HEAD_INIT(type) size,
-  #define PyType_Modified(t)
-
-  typedef struct {
-     void *buf;
-     PyObject *obj;
-     Py_ssize_t len;
-     Py_ssize_t itemsize;
-     int readonly;
-     int ndim;
-     char *format;
-     Py_ssize_t *shape;
-     Py_ssize_t *strides;
-     Py_ssize_t *suboffsets;
-     void *internal;
-  } Py_buffer;
-
-  #define PyBUF_SIMPLE 0
-  #define PyBUF_WRITABLE 0x0001
-  #define PyBUF_FORMAT 0x0004
-  #define PyBUF_ND 0x0008
-  #define PyBUF_STRIDES (0x0010 | PyBUF_ND)
-  #define PyBUF_C_CONTIGUOUS (0x0020 | PyBUF_STRIDES)
-  #define PyBUF_F_CONTIGUOUS (0x0040 | PyBUF_STRIDES)
-  #define PyBUF_ANY_CONTIGUOUS (0x0080 | PyBUF_STRIDES)
-  #define PyBUF_INDIRECT (0x0100 | PyBUF_STRIDES)
-  #define PyBUF_RECORDS (PyBUF_STRIDES | PyBUF_FORMAT | PyBUF_WRITABLE)
-  #define PyBUF_FULL (PyBUF_INDIRECT | PyBUF_FORMAT | PyBUF_WRITABLE)
-
-  typedef int (*getbufferproc)(PyObject *, Py_buffer *, int);
-  typedef void (*releasebufferproc)(PyObject *, Py_buffer *);
-#endif
-
-#if PY_MAJOR_VERSION < 3
-  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
-  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos) \
-          PyCode_New(a, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
-#else
-  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
-  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos) \
-          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
-#endif
-
-#if PY_MAJOR_VERSION < 3 && PY_MINOR_VERSION < 6
-  #define PyUnicode_FromString(s) PyUnicode_Decode(s, strlen(s), "UTF-8", "strict")
-#endif
-
-#if PY_MAJOR_VERSION >= 3
-  #define Py_TPFLAGS_CHECKTYPES 0
-  #define Py_TPFLAGS_HAVE_INDEX 0
-#endif
-
-#if (PY_VERSION_HEX < 0x02060000) || (PY_MAJOR_VERSION >= 3)
-  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
-#endif
-
-
-#if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_GET_LENGTH)
-  #define CYTHON_PEP393_ENABLED 1
-  #define __Pyx_PyUnicode_GET_LENGTH(u) PyUnicode_GET_LENGTH(u)
-  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
-#else
-  #define CYTHON_PEP393_ENABLED 0
-  #define __Pyx_PyUnicode_GET_LENGTH(u) PyUnicode_GET_SIZE(u)
-  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
-#endif
-
-#if PY_MAJOR_VERSION >= 3
-  #define PyBaseString_Type            PyUnicode_Type
-  #define PyStringObject               PyUnicodeObject
-  #define PyString_Type                PyUnicode_Type
-  #define PyString_Check               PyUnicode_Check
-  #define PyString_CheckExact          PyUnicode_CheckExact
-#endif
-
-#if PY_VERSION_HEX < 0x02060000
-  #define PyBytesObject                PyStringObject
-  #define PyBytes_Type                 PyString_Type
-  #define PyBytes_Check                PyString_Check
-  #define PyBytes_CheckExact           PyString_CheckExact
-  #define PyBytes_FromString           PyString_FromString
-  #define PyBytes_FromStringAndSize    PyString_FromStringAndSize
-  #define PyBytes_FromFormat           PyString_FromFormat
-  #define PyBytes_DecodeEscape         PyString_DecodeEscape
-  #define PyBytes_AsString             PyString_AsString
-  #define PyBytes_AsStringAndSize      PyString_AsStringAndSize
-  #define PyBytes_Size                 PyString_Size
-  #define PyBytes_AS_STRING            PyString_AS_STRING
-  #define PyBytes_GET_SIZE             PyString_GET_SIZE
-  #define PyBytes_Repr                 PyString_Repr
-  #define PyBytes_Concat               PyString_Concat
-  #define PyBytes_ConcatAndDel         PyString_ConcatAndDel
-#endif
-
-#if PY_VERSION_HEX < 0x02060000
-  #define PySet_Check(obj)             PyObject_TypeCheck(obj, &PySet_Type)
-  #define PyFrozenSet_Check(obj)       PyObject_TypeCheck(obj, &PyFrozenSet_Type)
-#endif
-#ifndef PySet_CheckExact
-  #define PySet_CheckExact(obj)        (Py_TYPE(obj) == &PySet_Type)
-#endif
-
-#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
-
-#if PY_MAJOR_VERSION >= 3
-  #define PyIntObject                  PyLongObject
-  #define PyInt_Type                   PyLong_Type
-  #define PyInt_Check(op)              PyLong_Check(op)
-  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
-  #define PyInt_FromString             PyLong_FromString
-  #define PyInt_FromUnicode            PyLong_FromUnicode
-  #define PyInt_FromLong               PyLong_FromLong
-  #define PyInt_FromSize_t             PyLong_FromSize_t
-  #define PyInt_FromSsize_t            PyLong_FromSsize_t
-  #define PyInt_AsLong                 PyLong_AsLong
-  #define PyInt_AS_LONG                PyLong_AS_LONG
-  #define PyInt_AsSsize_t              PyLong_AsSsize_t
-  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
-  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
-#endif
-
-#if PY_MAJOR_VERSION >= 3
-  #define PyBoolObject                 PyLongObject
-#endif
-
-#if PY_VERSION_HEX < 0x03020000
-  typedef long Py_hash_t;
-  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
-  #define __Pyx_PyInt_AsHash_t   PyInt_AsLong
-#else
-  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
-  #define __Pyx_PyInt_AsHash_t   PyInt_AsSsize_t
-#endif
-
-#if (PY_MAJOR_VERSION < 3) || (PY_VERSION_HEX >= 0x03010300)
-  #define __Pyx_PySequence_GetSlice(obj, a, b) PySequence_GetSlice(obj, a, b)
-  #define __Pyx_PySequence_SetSlice(obj, a, b, value) PySequence_SetSlice(obj, a, b, value)
-  #define __Pyx_PySequence_DelSlice(obj, a, b) PySequence_DelSlice(obj, a, b)
-#else
-  #define __Pyx_PySequence_GetSlice(obj, a, b) (unlikely(!(obj)) ? \
-        (PyErr_SetString(PyExc_SystemError, "null argument to internal routine"), (PyObject*)0) : \
-        (likely((obj)->ob_type->tp_as_mapping) ? (PySequence_GetSlice(obj, a, b)) : \
-            (PyErr_Format(PyExc_TypeError, "'%.200s' object is unsliceable", (obj)->ob_type->tp_name), (PyObject*)0)))
-  #define __Pyx_PySequence_SetSlice(obj, a, b, value) (unlikely(!(obj)) ? \
-        (PyErr_SetString(PyExc_SystemError, "null argument to internal routine"), -1) : \
-        (likely((obj)->ob_type->tp_as_mapping) ? (PySequence_SetSlice(obj, a, b, value)) : \
-            (PyErr_Format(PyExc_TypeError, "'%.200s' object doesn't support slice assignment", (obj)->ob_type->tp_name), -1)))
-  #define __Pyx_PySequence_DelSlice(obj, a, b) (unlikely(!(obj)) ? \
-        (PyErr_SetString(PyExc_SystemError, "null argument to internal routine"), -1) : \
-        (likely((obj)->ob_type->tp_as_mapping) ? (PySequence_DelSlice(obj, a, b)) : \
-            (PyErr_Format(PyExc_TypeError, "'%.200s' object doesn't support slice deletion", (obj)->ob_type->tp_name), -1)))
-#endif
-
-#if PY_MAJOR_VERSION >= 3
-  #define PyMethod_New(func, self, klass) ((self) ? PyMethod_New(func, self) : PyInstanceMethod_New(func))
-#endif
-
-#if PY_VERSION_HEX < 0x02050000
-  #define __Pyx_GetAttrString(o,n)   PyObject_GetAttrString((o),((char *)(n)))
-  #define __Pyx_SetAttrString(o,n,a) PyObject_SetAttrString((o),((char *)(n)),(a))
-  #define __Pyx_DelAttrString(o,n)   PyObject_DelAttrString((o),((char *)(n)))
-#else
-  #define __Pyx_GetAttrString(o,n)   PyObject_GetAttrString((o),(n))
-  #define __Pyx_SetAttrString(o,n,a) PyObject_SetAttrString((o),(n),(a))
-  #define __Pyx_DelAttrString(o,n)   PyObject_DelAttrString((o),(n))
-#endif
-
-#if PY_VERSION_HEX < 0x02050000
-  #define __Pyx_NAMESTR(n) ((char *)(n))
-  #define __Pyx_DOCSTR(n)  ((char *)(n))
-#else
-  #define __Pyx_NAMESTR(n) (n)
-  #define __Pyx_DOCSTR(n)  (n)
-#endif
-
-#if PY_MAJOR_VERSION >= 3
-  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
-  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
-#else
-  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_Divide(x,y)
-  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceDivide(x,y)
-#endif
-
-#ifndef __PYX_EXTERN_C
-  #ifdef __cplusplus
-    #define __PYX_EXTERN_C extern "C"
-  #else
-    #define __PYX_EXTERN_C extern
-  #endif
-#endif
-
-#if defined(WIN32) || defined(MS_WINDOWS)
-#define _USE_MATH_DEFINES
-#endif
-#include <math.h>
-#define __PYX_HAVE__ricker
-#define __PYX_HAVE_API__ricker
-#include <vector>
-#include "string.h"
-#include "Interval.h"
-#include "point.h"
-#include "box.h"
-#include "boxset.h"
-#include "tree.h"
-#include "string"
-#include "mapper.h"
-#include "ricker_cpp.h"
-#ifdef _OPENMP
-#include <omp.h>
-#endif /* _OPENMP */
-
-#ifdef PYREX_WITHOUT_ASSERTIONS
-#define CYTHON_WITHOUT_ASSERTIONS
-#endif
-
-
-/* inline attribute */
-#ifndef CYTHON_INLINE
-  #if defined(__GNUC__)
-    #define CYTHON_INLINE __inline__
-  #elif defined(_MSC_VER)
-    #define CYTHON_INLINE __inline
-  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
-    #define CYTHON_INLINE inline
-  #else
-    #define CYTHON_INLINE
-  #endif
-#endif
-
-/* unused attribute */
-#ifndef CYTHON_UNUSED
-# if defined(__GNUC__)
-#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
-#     define CYTHON_UNUSED __attribute__ ((__unused__))
-#   else
-#     define CYTHON_UNUSED
-#   endif
-# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
-#   define CYTHON_UNUSED __attribute__ ((__unused__))
-# else
-#   define CYTHON_UNUSED
-# endif
-#endif
-
-typedef struct {PyObject **p; char *s; const long n; const char* encoding; const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry; /*proto*/
-
-
-/* Type Conversion Predeclarations */
-
-#define __Pyx_PyBytes_FromUString(s) PyBytes_FromString((char*)s)
-#define __Pyx_PyBytes_AsUString(s)   ((unsigned char*) PyBytes_AsString(s))
-
-#define __Pyx_Owned_Py_None(b) (Py_INCREF(Py_None), Py_None)
-#define __Pyx_PyBool_FromLong(b) ((b) ? (Py_INCREF(Py_True), Py_True) : (Py_INCREF(Py_False), Py_False))
-static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
-static CYTHON_INLINE PyObject* __Pyx_PyNumber_Int(PyObject* x);
-
-static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
-static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
-static CYTHON_INLINE size_t __Pyx_PyInt_AsSize_t(PyObject*);
-
-#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
-#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
-
-#ifdef __GNUC__
-  /* Test for GCC > 2.95 */
-  #if __GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95))
-    #define likely(x)   __builtin_expect(!!(x), 1)
-    #define unlikely(x) __builtin_expect(!!(x), 0)
-  #else /* __GNUC__ > 2 ... */
-    #define likely(x)   (x)
-    #define unlikely(x) (x)
-  #endif /* __GNUC__ > 2 ... */
-#else /* __GNUC__ */
-  #define likely(x)   (x)
-  #define unlikely(x) (x)
-#endif /* __GNUC__ */
-    
-static PyObject *__pyx_m;
-static PyObject *__pyx_b;
-static PyObject *__pyx_empty_tuple;
-static PyObject *__pyx_empty_bytes;
-static int __pyx_lineno;
-static int __pyx_clineno = 0;
-static const char * __pyx_cfilenm= __FILE__;
-static const char *__pyx_filename;
-
-
-static const char *__pyx_f[] = {
-  "ricker.pyx",
-};
-
-/*--- Type declarations ---*/
-struct __pyx_obj_4rads_9enclosure_8cymapper_Mapper;
-struct __pyx_obj_6ricker_RickerMapper;
-
-/* "rads/enclosure/cymapper.pxd":3
- * from cppdefs cimport *
- * 
- * cdef class Mapper:             # <<<<<<<<<<<<<<
- * 	cdef cMapper *mapper
- * 	cdef cMapper *get_mapper(self)
- */
-struct __pyx_obj_4rads_9enclosure_8cymapper_Mapper {
-  PyObject_HEAD
-  struct __pyx_vtabstruct_4rads_9enclosure_8cymapper_Mapper *__pyx_vtab;
-  Mapper *mapper;
-};
-
-
-/* "ricker.pyx":11
- * 	void del_Ricker "delete" (cRicker *)
- * 
- * cdef class RickerMapper(Mapper):             # <<<<<<<<<<<<<<
- * 
- * 	def __cinit__(self):
- */
-struct __pyx_obj_6ricker_RickerMapper {
-  struct __pyx_obj_4rads_9enclosure_8cymapper_Mapper __pyx_base;
-};
-
-
-
-/* "rads/enclosure/cymapper.pxd":3
- * from cppdefs cimport *
- * 
- * cdef class Mapper:             # <<<<<<<<<<<<<<
- * 	cdef cMapper *mapper
- * 	cdef cMapper *get_mapper(self)
- */
-
-struct __pyx_vtabstruct_4rads_9enclosure_8cymapper_Mapper {
-  Mapper *(*get_mapper)(struct __pyx_obj_4rads_9enclosure_8cymapper_Mapper *);
-  int (*get_dim)(struct __pyx_obj_4rads_9enclosure_8cymapper_Mapper *, int __pyx_skip_dispatch);
-};
-static struct __pyx_vtabstruct_4rads_9enclosure_8cymapper_Mapper *__pyx_vtabptr_4rads_9enclosure_8cymapper_Mapper;
-
-
-/* "ricker.pyx":11
- * 	void del_Ricker "delete" (cRicker *)
- * 
- * cdef class RickerMapper(Mapper):             # <<<<<<<<<<<<<<
- * 
- * 	def __cinit__(self):
- */
-
-struct __pyx_vtabstruct_6ricker_RickerMapper {
-  struct __pyx_vtabstruct_4rads_9enclosure_8cymapper_Mapper __pyx_base;
-};
-static struct __pyx_vtabstruct_6ricker_RickerMapper *__pyx_vtabptr_6ricker_RickerMapper;
-#ifndef CYTHON_REFNANNY
-  #define CYTHON_REFNANNY 0
-#endif
-#if CYTHON_REFNANNY
-  typedef struct {
-    void (*INCREF)(void*, PyObject*, int);
-    void (*DECREF)(void*, PyObject*, int);
-    void (*GOTREF)(void*, PyObject*, int);
-    void (*GIVEREF)(void*, PyObject*, int);
-    void* (*SetupContext)(const char*, int, const char*);
-    void (*FinishContext)(void**);
-  } __Pyx_RefNannyAPIStruct;
-  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
-  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname); /*proto*/
-  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
-#ifdef WITH_THREAD
-  #define __Pyx_RefNannySetupContext(name, acquire_gil) \
-          if (acquire_gil) { \
-              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure(); \
-              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__); \
-              PyGILState_Release(__pyx_gilstate_save); \
-          } else { \
-              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__); \
-          }
-#else
-  #define __Pyx_RefNannySetupContext(name, acquire_gil) \
-          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__)
-#endif
-  #define __Pyx_RefNannyFinishContext() \
-          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
-  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
-  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
-  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
-  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
-  #define __Pyx_XINCREF(r)  do { if((r) != NULL) {__Pyx_INCREF(r); }} while(0)
-  #define __Pyx_XDECREF(r)  do { if((r) != NULL) {__Pyx_DECREF(r); }} while(0)
-  #define __Pyx_XGOTREF(r)  do { if((r) != NULL) {__Pyx_GOTREF(r); }} while(0)
-  #define __Pyx_XGIVEREF(r) do { if((r) != NULL) {__Pyx_GIVEREF(r);}} while(0)
-#else
-  #define __Pyx_RefNannyDeclarations
-  #define __Pyx_RefNannySetupContext(name, acquire_gil)
-  #define __Pyx_RefNannyFinishContext()
-  #define __Pyx_INCREF(r) Py_INCREF(r)
-  #define __Pyx_DECREF(r) Py_DECREF(r)
-  #define __Pyx_GOTREF(r)
-  #define __Pyx_GIVEREF(r)
-  #define __Pyx_XINCREF(r) Py_XINCREF(r)
-  #define __Pyx_XDECREF(r) Py_XDECREF(r)
-  #define __Pyx_XGOTREF(r)
-  #define __Pyx_XGIVEREF(r)
-#endif /* CYTHON_REFNANNY */
-#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
-#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)
-
-static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
-    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found); /*proto*/
-
-static CYTHON_INLINE int __Pyx_CheckKeywordStrings(PyObject *kwdict, const char* function_name, int kw_allowed); /*proto*/
-
-static int __Pyx_Print(PyObject*, PyObject *, int); /*proto*/
-#if PY_MAJOR_VERSION >= 3
-static PyObject* __pyx_print = 0;
-static PyObject* __pyx_print_kwargs = 0;
-#endif
-
-static int __Pyx_PrintOne(PyObject* stream, PyObject *o); /*proto*/
-
-static CYTHON_INLINE unsigned char __Pyx_PyInt_AsUnsignedChar(PyObject *);
-
-static CYTHON_INLINE unsigned short __Pyx_PyInt_AsUnsignedShort(PyObject *);
-
-static CYTHON_INLINE unsigned int __Pyx_PyInt_AsUnsignedInt(PyObject *);
-
-static CYTHON_INLINE char __Pyx_PyInt_AsChar(PyObject *);
-
-static CYTHON_INLINE short __Pyx_PyInt_AsShort(PyObject *);
-
-static CYTHON_INLINE int __Pyx_PyInt_AsInt(PyObject *);
-
-static CYTHON_INLINE signed char __Pyx_PyInt_AsSignedChar(PyObject *);
-
-static CYTHON_INLINE signed short __Pyx_PyInt_AsSignedShort(PyObject *);
-
-static CYTHON_INLINE signed int __Pyx_PyInt_AsSignedInt(PyObject *);
-
-static CYTHON_INLINE int __Pyx_PyInt_AsLongDouble(PyObject *);
-
-static CYTHON_INLINE unsigned long __Pyx_PyInt_AsUnsignedLong(PyObject *);
-
-static CYTHON_INLINE unsigned PY_LONG_LONG __Pyx_PyInt_AsUnsignedLongLong(PyObject *);
-
-static CYTHON_INLINE long __Pyx_PyInt_AsLong(PyObject *);
-
-static CYTHON_INLINE PY_LONG_LONG __Pyx_PyInt_AsLongLong(PyObject *);
-
-static CYTHON_INLINE signed long __Pyx_PyInt_AsSignedLong(PyObject *);
-
-static CYTHON_INLINE signed PY_LONG_LONG __Pyx_PyInt_AsSignedLongLong(PyObject *);
-
-static int __Pyx_check_binary_version(void);
-
-#if !defined(__Pyx_PyIdentifier_FromString)
-#if PY_MAJOR_VERSION < 3
-  #define __Pyx_PyIdentifier_FromString(s) PyString_FromString(s)
-#else
-  #define __Pyx_PyIdentifier_FromString(s) PyUnicode_FromString(s)
-#endif
-#endif
-
-static PyTypeObject *__Pyx_ImportType(const char *module_name, const char *class_name, size_t size, int strict);  /*proto*/
-
-static PyObject *__Pyx_ImportModule(const char *name); /*proto*/
-
-static void* __Pyx_GetVtable(PyObject *dict); /*proto*/
-
-static int __Pyx_SetVtable(PyObject *dict, void *vtable); /*proto*/
-
-typedef struct {
-    int code_line;
-    PyCodeObject* code_object;
-} __Pyx_CodeObjectCacheEntry;
-struct __Pyx_CodeObjectCache {
-    int count;
-    int max_count;
-    __Pyx_CodeObjectCacheEntry* entries;
-};
-static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
-static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
-static PyCodeObject *__pyx_find_code_object(int code_line);
-static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);
-
-static void __Pyx_AddTraceback(const char *funcname, int c_line,
-                               int py_line, const char *filename); /*proto*/
-
-static int __Pyx_InitStrings(__Pyx_StringTabEntry *t); /*proto*/
-
-
-/* Module declarations from 'libcpp.vector' */
-
-/* Module declarations from 'libc' */
-
-/* Module declarations from 'libc.string' */
-
-/* Module declarations from 'rads.enclosure.cppdefs' */
-
-/* Module declarations from 'rads.enclosure.cymapper' */
-static PyTypeObject *__pyx_ptype_4rads_9enclosure_8cymapper_Mapper = 0;
-
-/* Module declarations from 'ricker' */
-static PyTypeObject *__pyx_ptype_6ricker_RickerMapper = 0;
-#define __Pyx_MODULE_NAME "ricker"
-int __pyx_module_is_main_ricker = 0;
-
-/* Implementation of 'ricker' */
-static int __pyx_pf_6ricker_12RickerMapper___cinit__(struct __pyx_obj_6ricker_RickerMapper *__pyx_v_self); /* proto */
-static void __pyx_pf_6ricker_12RickerMapper_2__dealloc__(struct __pyx_obj_6ricker_RickerMapper *__pyx_v_self); /* proto */
-static char __pyx_k_1[] = "in RickernMapper cinit";
-static char __pyx_k____main__[] = "__main__";
-static char __pyx_k____test__[] = "__test__";
-static PyObject *__pyx_kp_s_1;
-static PyObject *__pyx_n_s____main__;
-static PyObject *__pyx_n_s____test__;
-
-/* Python wrapper */
-static int __pyx_pw_6ricker_12RickerMapper_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
-static int __pyx_pw_6ricker_12RickerMapper_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
-  int __pyx_r;
-  __Pyx_RefNannyDeclarations
-  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
-  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
-    __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return -1;}
-  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__cinit__", 0))) return -1;
-  __pyx_r = __pyx_pf_6ricker_12RickerMapper___cinit__(((struct __pyx_obj_6ricker_RickerMapper *)__pyx_v_self));
-  __Pyx_RefNannyFinishContext();
-  return __pyx_r;
-}
-
-/* "ricker.pyx":13
- * cdef class RickerMapper(Mapper):
- * 
- * 	def __cinit__(self):             # <<<<<<<<<<<<<<
- * 		print "in RickernMapper cinit"
- * 		self.mapper = <cMapper *>new_Ricker()
- */
-
-static int __pyx_pf_6ricker_12RickerMapper___cinit__(struct __pyx_obj_6ricker_RickerMapper *__pyx_v_self) {
-  int __pyx_r;
-  __Pyx_RefNannyDeclarations
-  int __pyx_lineno = 0;
-  const char *__pyx_filename = NULL;
-  int __pyx_clineno = 0;
-  __Pyx_RefNannySetupContext("__cinit__", 0);
-
-  /* "ricker.pyx":14
- * 
- * 	def __cinit__(self):
- * 		print "in RickernMapper cinit"             # <<<<<<<<<<<<<<
- * 		self.mapper = <cMapper *>new_Ricker()
- * 
- */
-  if (__Pyx_PrintOne(0, ((PyObject *)__pyx_kp_s_1)) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 14; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-
-  /* "ricker.pyx":15
- * 	def __cinit__(self):
- * 		print "in RickernMapper cinit"
- * 		self.mapper = <cMapper *>new_Ricker()             # <<<<<<<<<<<<<<
- * 
- * 	def __dealloc__(self):
- */
-  __pyx_v_self->__pyx_base.mapper = ((Mapper *)new RickerMapper());
-
-  __pyx_r = 0;
-  goto __pyx_L0;
-  __pyx_L1_error:;
-  __Pyx_AddTraceback("ricker.RickerMapper.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
-  __pyx_r = -1;
-  __pyx_L0:;
-  __Pyx_RefNannyFinishContext();
-  return __pyx_r;
-}
-
-/* Python wrapper */
-static void __pyx_pw_6ricker_12RickerMapper_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
-static void __pyx_pw_6ricker_12RickerMapper_3__dealloc__(PyObject *__pyx_v_self) {
-  __Pyx_RefNannyDeclarations
-  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
-  __pyx_pf_6ricker_12RickerMapper_2__dealloc__(((struct __pyx_obj_6ricker_RickerMapper *)__pyx_v_self));
-  __Pyx_RefNannyFinishContext();
-}
-
-/* "ricker.pyx":17
- * 		self.mapper = <cMapper *>new_Ricker()
- * 
- * 	def __dealloc__(self):             # <<<<<<<<<<<<<<
- * 		del_Ricker(<cRicker *>self.mapper)
- * 
- */
-
-static void __pyx_pf_6ricker_12RickerMapper_2__dealloc__(struct __pyx_obj_6ricker_RickerMapper *__pyx_v_self) {
-  __Pyx_RefNannyDeclarations
-  __Pyx_RefNannySetupContext("__dealloc__", 0);
-
-  /* "ricker.pyx":18
- * 
- * 	def __dealloc__(self):
- * 		del_Ricker(<cRicker *>self.mapper)             # <<<<<<<<<<<<<<
- * 
- */
-  delete(((RickerMapper *)__pyx_v_self->__pyx_base.mapper));
-
-  __Pyx_RefNannyFinishContext();
-}
-static struct __pyx_vtabstruct_6ricker_RickerMapper __pyx_vtable_6ricker_RickerMapper;
-
-static PyObject *__pyx_tp_new_6ricker_RickerMapper(PyTypeObject *t, PyObject *a, PyObject *k) {
-  struct __pyx_obj_6ricker_RickerMapper *p;
-  PyObject *o = __pyx_ptype_4rads_9enclosure_8cymapper_Mapper->tp_new(t, a, k);
-  if (!o) return 0;
-  p = ((struct __pyx_obj_6ricker_RickerMapper *)o);
-  p->__pyx_base.__pyx_vtab = (struct __pyx_vtabstruct_4rads_9enclosure_8cymapper_Mapper*)__pyx_vtabptr_6ricker_RickerMapper;
-  if (__pyx_pw_6ricker_12RickerMapper_1__cinit__(o, __pyx_empty_tuple, NULL) < 0) {
-    Py_DECREF(o); o = 0;
-  }
-  return o;
-}
-
-static void __pyx_tp_dealloc_6ricker_RickerMapper(PyObject *o) {
-  {
-    PyObject *etype, *eval, *etb;
-    PyErr_Fetch(&etype, &eval, &etb);
-    ++Py_REFCNT(o);
-    __pyx_pw_6ricker_12RickerMapper_3__dealloc__(o);
-    if (PyErr_Occurred()) PyErr_WriteUnraisable(o);
-    --Py_REFCNT(o);
-    PyErr_Restore(etype, eval, etb);
-  }
-  __pyx_ptype_4rads_9enclosure_8cymapper_Mapper->tp_dealloc(o);
-}
-
-static PyMethodDef __pyx_methods_6ricker_RickerMapper[] = {
-  {0, 0, 0, 0}
-};
-
-static PyNumberMethods __pyx_tp_as_number_RickerMapper = {
-  0, /*nb_add*/
-  0, /*nb_subtract*/
-  0, /*nb_multiply*/
-  #if PY_MAJOR_VERSION < 3
-  0, /*nb_divide*/
-  #endif
-  0, /*nb_remainder*/
-  0, /*nb_divmod*/
-  0, /*nb_power*/
-  0, /*nb_negative*/
-  0, /*nb_positive*/
-  0, /*nb_absolute*/
-  0, /*nb_nonzero*/
-  0, /*nb_invert*/
-  0, /*nb_lshift*/
-  0, /*nb_rshift*/
-  0, /*nb_and*/
-  0, /*nb_xor*/
-  0, /*nb_or*/
-  #if PY_MAJOR_VERSION < 3
-  0, /*nb_coerce*/
-  #endif
-  0, /*nb_int*/
-  #if PY_MAJOR_VERSION < 3
-  0, /*nb_long*/
-  #else
-  0, /*reserved*/
-  #endif
-  0, /*nb_float*/
-  #if PY_MAJOR_VERSION < 3
-  0, /*nb_oct*/
-  #endif
-  #if PY_MAJOR_VERSION < 3
-  0, /*nb_hex*/
-  #endif
-  0, /*nb_inplace_add*/
-  0, /*nb_inplace_subtract*/
-  0, /*nb_inplace_multiply*/
-  #if PY_MAJOR_VERSION < 3
-  0, /*nb_inplace_divide*/
-  #endif
-  0, /*nb_inplace_remainder*/
-  0, /*nb_inplace_power*/
-  0, /*nb_inplace_lshift*/
-  0, /*nb_inplace_rshift*/
-  0, /*nb_inplace_and*/
-  0, /*nb_inplace_xor*/
-  0, /*nb_inplace_or*/
-  0, /*nb_floor_divide*/
-  0, /*nb_true_divide*/
-  0, /*nb_inplace_floor_divide*/
-  0, /*nb_inplace_true_divide*/
-  #if PY_VERSION_HEX >= 0x02050000
-  0, /*nb_index*/
-  #endif
-};
-
-static PySequenceMethods __pyx_tp_as_sequence_RickerMapper = {
-  0, /*sq_length*/
-  0, /*sq_concat*/
-  0, /*sq_repeat*/
-  0, /*sq_item*/
-  0, /*sq_slice*/
-  0, /*sq_ass_item*/
-  0, /*sq_ass_slice*/
-  0, /*sq_contains*/
-  0, /*sq_inplace_concat*/
-  0, /*sq_inplace_repeat*/
-};
-
-static PyMappingMethods __pyx_tp_as_mapping_RickerMapper = {
-  0, /*mp_length*/
-  0, /*mp_subscript*/
-  0, /*mp_ass_subscript*/
-};
-
-static PyBufferProcs __pyx_tp_as_buffer_RickerMapper = {
-  #if PY_MAJOR_VERSION < 3
-  0, /*bf_getreadbuffer*/
-  #endif
-  #if PY_MAJOR_VERSION < 3
-  0, /*bf_getwritebuffer*/
-  #endif
-  #if PY_MAJOR_VERSION < 3
-  0, /*bf_getsegcount*/
-  #endif
-  #if PY_MAJOR_VERSION < 3
-  0, /*bf_getcharbuffer*/
-  #endif
-  #if PY_VERSION_HEX >= 0x02060000
-  0, /*bf_getbuffer*/
-  #endif
-  #if PY_VERSION_HEX >= 0x02060000
-  0, /*bf_releasebuffer*/
-  #endif
-};
-
-static PyTypeObject __pyx_type_6ricker_RickerMapper = {
-  PyVarObject_HEAD_INIT(0, 0)
-  __Pyx_NAMESTR("ricker.RickerMapper"), /*tp_name*/
-  sizeof(struct __pyx_obj_6ricker_RickerMapper), /*tp_basicsize*/
-  0, /*tp_itemsize*/
-  __pyx_tp_dealloc_6ricker_RickerMapper, /*tp_dealloc*/
-  0, /*tp_print*/
-  0, /*tp_getattr*/
-  0, /*tp_setattr*/
-  #if PY_MAJOR_VERSION < 3
-  0, /*tp_compare*/
-  #else
-  0, /*reserved*/
-  #endif
-  0, /*tp_repr*/
-  &__pyx_tp_as_number_RickerMapper, /*tp_as_number*/
-  &__pyx_tp_as_sequence_RickerMapper, /*tp_as_sequence*/
-  &__pyx_tp_as_mapping_RickerMapper, /*tp_as_mapping*/
-  0, /*tp_hash*/
-  0, /*tp_call*/
-  0, /*tp_str*/
-  0, /*tp_getattro*/
-  0, /*tp_setattro*/
-  &__pyx_tp_as_buffer_RickerMapper, /*tp_as_buffer*/
-  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE, /*tp_flags*/
-  0, /*tp_doc*/
-  0, /*tp_traverse*/
-  0, /*tp_clear*/
-  0, /*tp_richcompare*/
-  0, /*tp_weaklistoffset*/
-  0, /*tp_iter*/
-  0, /*tp_iternext*/
-  __pyx_methods_6ricker_RickerMapper, /*tp_methods*/
-  0, /*tp_members*/
-  0, /*tp_getset*/
-  0, /*tp_base*/
-  0, /*tp_dict*/
-  0, /*tp_descr_get*/
-  0, /*tp_descr_set*/
-  0, /*tp_dictoffset*/
-  0, /*tp_init*/
-  0, /*tp_alloc*/
-  __pyx_tp_new_6ricker_RickerMapper, /*tp_new*/
-  0, /*tp_free*/
-  0, /*tp_is_gc*/
-  0, /*tp_bases*/
-  0, /*tp_mro*/
-  0, /*tp_cache*/
-  0, /*tp_subclasses*/
-  0, /*tp_weaklist*/
-  0, /*tp_del*/
-  #if PY_VERSION_HEX >= 0x02060000
-  0, /*tp_version_tag*/
-  #endif
-};
-
-static PyMethodDef __pyx_methods[] = {
-  {0, 0, 0, 0}
-};
-
-#if PY_MAJOR_VERSION >= 3
-static struct PyModuleDef __pyx_moduledef = {
-    PyModuleDef_HEAD_INIT,
-    __Pyx_NAMESTR("ricker"),
-    0, /* m_doc */
-    -1, /* m_size */
-    __pyx_methods /* m_methods */,
-    NULL, /* m_reload */
-    NULL, /* m_traverse */
-    NULL, /* m_clear */
-    NULL /* m_free */
-};
-#endif
-
-static __Pyx_StringTabEntry __pyx_string_tab[] = {
-  {&__pyx_kp_s_1, __pyx_k_1, sizeof(__pyx_k_1), 0, 0, 1, 0},
-  {&__pyx_n_s____main__, __pyx_k____main__, sizeof(__pyx_k____main__), 0, 0, 1, 1},
-  {&__pyx_n_s____test__, __pyx_k____test__, sizeof(__pyx_k____test__), 0, 0, 1, 1},
-  {0, 0, 0, 0, 0, 0, 0}
-};
-static int __Pyx_InitCachedBuiltins(void) {
-  return 0;
-}
-
-static int __Pyx_InitCachedConstants(void) {
-  __Pyx_RefNannyDeclarations
-  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);
-  __Pyx_RefNannyFinishContext();
-  return 0;
-}
-
-static int __Pyx_InitGlobals(void) {
-  if (__Pyx_InitStrings(__pyx_string_tab) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
-  return 0;
-  __pyx_L1_error:;
-  return -1;
-}
-
-#if PY_MAJOR_VERSION < 3
-PyMODINIT_FUNC initricker(void); /*proto*/
-PyMODINIT_FUNC initricker(void)
-#else
-PyMODINIT_FUNC PyInit_ricker(void); /*proto*/
-PyMODINIT_FUNC PyInit_ricker(void)
-#endif
-{
-  PyObject *__pyx_t_1 = NULL;
-  __Pyx_RefNannyDeclarations
-  #if CYTHON_REFNANNY
-  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
-  if (!__Pyx_RefNanny) {
-      PyErr_Clear();
-      __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
-      if (!__Pyx_RefNanny)
-          Py_FatalError("failed to import 'refnanny' module");
-  }
-  #endif
-  __Pyx_RefNannySetupContext("PyMODINIT_FUNC PyInit_ricker(void)", 0);
-  if ( __Pyx_check_binary_version() < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_empty_tuple)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_bytes)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  #ifdef __Pyx_CyFunction_USED
-  if (__Pyx_CyFunction_init() < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  #endif
-  #ifdef __Pyx_FusedFunction_USED
-  if (__pyx_FusedFunction_init() < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  #endif
-  #ifdef __Pyx_Generator_USED
-  if (__pyx_Generator_init() < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  #endif
-  /*--- Library function declarations ---*/
-  /*--- Threads initialization code ---*/
-  #if defined(__PYX_FORCE_INIT_THREADS) && __PYX_FORCE_INIT_THREADS
-  #ifdef WITH_THREAD /* Python build with threading support? */
-  PyEval_InitThreads();
-  #endif
-  #endif
-  /*--- Module creation code ---*/
-  #if PY_MAJOR_VERSION < 3
-  __pyx_m = Py_InitModule4(__Pyx_NAMESTR("ricker"), __pyx_methods, 0, 0, PYTHON_API_VERSION);
-  #else
-  __pyx_m = PyModule_Create(&__pyx_moduledef);
-  #endif
-  if (!__pyx_m) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
-  #if PY_MAJOR_VERSION < 3
-  Py_INCREF(__pyx_m);
-  #endif
-  __pyx_b = PyImport_AddModule(__Pyx_NAMESTR(__Pyx_BUILTIN_MODULE_NAME));
-  if (!__pyx_b) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
-  if (__Pyx_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
-  /*--- Initialize various global constants etc. ---*/
-  if (unlikely(__Pyx_InitGlobals() < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  if (__pyx_module_is_main_ricker) {
-    if (__Pyx_SetAttrString(__pyx_m, "__name__", __pyx_n_s____main__) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
-  }
-  /*--- Builtin init code ---*/
-  if (unlikely(__Pyx_InitCachedBuiltins() < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  /*--- Constants init code ---*/
-  if (unlikely(__Pyx_InitCachedConstants() < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  /*--- Global init code ---*/
-  /*--- Variable export code ---*/
-  /*--- Function export code ---*/
-  /*--- Type init code ---*/
-  __pyx_ptype_4rads_9enclosure_8cymapper_Mapper = __Pyx_ImportType("rads.enclosure.cymapper", "Mapper", sizeof(struct __pyx_obj_4rads_9enclosure_8cymapper_Mapper), 1); if (unlikely(!__pyx_ptype_4rads_9enclosure_8cymapper_Mapper)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __pyx_vtabptr_4rads_9enclosure_8cymapper_Mapper = (struct __pyx_vtabstruct_4rads_9enclosure_8cymapper_Mapper*)__Pyx_GetVtable(__pyx_ptype_4rads_9enclosure_8cymapper_Mapper->tp_dict); if (unlikely(!__pyx_vtabptr_4rads_9enclosure_8cymapper_Mapper)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __pyx_vtabptr_6ricker_RickerMapper = &__pyx_vtable_6ricker_RickerMapper;
-  __pyx_vtable_6ricker_RickerMapper.__pyx_base = *__pyx_vtabptr_4rads_9enclosure_8cymapper_Mapper;
-  __pyx_type_6ricker_RickerMapper.tp_base = __pyx_ptype_4rads_9enclosure_8cymapper_Mapper;
-  if (PyType_Ready(&__pyx_type_6ricker_RickerMapper) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 11; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  if (__Pyx_SetVtable(__pyx_type_6ricker_RickerMapper.tp_dict, __pyx_vtabptr_6ricker_RickerMapper) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 11; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  if (__Pyx_SetAttrString(__pyx_m, "RickerMapper", (PyObject *)&__pyx_type_6ricker_RickerMapper) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 11; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __pyx_ptype_6ricker_RickerMapper = &__pyx_type_6ricker_RickerMapper;
-  /*--- Type import code ---*/
-  /*--- Variable import code ---*/
-  /*--- Function import code ---*/
-  /*--- Execution code ---*/
-
-  /* "ricker.pyx":1
- * from rads.enclosure.cppdefs cimport *             # <<<<<<<<<<<<<<
- * from rads.enclosure.cymapper cimport Mapper
- * 
- */
-  __pyx_t_1 = PyDict_New(); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __Pyx_GOTREF(((PyObject *)__pyx_t_1));
-  if (PyObject_SetAttr(__pyx_m, __pyx_n_s____test__, ((PyObject *)__pyx_t_1)) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __Pyx_DECREF(((PyObject *)__pyx_t_1)); __pyx_t_1 = 0;
-  goto __pyx_L0;
-  __pyx_L1_error:;
-  __Pyx_XDECREF(__pyx_t_1);
-  if (__pyx_m) {
-    __Pyx_AddTraceback("init ricker", __pyx_clineno, __pyx_lineno, __pyx_filename);
-    Py_DECREF(__pyx_m); __pyx_m = 0;
-  } else if (!PyErr_Occurred()) {
-    PyErr_SetString(PyExc_ImportError, "init ricker");
-  }
-  __pyx_L0:;
-  __Pyx_RefNannyFinishContext();
-  #if PY_MAJOR_VERSION < 3
-  return;
-  #else
-  return __pyx_m;
-  #endif
-}
-
-/* Runtime support code */
-#if CYTHON_REFNANNY
-static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
-    PyObject *m = NULL, *p = NULL;
-    void *r = NULL;
-    m = PyImport_ImportModule((char *)modname);
-    if (!m) goto end;
-    p = PyObject_GetAttrString(m, (char *)"RefNannyAPI");
-    if (!p) goto end;
-    r = PyLong_AsVoidPtr(p);
-end:
-    Py_XDECREF(p);
-    Py_XDECREF(m);
-    return (__Pyx_RefNannyAPIStruct *)r;
-}
-#endif /* CYTHON_REFNANNY */
-
-static void __Pyx_RaiseArgtupleInvalid(
-    const char* func_name,
-    int exact,
-    Py_ssize_t num_min,
-    Py_ssize_t num_max,
-    Py_ssize_t num_found)
-{
-    Py_ssize_t num_expected;
-    const char *more_or_less;
-    if (num_found < num_min) {
-        num_expected = num_min;
-        more_or_less = "at least";
-    } else {
-        num_expected = num_max;
-        more_or_less = "at most";
-    }
-    if (exact) {
-        more_or_less = "exactly";
-    }
-    PyErr_Format(PyExc_TypeError,
-                 "%s() takes %s %"PY_FORMAT_SIZE_T"d positional argument%s (%"PY_FORMAT_SIZE_T"d given)",
-                 func_name, more_or_less, num_expected,
-                 (num_expected == 1) ? "" : "s", num_found);
-}
-
-static CYTHON_INLINE int __Pyx_CheckKeywordStrings(
-    PyObject *kwdict,
-    const char* function_name,
-    int kw_allowed)
-{
-    PyObject* key = 0;
-    Py_ssize_t pos = 0;
-    while (PyDict_Next(kwdict, &pos, &key, 0)) {
-        #if PY_MAJOR_VERSION < 3
-        if (unlikely(!PyString_CheckExact(key)) && unlikely(!PyString_Check(key)))
-        #else
-        if (unlikely(!PyUnicode_Check(key)))
-        #endif
-            goto invalid_keyword_type;
-    }
-    if ((!kw_allowed) && unlikely(key))
-        goto invalid_keyword;
-    return 1;
-invalid_keyword_type:
-    PyErr_Format(PyExc_TypeError,
-        "%s() keywords must be strings", function_name);
-    return 0;
-invalid_keyword:
-    PyErr_Format(PyExc_TypeError,
-    #if PY_MAJOR_VERSION < 3
-        "%s() got an unexpected keyword argument '%s'",
-        function_name, PyString_AsString(key));
-    #else
-        "%s() got an unexpected keyword argument '%U'",
-        function_name, key);
-    #endif
-    return 0;
-}
-
-#if PY_MAJOR_VERSION < 3
-static PyObject *__Pyx_GetStdout(void) {
-    PyObject *f = PySys_GetObject((char *)"stdout");
-    if (!f) {
-        PyErr_SetString(PyExc_RuntimeError, "lost sys.stdout");
-    }
-    return f;
-}
-static int __Pyx_Print(PyObject* f, PyObject *arg_tuple, int newline) {
-    PyObject* v;
-    int i;
-    if (!f) {
-        if (!(f = __Pyx_GetStdout()))
-            return -1;
-    }
-    for (i=0; i < PyTuple_GET_SIZE(arg_tuple); i++) {
-        if (PyFile_SoftSpace(f, 1)) {
-            if (PyFile_WriteString(" ", f) < 0)
-                return -1;
-        }
-        v = PyTuple_GET_ITEM(arg_tuple, i);
-        if (PyFile_WriteObject(v, f, Py_PRINT_RAW) < 0)
-            return -1;
-        if (PyString_Check(v)) {
-            char *s = PyString_AsString(v);
-            Py_ssize_t len = PyString_Size(v);
-            if (len > 0 &&
-                isspace(Py_CHARMASK(s[len-1])) &&
-                s[len-1] != ' ')
-                    PyFile_SoftSpace(f, 0);
-        }
-    }
-    if (newline) {
-        if (PyFile_WriteString("\n", f) < 0)
-            return -1;
-        PyFile_SoftSpace(f, 0);
-    }
-    return 0;
-}
-#else /* Python 3 has a print function */
-static int __Pyx_Print(PyObject* stream, PyObject *arg_tuple, int newline) {
-    PyObject* kwargs = 0;
-    PyObject* result = 0;
-    PyObject* end_string;
-    if (unlikely(!__pyx_print)) {
-        __pyx_print = __Pyx_GetAttrString(__pyx_b, "print");
-        if (!__pyx_print)
-            return -1;
-    }
-    if (stream) {
-        kwargs = PyDict_New();
-        if (unlikely(!kwargs))
-            return -1;
-        if (unlikely(PyDict_SetItemString(kwargs, "file", stream) < 0))
-            goto bad;
-        if (!newline) {
-            end_string = PyUnicode_FromStringAndSize(" ", 1);
-            if (unlikely(!end_string))
-                goto bad;
-            if (PyDict_SetItemString(kwargs, "end", end_string) < 0) {
-                Py_DECREF(end_string);
-                goto bad;
-            }
-            Py_DECREF(end_string);
-        }
-    } else if (!newline) {
-        if (unlikely(!__pyx_print_kwargs)) {
-            __pyx_print_kwargs = PyDict_New();
-            if (unlikely(!__pyx_print_kwargs))
-                return -1;
-            end_string = PyUnicode_FromStringAndSize(" ", 1);
-            if (unlikely(!end_string))
-                return -1;
-            if (PyDict_SetItemString(__pyx_print_kwargs, "end", end_string) < 0) {
-                Py_DECREF(end_string);
-                return -1;
-            }
-            Py_DECREF(end_string);
-        }
-        kwargs = __pyx_print_kwargs;
-    }
-    result = PyObject_Call(__pyx_print, arg_tuple, kwargs);
-    if (unlikely(kwargs) && (kwargs != __pyx_print_kwargs))
-        Py_DECREF(kwargs);
-    if (!result)
-        return -1;
-    Py_DECREF(result);
-    return 0;
-bad:
-    if (kwargs != __pyx_print_kwargs)
-        Py_XDECREF(kwargs);
-    return -1;
-}
-#endif
-
-#if PY_MAJOR_VERSION < 3
-static int __Pyx_PrintOne(PyObject* f, PyObject *o) {
-    if (!f) {
-        if (!(f = __Pyx_GetStdout()))
-            return -1;
-    }
-    if (PyFile_SoftSpace(f, 0)) {
-        if (PyFile_WriteString(" ", f) < 0)
-            return -1;
-    }
-    if (PyFile_WriteObject(o, f, Py_PRINT_RAW) < 0)
-        return -1;
-    if (PyFile_WriteString("\n", f) < 0)
-        return -1;
-    return 0;
-    /* the line below is just to avoid compiler
-     * compiler warnings about unused functions */
-    return __Pyx_Print(f, NULL, 0);
-}
-#else /* Python 3 has a print function */
-static int __Pyx_PrintOne(PyObject* stream, PyObject *o) {
-    int res;
-    PyObject* arg_tuple = PyTuple_New(1);
-    if (unlikely(!arg_tuple))
-        return -1;
-    Py_INCREF(o);
-    PyTuple_SET_ITEM(arg_tuple, 0, o);
-    res = __Pyx_Print(stream, arg_tuple, 1);
-    Py_DECREF(arg_tuple);
-    return res;
-}
-#endif
-
-static CYTHON_INLINE unsigned char __Pyx_PyInt_AsUnsignedChar(PyObject* x) {
-    const unsigned char neg_one = (unsigned char)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(unsigned char) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(unsigned char)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to unsigned char" :
-                    "value too large to convert to unsigned char");
-            }
-            return (unsigned char)-1;
-        }
-        return (unsigned char)val;
-    }
-    return (unsigned char)__Pyx_PyInt_AsUnsignedLong(x);
-}
-
-static CYTHON_INLINE unsigned short __Pyx_PyInt_AsUnsignedShort(PyObject* x) {
-    const unsigned short neg_one = (unsigned short)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(unsigned short) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(unsigned short)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to unsigned short" :
-                    "value too large to convert to unsigned short");
-            }
-            return (unsigned short)-1;
-        }
-        return (unsigned short)val;
-    }
-    return (unsigned short)__Pyx_PyInt_AsUnsignedLong(x);
-}
-
-static CYTHON_INLINE unsigned int __Pyx_PyInt_AsUnsignedInt(PyObject* x) {
-    const unsigned int neg_one = (unsigned int)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(unsigned int) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(unsigned int)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to unsigned int" :
-                    "value too large to convert to unsigned int");
-            }
-            return (unsigned int)-1;
-        }
-        return (unsigned int)val;
-    }
-    return (unsigned int)__Pyx_PyInt_AsUnsignedLong(x);
-}
-
-static CYTHON_INLINE char __Pyx_PyInt_AsChar(PyObject* x) {
-    const char neg_one = (char)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(char) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(char)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to char" :
-                    "value too large to convert to char");
-            }
-            return (char)-1;
-        }
-        return (char)val;
-    }
-    return (char)__Pyx_PyInt_AsLong(x);
-}
-
-static CYTHON_INLINE short __Pyx_PyInt_AsShort(PyObject* x) {
-    const short neg_one = (short)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(short) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(short)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to short" :
-                    "value too large to convert to short");
-            }
-            return (short)-1;
-        }
-        return (short)val;
-    }
-    return (short)__Pyx_PyInt_AsLong(x);
-}
-
-static CYTHON_INLINE int __Pyx_PyInt_AsInt(PyObject* x) {
-    const int neg_one = (int)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(int) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(int)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to int" :
-                    "value too large to convert to int");
-            }
-            return (int)-1;
-        }
-        return (int)val;
-    }
-    return (int)__Pyx_PyInt_AsLong(x);
-}
-
-static CYTHON_INLINE signed char __Pyx_PyInt_AsSignedChar(PyObject* x) {
-    const signed char neg_one = (signed char)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(signed char) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(signed char)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to signed char" :
-                    "value too large to convert to signed char");
-            }
-            return (signed char)-1;
-        }
-        return (signed char)val;
-    }
-    return (signed char)__Pyx_PyInt_AsSignedLong(x);
-}
-
-static CYTHON_INLINE signed short __Pyx_PyInt_AsSignedShort(PyObject* x) {
-    const signed short neg_one = (signed short)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(signed short) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(signed short)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to signed short" :
-                    "value too large to convert to signed short");
-            }
-            return (signed short)-1;
-        }
-        return (signed short)val;
-    }
-    return (signed short)__Pyx_PyInt_AsSignedLong(x);
-}
-
-static CYTHON_INLINE signed int __Pyx_PyInt_AsSignedInt(PyObject* x) {
-    const signed int neg_one = (signed int)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(signed int) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(signed int)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to signed int" :
-                    "value too large to convert to signed int");
-            }
-            return (signed int)-1;
-        }
-        return (signed int)val;
-    }
-    return (signed int)__Pyx_PyInt_AsSignedLong(x);
-}
-
-static CYTHON_INLINE int __Pyx_PyInt_AsLongDouble(PyObject* x) {
-    const int neg_one = (int)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(int) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(int)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to int" :
-                    "value too large to convert to int");
-            }
-            return (int)-1;
-        }
-        return (int)val;
-    }
-    return (int)__Pyx_PyInt_AsLong(x);
-}
-
-static CYTHON_INLINE unsigned long __Pyx_PyInt_AsUnsignedLong(PyObject* x) {
-    const unsigned long neg_one = (unsigned long)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-#if PY_VERSION_HEX < 0x03000000
-    if (likely(PyInt_Check(x))) {
-        long val = PyInt_AS_LONG(x);
-        if (is_unsigned && unlikely(val < 0)) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "can't convert negative value to unsigned long");
-            return (unsigned long)-1;
-        }
-        return (unsigned long)val;
-    } else
-#endif
-    if (likely(PyLong_Check(x))) {
-        if (is_unsigned) {
-            if (unlikely(Py_SIZE(x) < 0)) {
-                PyErr_SetString(PyExc_OverflowError,
-                                "can't convert negative value to unsigned long");
-                return (unsigned long)-1;
-            }
-            return (unsigned long)PyLong_AsUnsignedLong(x);
-        } else {
-            return (unsigned long)PyLong_AsLong(x);
-        }
-    } else {
-        unsigned long val;
-        PyObject *tmp = __Pyx_PyNumber_Int(x);
-        if (!tmp) return (unsigned long)-1;
-        val = __Pyx_PyInt_AsUnsignedLong(tmp);
-        Py_DECREF(tmp);
-        return val;
-    }
-}
-
-static CYTHON_INLINE unsigned PY_LONG_LONG __Pyx_PyInt_AsUnsignedLongLong(PyObject* x) {
-    const unsigned PY_LONG_LONG neg_one = (unsigned PY_LONG_LONG)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-#if PY_VERSION_HEX < 0x03000000
-    if (likely(PyInt_Check(x))) {
-        long val = PyInt_AS_LONG(x);
-        if (is_unsigned && unlikely(val < 0)) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "can't convert negative value to unsigned PY_LONG_LONG");
-            return (unsigned PY_LONG_LONG)-1;
-        }
-        return (unsigned PY_LONG_LONG)val;
-    } else
-#endif
-    if (likely(PyLong_Check(x))) {
-        if (is_unsigned) {
-            if (unlikely(Py_SIZE(x) < 0)) {
-                PyErr_SetString(PyExc_OverflowError,
-                                "can't convert negative value to unsigned PY_LONG_LONG");
-                return (unsigned PY_LONG_LONG)-1;
-            }
-            return (unsigned PY_LONG_LONG)PyLong_AsUnsignedLongLong(x);
-        } else {
-            return (unsigned PY_LONG_LONG)PyLong_AsLongLong(x);
-        }
-    } else {
-        unsigned PY_LONG_LONG val;
-        PyObject *tmp = __Pyx_PyNumber_Int(x);
-        if (!tmp) return (unsigned PY_LONG_LONG)-1;
-        val = __Pyx_PyInt_AsUnsignedLongLong(tmp);
-        Py_DECREF(tmp);
-        return val;
-    }
-}
-
-static CYTHON_INLINE long __Pyx_PyInt_AsLong(PyObject* x) {
-    const long neg_one = (long)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-#if PY_VERSION_HEX < 0x03000000
-    if (likely(PyInt_Check(x))) {
-        long val = PyInt_AS_LONG(x);
-        if (is_unsigned && unlikely(val < 0)) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "can't convert negative value to long");
-            return (long)-1;
-        }
-        return (long)val;
-    } else
-#endif
-    if (likely(PyLong_Check(x))) {
-        if (is_unsigned) {
-            if (unlikely(Py_SIZE(x) < 0)) {
-                PyErr_SetString(PyExc_OverflowError,
-                                "can't convert negative value to long");
-                return (long)-1;
-            }
-            return (long)PyLong_AsUnsignedLong(x);
-        } else {
-            return (long)PyLong_AsLong(x);
-        }
-    } else {
-        long val;
-        PyObject *tmp = __Pyx_PyNumber_Int(x);
-        if (!tmp) return (long)-1;
-        val = __Pyx_PyInt_AsLong(tmp);
-        Py_DECREF(tmp);
-        return val;
-    }
-}
-
-static CYTHON_INLINE PY_LONG_LONG __Pyx_PyInt_AsLongLong(PyObject* x) {
-    const PY_LONG_LONG neg_one = (PY_LONG_LONG)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-#if PY_VERSION_HEX < 0x03000000
-    if (likely(PyInt_Check(x))) {
-        long val = PyInt_AS_LONG(x);
-        if (is_unsigned && unlikely(val < 0)) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "can't convert negative value to PY_LONG_LONG");
-            return (PY_LONG_LONG)-1;
-        }
-        return (PY_LONG_LONG)val;
-    } else
-#endif
-    if (likely(PyLong_Check(x))) {
-        if (is_unsigned) {
-            if (unlikely(Py_SIZE(x) < 0)) {
-                PyErr_SetString(PyExc_OverflowError,
-                                "can't convert negative value to PY_LONG_LONG");
-                return (PY_LONG_LONG)-1;
-            }
-            return (PY_LONG_LONG)PyLong_AsUnsignedLongLong(x);
-        } else {
-            return (PY_LONG_LONG)PyLong_AsLongLong(x);
-        }
-    } else {
-        PY_LONG_LONG val;
-        PyObject *tmp = __Pyx_PyNumber_Int(x);
-        if (!tmp) return (PY_LONG_LONG)-1;
-        val = __Pyx_PyInt_AsLongLong(tmp);
-        Py_DECREF(tmp);
-        return val;
-    }
-}
-
-static CYTHON_INLINE signed long __Pyx_PyInt_AsSignedLong(PyObject* x) {
-    const signed long neg_one = (signed long)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-#if PY_VERSION_HEX < 0x03000000
-    if (likely(PyInt_Check(x))) {
-        long val = PyInt_AS_LONG(x);
-        if (is_unsigned && unlikely(val < 0)) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "can't convert negative value to signed long");
-            return (signed long)-1;
-        }
-        return (signed long)val;
-    } else
-#endif
-    if (likely(PyLong_Check(x))) {
-        if (is_unsigned) {
-            if (unlikely(Py_SIZE(x) < 0)) {
-                PyErr_SetString(PyExc_OverflowError,
-                                "can't convert negative value to signed long");
-                return (signed long)-1;
-            }
-            return (signed long)PyLong_AsUnsignedLong(x);
-        } else {
-            return (signed long)PyLong_AsLong(x);
-        }
-    } else {
-        signed long val;
-        PyObject *tmp = __Pyx_PyNumber_Int(x);
-        if (!tmp) return (signed long)-1;
-        val = __Pyx_PyInt_AsSignedLong(tmp);
-        Py_DECREF(tmp);
-        return val;
-    }
-}
-
-static CYTHON_INLINE signed PY_LONG_LONG __Pyx_PyInt_AsSignedLongLong(PyObject* x) {
-    const signed PY_LONG_LONG neg_one = (signed PY_LONG_LONG)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-#if PY_VERSION_HEX < 0x03000000
-    if (likely(PyInt_Check(x))) {
-        long val = PyInt_AS_LONG(x);
-        if (is_unsigned && unlikely(val < 0)) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "can't convert negative value to signed PY_LONG_LONG");
-            return (signed PY_LONG_LONG)-1;
-        }
-        return (signed PY_LONG_LONG)val;
-    } else
-#endif
-    if (likely(PyLong_Check(x))) {
-        if (is_unsigned) {
-            if (unlikely(Py_SIZE(x) < 0)) {
-                PyErr_SetString(PyExc_OverflowError,
-                                "can't convert negative value to signed PY_LONG_LONG");
-                return (signed PY_LONG_LONG)-1;
-            }
-            return (signed PY_LONG_LONG)PyLong_AsUnsignedLongLong(x);
-        } else {
-            return (signed PY_LONG_LONG)PyLong_AsLongLong(x);
-        }
-    } else {
-        signed PY_LONG_LONG val;
-        PyObject *tmp = __Pyx_PyNumber_Int(x);
-        if (!tmp) return (signed PY_LONG_LONG)-1;
-        val = __Pyx_PyInt_AsSignedLongLong(tmp);
-        Py_DECREF(tmp);
-        return val;
-    }
-}
-
-static int __Pyx_check_binary_version(void) {
-    char ctversion[4], rtversion[4];
-    PyOS_snprintf(ctversion, 4, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
-    PyOS_snprintf(rtversion, 4, "%s", Py_GetVersion());
-    if (ctversion[0] != rtversion[0] || ctversion[2] != rtversion[2]) {
-        char message[200];
-        PyOS_snprintf(message, sizeof(message),
-                      "compiletime version %s of module '%.100s' "
-                      "does not match runtime version %s",
-                      ctversion, __Pyx_MODULE_NAME, rtversion);
-        #if PY_VERSION_HEX < 0x02050000
-        return PyErr_Warn(NULL, message);
-        #else
-        return PyErr_WarnEx(NULL, message, 1);
-        #endif
-    }
-    return 0;
-}
-
-#ifndef __PYX_HAVE_RT_ImportType
-#define __PYX_HAVE_RT_ImportType
-static PyTypeObject *__Pyx_ImportType(const char *module_name, const char *class_name,
-    size_t size, int strict)
-{
-    PyObject *py_module = 0;
-    PyObject *result = 0;
-    PyObject *py_name = 0;
-    char warning[200];
-    py_module = __Pyx_ImportModule(module_name);
-    if (!py_module)
-        goto bad;
-    py_name = __Pyx_PyIdentifier_FromString(class_name);
-    if (!py_name)
-        goto bad;
-    result = PyObject_GetAttr(py_module, py_name);
-    Py_DECREF(py_name);
-    py_name = 0;
-    Py_DECREF(py_module);
-    py_module = 0;
-    if (!result)
-        goto bad;
-    if (!PyType_Check(result)) {
-        PyErr_Format(PyExc_TypeError,
-            "%s.%s is not a type object",
-            module_name, class_name);
-        goto bad;
-    }
-    if (!strict && (size_t)((PyTypeObject *)result)->tp_basicsize > size) {
-        PyOS_snprintf(warning, sizeof(warning),
-            "%s.%s size changed, may indicate binary incompatibility",
-            module_name, class_name);
-        #if PY_VERSION_HEX < 0x02050000
-        if (PyErr_Warn(NULL, warning) < 0) goto bad;
-        #else
-        if (PyErr_WarnEx(NULL, warning, 0) < 0) goto bad;
-        #endif
-    }
-    else if ((size_t)((PyTypeObject *)result)->tp_basicsize != size) {
-        PyErr_Format(PyExc_ValueError,
-            "%s.%s has the wrong size, try recompiling",
-            module_name, class_name);
-        goto bad;
-    }
-    return (PyTypeObject *)result;
-bad:
-    Py_XDECREF(py_module);
-    Py_XDECREF(result);
-    return NULL;
-}
-#endif
-
-#ifndef __PYX_HAVE_RT_ImportModule
-#define __PYX_HAVE_RT_ImportModule
-static PyObject *__Pyx_ImportModule(const char *name) {
-    PyObject *py_name = 0;
-    PyObject *py_module = 0;
-    py_name = __Pyx_PyIdentifier_FromString(name);
-    if (!py_name)
-        goto bad;
-    py_module = PyImport_Import(py_name);
-    Py_DECREF(py_name);
-    return py_module;
-bad:
-    Py_XDECREF(py_name);
-    return 0;
-}
-#endif
-
-static void* __Pyx_GetVtable(PyObject *dict) {
-    void* ptr;
-    PyObject *ob = PyMapping_GetItemString(dict, (char *)"__pyx_vtable__");
-    if (!ob)
-        goto bad;
-#if PY_VERSION_HEX >= 0x02070000 && !(PY_MAJOR_VERSION==3&&PY_MINOR_VERSION==0)
-    ptr = PyCapsule_GetPointer(ob, 0);
-#else
-    ptr = PyCObject_AsVoidPtr(ob);
-#endif
-    if (!ptr && !PyErr_Occurred())
-        PyErr_SetString(PyExc_RuntimeError, "invalid vtable found for imported type");
-    Py_DECREF(ob);
-    return ptr;
-bad:
-    Py_XDECREF(ob);
-    return NULL;
-}
-
-static int __Pyx_SetVtable(PyObject *dict, void *vtable) {
-#if PY_VERSION_HEX >= 0x02070000 && !(PY_MAJOR_VERSION==3&&PY_MINOR_VERSION==0)
-    PyObject *ob = PyCapsule_New(vtable, 0, 0);
-#else
-    PyObject *ob = PyCObject_FromVoidPtr(vtable, 0);
-#endif
-    if (!ob)
-        goto bad;
-    if (PyDict_SetItemString(dict, "__pyx_vtable__", ob) < 0)
-        goto bad;
-    Py_DECREF(ob);
-    return 0;
-bad:
-    Py_XDECREF(ob);
-    return -1;
-}
-
-static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
-    int start = 0, mid = 0, end = count - 1;
-    if (end >= 0 && code_line > entries[end].code_line) {
-        return count;
-    }
-    while (start < end) {
-        mid = (start + end) / 2;
-        if (code_line < entries[mid].code_line) {
-            end = mid;
-        } else if (code_line > entries[mid].code_line) {
-             start = mid + 1;
-        } else {
-            return mid;
-        }
-    }
-    if (code_line <= entries[mid].code_line) {
-        return mid;
-    } else {
-        return mid + 1;
-    }
-}
-static PyCodeObject *__pyx_find_code_object(int code_line) {
-    PyCodeObject* code_object;
-    int pos;
-    if (unlikely(!code_line) || unlikely(!__pyx_code_cache.entries)) {
-        return NULL;
-    }
-    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
-    if (unlikely(pos >= __pyx_code_cache.count) || unlikely(__pyx_code_cache.entries[pos].code_line != code_line)) {
-        return NULL;
-    }
-    code_object = __pyx_code_cache.entries[pos].code_object;
-    Py_INCREF(code_object);
-    return code_object;
-}
-static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object) {
-    int pos, i;
-    __Pyx_CodeObjectCacheEntry* entries = __pyx_code_cache.entries;
-    if (unlikely(!code_line)) {
-        return;
-    }
-    if (unlikely(!entries)) {
-        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
-        if (likely(entries)) {
-            __pyx_code_cache.entries = entries;
-            __pyx_code_cache.max_count = 64;
-            __pyx_code_cache.count = 1;
-            entries[0].code_line = code_line;
-            entries[0].code_object = code_object;
-            Py_INCREF(code_object);
-        }
-        return;
-    }
-    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
-    if ((pos < __pyx_code_cache.count) && unlikely(__pyx_code_cache.entries[pos].code_line == code_line)) {
-        PyCodeObject* tmp = entries[pos].code_object;
-        entries[pos].code_object = code_object;
-        Py_DECREF(tmp);
-        return;
-    }
-    if (__pyx_code_cache.count == __pyx_code_cache.max_count) {
-        int new_max = __pyx_code_cache.max_count + 64;
-        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
-            __pyx_code_cache.entries, new_max*sizeof(__Pyx_CodeObjectCacheEntry));
-        if (unlikely(!entries)) {
-            return;
-        }
-        __pyx_code_cache.entries = entries;
-        __pyx_code_cache.max_count = new_max;
-    }
-    for (i=__pyx_code_cache.count; i>pos; i--) {
-        entries[i] = entries[i-1];
-    }
-    entries[pos].code_line = code_line;
-    entries[pos].code_object = code_object;
-    __pyx_code_cache.count++;
-    Py_INCREF(code_object);
-}
-
-#include "compile.h"
-#include "frameobject.h"
-#include "traceback.h"
-static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
-            const char *funcname, int c_line,
-            int py_line, const char *filename) {
-    PyCodeObject *py_code = 0;
-    PyObject *py_srcfile = 0;
-    PyObject *py_funcname = 0;
-    #if PY_MAJOR_VERSION < 3
-    py_srcfile = PyString_FromString(filename);
-    #else
-    py_srcfile = PyUnicode_FromString(filename);
-    #endif
-    if (!py_srcfile) goto bad;
-    if (c_line) {
-        #if PY_MAJOR_VERSION < 3
-        py_funcname = PyString_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
-        #else
-        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
-        #endif
-    }
-    else {
-        #if PY_MAJOR_VERSION < 3
-        py_funcname = PyString_FromString(funcname);
-        #else
-        py_funcname = PyUnicode_FromString(funcname);
-        #endif
-    }
-    if (!py_funcname) goto bad;
-    py_code = __Pyx_PyCode_New(
-        0,            /*int argcount,*/
-        0,            /*int kwonlyargcount,*/
-        0,            /*int nlocals,*/
-        0,            /*int stacksize,*/
-        0,            /*int flags,*/
-        __pyx_empty_bytes, /*PyObject *code,*/
-        __pyx_empty_tuple, /*PyObject *consts,*/
-        __pyx_empty_tuple, /*PyObject *names,*/
-        __pyx_empty_tuple, /*PyObject *varnames,*/
-        __pyx_empty_tuple, /*PyObject *freevars,*/
-        __pyx_empty_tuple, /*PyObject *cellvars,*/
-        py_srcfile,   /*PyObject *filename,*/
-        py_funcname,  /*PyObject *name,*/
-        py_line,      /*int firstlineno,*/
-        __pyx_empty_bytes  /*PyObject *lnotab*/
-    );
-    Py_DECREF(py_srcfile);
-    Py_DECREF(py_funcname);
-    return py_code;
-bad:
-    Py_XDECREF(py_srcfile);
-    Py_XDECREF(py_funcname);
-    return NULL;
-}
-static void __Pyx_AddTraceback(const char *funcname, int c_line,
-                               int py_line, const char *filename) {
-    PyCodeObject *py_code = 0;
-    PyObject *py_globals = 0;
-    PyFrameObject *py_frame = 0;
-    py_code = __pyx_find_code_object(c_line ? c_line : py_line);
-    if (!py_code) {
-        py_code = __Pyx_CreateCodeObjectForTraceback(
-            funcname, c_line, py_line, filename);
-        if (!py_code) goto bad;
-        __pyx_insert_code_object(c_line ? c_line : py_line, py_code);
-    }
-    py_globals = PyModule_GetDict(__pyx_m);
-    if (!py_globals) goto bad;
-    py_frame = PyFrame_New(
-        PyThreadState_GET(), /*PyThreadState *tstate,*/
-        py_code,             /*PyCodeObject *code,*/
-        py_globals,          /*PyObject *globals,*/
-        0                    /*PyObject *locals*/
-    );
-    if (!py_frame) goto bad;
-    py_frame->f_lineno = py_line;
-    PyTraceBack_Here(py_frame);
-bad:
-    Py_XDECREF(py_code);
-    Py_XDECREF(py_frame);
-}
-
-static int __Pyx_InitStrings(__Pyx_StringTabEntry *t) {
-    while (t->p) {
-        #if PY_MAJOR_VERSION < 3
-        if (t->is_unicode) {
-            *t->p = PyUnicode_DecodeUTF8(t->s, t->n - 1, NULL);
-        } else if (t->intern) {
-            *t->p = PyString_InternFromString(t->s);
-        } else {
-            *t->p = PyString_FromStringAndSize(t->s, t->n - 1);
-        }
-        #else  /* Python 3+ has unicode identifiers */
-        if (t->is_unicode | t->is_str) {
-            if (t->intern) {
-                *t->p = PyUnicode_InternFromString(t->s);
-            } else if (t->encoding) {
-                *t->p = PyUnicode_Decode(t->s, t->n - 1, t->encoding, NULL);
-            } else {
-                *t->p = PyUnicode_FromStringAndSize(t->s, t->n - 1);
-            }
-        } else {
-            *t->p = PyBytes_FromStringAndSize(t->s, t->n - 1);
-        }
-        #endif
-        if (!*t->p)
-            return -1;
-        ++t;
-    }
-    return 0;
-}
-
-
-/* Type Conversion Functions */
-
-static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
-   int is_true = x == Py_True;
-   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
-   else return PyObject_IsTrue(x);
-}
-
-static CYTHON_INLINE PyObject* __Pyx_PyNumber_Int(PyObject* x) {
-  PyNumberMethods *m;
-  const char *name = NULL;
-  PyObject *res = NULL;
-#if PY_VERSION_HEX < 0x03000000
-  if (PyInt_Check(x) || PyLong_Check(x))
-#else
-  if (PyLong_Check(x))
-#endif
-    return Py_INCREF(x), x;
-  m = Py_TYPE(x)->tp_as_number;
-#if PY_VERSION_HEX < 0x03000000
-  if (m && m->nb_int) {
-    name = "int";
-    res = PyNumber_Int(x);
-  }
-  else if (m && m->nb_long) {
-    name = "long";
-    res = PyNumber_Long(x);
-  }
-#else
-  if (m && m->nb_int) {
-    name = "int";
-    res = PyNumber_Long(x);
-  }
-#endif
-  if (res) {
-#if PY_VERSION_HEX < 0x03000000
-    if (!PyInt_Check(res) && !PyLong_Check(res)) {
-#else
-    if (!PyLong_Check(res)) {
-#endif
-      PyErr_Format(PyExc_TypeError,
-                   "__%s__ returned non-%s (type %.200s)",
-                   name, name, Py_TYPE(res)->tp_name);
-      Py_DECREF(res);
-      return NULL;
-    }
-  }
-  else if (!PyErr_Occurred()) {
-    PyErr_SetString(PyExc_TypeError,
-                    "an integer is required");
-  }
-  return res;
-}
-
-static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
-  Py_ssize_t ival;
-  PyObject* x = PyNumber_Index(b);
-  if (!x) return -1;
-  ival = PyInt_AsSsize_t(x);
-  Py_DECREF(x);
-  return ival;
-}
-
-static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t ival) {
-#if PY_VERSION_HEX < 0x02050000
-   if (ival <= LONG_MAX)
-       return PyInt_FromLong((long)ival);
-   else {
-       unsigned char *bytes = (unsigned char *) &ival;
-       int one = 1; int little = (int)*(unsigned char*)&one;
-       return _PyLong_FromByteArray(bytes, sizeof(size_t), little, 0);
-   }
-#else
-   return PyInt_FromSize_t(ival);
-#endif
-}
-
-static CYTHON_INLINE size_t __Pyx_PyInt_AsSize_t(PyObject* x) {
-   unsigned PY_LONG_LONG val = __Pyx_PyInt_AsUnsignedLongLong(x);
-   if (unlikely(val == (unsigned PY_LONG_LONG)-1 && PyErr_Occurred())) {
-       return (size_t)-1;
-   } else if (unlikely(val != (unsigned PY_LONG_LONG)(size_t)val)) {
-       PyErr_SetString(PyExc_OverflowError,
-                       "value too large to convert to size_t");
-       return (size_t)-1;
-   }
-   return (size_t)val;
-}
-
-
-#endif /* Py_PYTHON_H */
diff --git a/sandbox/ricker.cpp b/sandbox/ricker.cpp
deleted file mode 100644
index fecefc3..0000000
--- a/sandbox/ricker.cpp
+++ /dev/null
@@ -1,2022 +0,0 @@
-/* Generated by Cython 0.16 on Tue Mar 26 16:29:07 2013 */
-
-#define PY_SSIZE_T_CLEAN
-#include "Python.h"
-#ifndef Py_PYTHON_H
-    #error Python headers needed to compile C extensions, please install development version of Python.
-#elif PY_VERSION_HEX < 0x02040000
-    #error Cython requires Python 2.4+.
-#else
-#include <stddef.h> /* For offsetof */
-#ifndef offsetof
-#define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
-#endif
-
-#if !defined(WIN32) && !defined(MS_WINDOWS)
-  #ifndef __stdcall
-    #define __stdcall
-  #endif
-  #ifndef __cdecl
-    #define __cdecl
-  #endif
-  #ifndef __fastcall
-    #define __fastcall
-  #endif
-#endif
-
-#ifndef DL_IMPORT
-  #define DL_IMPORT(t) t
-#endif
-#ifndef DL_EXPORT
-  #define DL_EXPORT(t) t
-#endif
-
-#ifndef PY_LONG_LONG
-  #define PY_LONG_LONG LONG_LONG
-#endif
-
-#ifndef Py_HUGE_VAL
-  #define Py_HUGE_VAL HUGE_VAL
-#endif
-
-#ifdef PYPY_VERSION
-#define CYTHON_COMPILING_IN_PYPY 1
-#define CYTHON_COMPILING_IN_CPYTHON 0
-#else
-#define CYTHON_COMPILING_IN_PYPY 0
-#define CYTHON_COMPILING_IN_CPYTHON 1
-#endif
-
-#if CYTHON_COMPILING_IN_PYPY
-  #define __Pyx_PyCFunction_Call PyObject_Call
-#else
-  #define __Pyx_PyCFunction_Call PyCFunction_Call
-#endif
-
-#if PY_VERSION_HEX < 0x02050000
-  typedef int Py_ssize_t;
-  #define PY_SSIZE_T_MAX INT_MAX
-  #define PY_SSIZE_T_MIN INT_MIN
-  #define PY_FORMAT_SIZE_T ""
-  #define PyInt_FromSsize_t(z) PyInt_FromLong(z)
-  #define PyInt_AsSsize_t(o)   __Pyx_PyInt_AsInt(o)
-  #define PyNumber_Index(o)    PyNumber_Int(o)
-  #define PyIndex_Check(o)     PyNumber_Check(o)
-  #define PyErr_WarnEx(category, message, stacklevel) PyErr_Warn(category, message)
-  #define __PYX_BUILD_PY_SSIZE_T "i"
-#else
-  #define __PYX_BUILD_PY_SSIZE_T "n"
-#endif
-
-#if PY_VERSION_HEX < 0x02060000
-  #define Py_REFCNT(ob) (((PyObject*)(ob))->ob_refcnt)
-  #define Py_TYPE(ob)   (((PyObject*)(ob))->ob_type)
-  #define Py_SIZE(ob)   (((PyVarObject*)(ob))->ob_size)
-  #define PyVarObject_HEAD_INIT(type, size) \
-          PyObject_HEAD_INIT(type) size,
-  #define PyType_Modified(t)
-
-  typedef struct {
-     void *buf;
-     PyObject *obj;
-     Py_ssize_t len;
-     Py_ssize_t itemsize;
-     int readonly;
-     int ndim;
-     char *format;
-     Py_ssize_t *shape;
-     Py_ssize_t *strides;
-     Py_ssize_t *suboffsets;
-     void *internal;
-  } Py_buffer;
-
-  #define PyBUF_SIMPLE 0
-  #define PyBUF_WRITABLE 0x0001
-  #define PyBUF_FORMAT 0x0004
-  #define PyBUF_ND 0x0008
-  #define PyBUF_STRIDES (0x0010 | PyBUF_ND)
-  #define PyBUF_C_CONTIGUOUS (0x0020 | PyBUF_STRIDES)
-  #define PyBUF_F_CONTIGUOUS (0x0040 | PyBUF_STRIDES)
-  #define PyBUF_ANY_CONTIGUOUS (0x0080 | PyBUF_STRIDES)
-  #define PyBUF_INDIRECT (0x0100 | PyBUF_STRIDES)
-  #define PyBUF_RECORDS (PyBUF_STRIDES | PyBUF_FORMAT | PyBUF_WRITABLE)
-  #define PyBUF_FULL (PyBUF_INDIRECT | PyBUF_FORMAT | PyBUF_WRITABLE)
-
-  typedef int (*getbufferproc)(PyObject *, Py_buffer *, int);
-  typedef void (*releasebufferproc)(PyObject *, Py_buffer *);
-#endif
-
-#if PY_MAJOR_VERSION < 3
-  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
-  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos) \
-          PyCode_New(a, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
-#else
-  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
-  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos) \
-          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
-#endif
-
-#if PY_MAJOR_VERSION < 3 && PY_MINOR_VERSION < 6
-  #define PyUnicode_FromString(s) PyUnicode_Decode(s, strlen(s), "UTF-8", "strict")
-#endif
-
-#if PY_MAJOR_VERSION >= 3
-  #define Py_TPFLAGS_CHECKTYPES 0
-  #define Py_TPFLAGS_HAVE_INDEX 0
-#endif
-
-#if (PY_VERSION_HEX < 0x02060000) || (PY_MAJOR_VERSION >= 3)
-  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
-#endif
-
-
-#if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_GET_LENGTH)
-  #define CYTHON_PEP393_ENABLED 1
-  #define __Pyx_PyUnicode_GET_LENGTH(u) PyUnicode_GET_LENGTH(u)
-  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
-#else
-  #define CYTHON_PEP393_ENABLED 0
-  #define __Pyx_PyUnicode_GET_LENGTH(u) PyUnicode_GET_SIZE(u)
-  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
-#endif
-
-#if PY_MAJOR_VERSION >= 3
-  #define PyBaseString_Type            PyUnicode_Type
-  #define PyStringObject               PyUnicodeObject
-  #define PyString_Type                PyUnicode_Type
-  #define PyString_Check               PyUnicode_Check
-  #define PyString_CheckExact          PyUnicode_CheckExact
-#endif
-
-#if PY_VERSION_HEX < 0x02060000
-  #define PyBytesObject                PyStringObject
-  #define PyBytes_Type                 PyString_Type
-  #define PyBytes_Check                PyString_Check
-  #define PyBytes_CheckExact           PyString_CheckExact
-  #define PyBytes_FromString           PyString_FromString
-  #define PyBytes_FromStringAndSize    PyString_FromStringAndSize
-  #define PyBytes_FromFormat           PyString_FromFormat
-  #define PyBytes_DecodeEscape         PyString_DecodeEscape
-  #define PyBytes_AsString             PyString_AsString
-  #define PyBytes_AsStringAndSize      PyString_AsStringAndSize
-  #define PyBytes_Size                 PyString_Size
-  #define PyBytes_AS_STRING            PyString_AS_STRING
-  #define PyBytes_GET_SIZE             PyString_GET_SIZE
-  #define PyBytes_Repr                 PyString_Repr
-  #define PyBytes_Concat               PyString_Concat
-  #define PyBytes_ConcatAndDel         PyString_ConcatAndDel
-#endif
-
-#if PY_VERSION_HEX < 0x02060000
-  #define PySet_Check(obj)             PyObject_TypeCheck(obj, &PySet_Type)
-  #define PyFrozenSet_Check(obj)       PyObject_TypeCheck(obj, &PyFrozenSet_Type)
-#endif
-#ifndef PySet_CheckExact
-  #define PySet_CheckExact(obj)        (Py_TYPE(obj) == &PySet_Type)
-#endif
-
-#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
-
-#if PY_MAJOR_VERSION >= 3
-  #define PyIntObject                  PyLongObject
-  #define PyInt_Type                   PyLong_Type
-  #define PyInt_Check(op)              PyLong_Check(op)
-  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
-  #define PyInt_FromString             PyLong_FromString
-  #define PyInt_FromUnicode            PyLong_FromUnicode
-  #define PyInt_FromLong               PyLong_FromLong
-  #define PyInt_FromSize_t             PyLong_FromSize_t
-  #define PyInt_FromSsize_t            PyLong_FromSsize_t
-  #define PyInt_AsLong                 PyLong_AsLong
-  #define PyInt_AS_LONG                PyLong_AS_LONG
-  #define PyInt_AsSsize_t              PyLong_AsSsize_t
-  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
-  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
-#endif
-
-#if PY_MAJOR_VERSION >= 3
-  #define PyBoolObject                 PyLongObject
-#endif
-
-#if PY_VERSION_HEX < 0x03020000
-  typedef long Py_hash_t;
-  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
-  #define __Pyx_PyInt_AsHash_t   PyInt_AsLong
-#else
-  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
-  #define __Pyx_PyInt_AsHash_t   PyInt_AsSsize_t
-#endif
-
-#if (PY_MAJOR_VERSION < 3) || (PY_VERSION_HEX >= 0x03010300)
-  #define __Pyx_PySequence_GetSlice(obj, a, b) PySequence_GetSlice(obj, a, b)
-  #define __Pyx_PySequence_SetSlice(obj, a, b, value) PySequence_SetSlice(obj, a, b, value)
-  #define __Pyx_PySequence_DelSlice(obj, a, b) PySequence_DelSlice(obj, a, b)
-#else
-  #define __Pyx_PySequence_GetSlice(obj, a, b) (unlikely(!(obj)) ? \
-        (PyErr_SetString(PyExc_SystemError, "null argument to internal routine"), (PyObject*)0) : \
-        (likely((obj)->ob_type->tp_as_mapping) ? (PySequence_GetSlice(obj, a, b)) : \
-            (PyErr_Format(PyExc_TypeError, "'%.200s' object is unsliceable", (obj)->ob_type->tp_name), (PyObject*)0)))
-  #define __Pyx_PySequence_SetSlice(obj, a, b, value) (unlikely(!(obj)) ? \
-        (PyErr_SetString(PyExc_SystemError, "null argument to internal routine"), -1) : \
-        (likely((obj)->ob_type->tp_as_mapping) ? (PySequence_SetSlice(obj, a, b, value)) : \
-            (PyErr_Format(PyExc_TypeError, "'%.200s' object doesn't support slice assignment", (obj)->ob_type->tp_name), -1)))
-  #define __Pyx_PySequence_DelSlice(obj, a, b) (unlikely(!(obj)) ? \
-        (PyErr_SetString(PyExc_SystemError, "null argument to internal routine"), -1) : \
-        (likely((obj)->ob_type->tp_as_mapping) ? (PySequence_DelSlice(obj, a, b)) : \
-            (PyErr_Format(PyExc_TypeError, "'%.200s' object doesn't support slice deletion", (obj)->ob_type->tp_name), -1)))
-#endif
-
-#if PY_MAJOR_VERSION >= 3
-  #define PyMethod_New(func, self, klass) ((self) ? PyMethod_New(func, self) : PyInstanceMethod_New(func))
-#endif
-
-#if PY_VERSION_HEX < 0x02050000
-  #define __Pyx_GetAttrString(o,n)   PyObject_GetAttrString((o),((char *)(n)))
-  #define __Pyx_SetAttrString(o,n,a) PyObject_SetAttrString((o),((char *)(n)),(a))
-  #define __Pyx_DelAttrString(o,n)   PyObject_DelAttrString((o),((char *)(n)))
-#else
-  #define __Pyx_GetAttrString(o,n)   PyObject_GetAttrString((o),(n))
-  #define __Pyx_SetAttrString(o,n,a) PyObject_SetAttrString((o),(n),(a))
-  #define __Pyx_DelAttrString(o,n)   PyObject_DelAttrString((o),(n))
-#endif
-
-#if PY_VERSION_HEX < 0x02050000
-  #define __Pyx_NAMESTR(n) ((char *)(n))
-  #define __Pyx_DOCSTR(n)  ((char *)(n))
-#else
-  #define __Pyx_NAMESTR(n) (n)
-  #define __Pyx_DOCSTR(n)  (n)
-#endif
-
-#if PY_MAJOR_VERSION >= 3
-  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
-  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
-#else
-  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_Divide(x,y)
-  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceDivide(x,y)
-#endif
-
-#ifndef __PYX_EXTERN_C
-  #ifdef __cplusplus
-    #define __PYX_EXTERN_C extern "C"
-  #else
-    #define __PYX_EXTERN_C extern
-  #endif
-#endif
-
-#if defined(WIN32) || defined(MS_WINDOWS)
-#define _USE_MATH_DEFINES
-#endif
-#include <math.h>
-#define __PYX_HAVE__ricker
-#define __PYX_HAVE_API__ricker
-#include <vector>
-#include "string.h"
-#include "Interval.h"
-#include "point.h"
-#include "box.h"
-#include "boxset.h"
-#include "tree.h"
-#include "string"
-#include "mapper.h"
-#include "ricker_cpp.h"
-#ifdef _OPENMP
-#include <omp.h>
-#endif /* _OPENMP */
-
-#ifdef PYREX_WITHOUT_ASSERTIONS
-#define CYTHON_WITHOUT_ASSERTIONS
-#endif
-
-
-/* inline attribute */
-#ifndef CYTHON_INLINE
-  #if defined(__GNUC__)
-    #define CYTHON_INLINE __inline__
-  #elif defined(_MSC_VER)
-    #define CYTHON_INLINE __inline
-  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
-    #define CYTHON_INLINE inline
-  #else
-    #define CYTHON_INLINE
-  #endif
-#endif
-
-/* unused attribute */
-#ifndef CYTHON_UNUSED
-# if defined(__GNUC__)
-#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
-#     define CYTHON_UNUSED __attribute__ ((__unused__))
-#   else
-#     define CYTHON_UNUSED
-#   endif
-# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
-#   define CYTHON_UNUSED __attribute__ ((__unused__))
-# else
-#   define CYTHON_UNUSED
-# endif
-#endif
-
-typedef struct {PyObject **p; char *s; const long n; const char* encoding; const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry; /*proto*/
-
-
-/* Type Conversion Predeclarations */
-
-#define __Pyx_PyBytes_FromUString(s) PyBytes_FromString((char*)s)
-#define __Pyx_PyBytes_AsUString(s)   ((unsigned char*) PyBytes_AsString(s))
-
-#define __Pyx_Owned_Py_None(b) (Py_INCREF(Py_None), Py_None)
-#define __Pyx_PyBool_FromLong(b) ((b) ? (Py_INCREF(Py_True), Py_True) : (Py_INCREF(Py_False), Py_False))
-static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
-static CYTHON_INLINE PyObject* __Pyx_PyNumber_Int(PyObject* x);
-
-static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
-static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
-static CYTHON_INLINE size_t __Pyx_PyInt_AsSize_t(PyObject*);
-
-#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
-#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
-
-#ifdef __GNUC__
-  /* Test for GCC > 2.95 */
-  #if __GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95))
-    #define likely(x)   __builtin_expect(!!(x), 1)
-    #define unlikely(x) __builtin_expect(!!(x), 0)
-  #else /* __GNUC__ > 2 ... */
-    #define likely(x)   (x)
-    #define unlikely(x) (x)
-  #endif /* __GNUC__ > 2 ... */
-#else /* __GNUC__ */
-  #define likely(x)   (x)
-  #define unlikely(x) (x)
-#endif /* __GNUC__ */
-    
-static PyObject *__pyx_m;
-static PyObject *__pyx_b;
-static PyObject *__pyx_empty_tuple;
-static PyObject *__pyx_empty_bytes;
-static int __pyx_lineno;
-static int __pyx_clineno = 0;
-static const char * __pyx_cfilenm= __FILE__;
-static const char *__pyx_filename;
-
-
-static const char *__pyx_f[] = {
-  "ricker.pyx",
-};
-
-/*--- Type declarations ---*/
-struct __pyx_obj_4rads_9enclosure_8cymapper_Mapper;
-struct __pyx_obj_6ricker_RickerMapper;
-
-/* "rads/enclosure/cymapper.pxd":3
- * from cppdefs cimport *
- * 
- * cdef class Mapper:             # <<<<<<<<<<<<<<
- * 	cdef cMapper *mapper
- * 	cdef cMapper *get_mapper(self)
- */
-struct __pyx_obj_4rads_9enclosure_8cymapper_Mapper {
-  PyObject_HEAD
-  struct __pyx_vtabstruct_4rads_9enclosure_8cymapper_Mapper *__pyx_vtab;
-  Mapper *mapper;
-};
-
-
-/* "ricker.pyx":11
- * 	void del_Ricker "delete" (cRicker *)
- * 
- * cdef class RickerMapper(Mapper):             # <<<<<<<<<<<<<<
- * 
- * 	def __cinit__(self):
- */
-struct __pyx_obj_6ricker_RickerMapper {
-  struct __pyx_obj_4rads_9enclosure_8cymapper_Mapper __pyx_base;
-};
-
-
-
-/* "rads/enclosure/cymapper.pxd":3
- * from cppdefs cimport *
- * 
- * cdef class Mapper:             # <<<<<<<<<<<<<<
- * 	cdef cMapper *mapper
- * 	cdef cMapper *get_mapper(self)
- */
-
-struct __pyx_vtabstruct_4rads_9enclosure_8cymapper_Mapper {
-  Mapper *(*get_mapper)(struct __pyx_obj_4rads_9enclosure_8cymapper_Mapper *);
-  int (*get_dim)(struct __pyx_obj_4rads_9enclosure_8cymapper_Mapper *, int __pyx_skip_dispatch);
-};
-static struct __pyx_vtabstruct_4rads_9enclosure_8cymapper_Mapper *__pyx_vtabptr_4rads_9enclosure_8cymapper_Mapper;
-
-
-/* "ricker.pyx":11
- * 	void del_Ricker "delete" (cRicker *)
- * 
- * cdef class RickerMapper(Mapper):             # <<<<<<<<<<<<<<
- * 
- * 	def __cinit__(self):
- */
-
-struct __pyx_vtabstruct_6ricker_RickerMapper {
-  struct __pyx_vtabstruct_4rads_9enclosure_8cymapper_Mapper __pyx_base;
-};
-static struct __pyx_vtabstruct_6ricker_RickerMapper *__pyx_vtabptr_6ricker_RickerMapper;
-#ifndef CYTHON_REFNANNY
-  #define CYTHON_REFNANNY 0
-#endif
-#if CYTHON_REFNANNY
-  typedef struct {
-    void (*INCREF)(void*, PyObject*, int);
-    void (*DECREF)(void*, PyObject*, int);
-    void (*GOTREF)(void*, PyObject*, int);
-    void (*GIVEREF)(void*, PyObject*, int);
-    void* (*SetupContext)(const char*, int, const char*);
-    void (*FinishContext)(void**);
-  } __Pyx_RefNannyAPIStruct;
-  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
-  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname); /*proto*/
-  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
-#ifdef WITH_THREAD
-  #define __Pyx_RefNannySetupContext(name, acquire_gil) \
-          if (acquire_gil) { \
-              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure(); \
-              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__); \
-              PyGILState_Release(__pyx_gilstate_save); \
-          } else { \
-              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__); \
-          }
-#else
-  #define __Pyx_RefNannySetupContext(name, acquire_gil) \
-          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__)
-#endif
-  #define __Pyx_RefNannyFinishContext() \
-          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
-  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
-  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
-  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
-  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
-  #define __Pyx_XINCREF(r)  do { if((r) != NULL) {__Pyx_INCREF(r); }} while(0)
-  #define __Pyx_XDECREF(r)  do { if((r) != NULL) {__Pyx_DECREF(r); }} while(0)
-  #define __Pyx_XGOTREF(r)  do { if((r) != NULL) {__Pyx_GOTREF(r); }} while(0)
-  #define __Pyx_XGIVEREF(r) do { if((r) != NULL) {__Pyx_GIVEREF(r);}} while(0)
-#else
-  #define __Pyx_RefNannyDeclarations
-  #define __Pyx_RefNannySetupContext(name, acquire_gil)
-  #define __Pyx_RefNannyFinishContext()
-  #define __Pyx_INCREF(r) Py_INCREF(r)
-  #define __Pyx_DECREF(r) Py_DECREF(r)
-  #define __Pyx_GOTREF(r)
-  #define __Pyx_GIVEREF(r)
-  #define __Pyx_XINCREF(r) Py_XINCREF(r)
-  #define __Pyx_XDECREF(r) Py_XDECREF(r)
-  #define __Pyx_XGOTREF(r)
-  #define __Pyx_XGIVEREF(r)
-#endif /* CYTHON_REFNANNY */
-#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
-#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)
-
-static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
-    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found); /*proto*/
-
-static CYTHON_INLINE int __Pyx_CheckKeywordStrings(PyObject *kwdict, const char* function_name, int kw_allowed); /*proto*/
-
-static int __Pyx_Print(PyObject*, PyObject *, int); /*proto*/
-#if PY_MAJOR_VERSION >= 3
-static PyObject* __pyx_print = 0;
-static PyObject* __pyx_print_kwargs = 0;
-#endif
-
-static int __Pyx_PrintOne(PyObject* stream, PyObject *o); /*proto*/
-
-static CYTHON_INLINE unsigned char __Pyx_PyInt_AsUnsignedChar(PyObject *);
-
-static CYTHON_INLINE unsigned short __Pyx_PyInt_AsUnsignedShort(PyObject *);
-
-static CYTHON_INLINE unsigned int __Pyx_PyInt_AsUnsignedInt(PyObject *);
-
-static CYTHON_INLINE char __Pyx_PyInt_AsChar(PyObject *);
-
-static CYTHON_INLINE short __Pyx_PyInt_AsShort(PyObject *);
-
-static CYTHON_INLINE int __Pyx_PyInt_AsInt(PyObject *);
-
-static CYTHON_INLINE signed char __Pyx_PyInt_AsSignedChar(PyObject *);
-
-static CYTHON_INLINE signed short __Pyx_PyInt_AsSignedShort(PyObject *);
-
-static CYTHON_INLINE signed int __Pyx_PyInt_AsSignedInt(PyObject *);
-
-static CYTHON_INLINE int __Pyx_PyInt_AsLongDouble(PyObject *);
-
-static CYTHON_INLINE unsigned long __Pyx_PyInt_AsUnsignedLong(PyObject *);
-
-static CYTHON_INLINE unsigned PY_LONG_LONG __Pyx_PyInt_AsUnsignedLongLong(PyObject *);
-
-static CYTHON_INLINE long __Pyx_PyInt_AsLong(PyObject *);
-
-static CYTHON_INLINE PY_LONG_LONG __Pyx_PyInt_AsLongLong(PyObject *);
-
-static CYTHON_INLINE signed long __Pyx_PyInt_AsSignedLong(PyObject *);
-
-static CYTHON_INLINE signed PY_LONG_LONG __Pyx_PyInt_AsSignedLongLong(PyObject *);
-
-static int __Pyx_check_binary_version(void);
-
-#if !defined(__Pyx_PyIdentifier_FromString)
-#if PY_MAJOR_VERSION < 3
-  #define __Pyx_PyIdentifier_FromString(s) PyString_FromString(s)
-#else
-  #define __Pyx_PyIdentifier_FromString(s) PyUnicode_FromString(s)
-#endif
-#endif
-
-static PyTypeObject *__Pyx_ImportType(const char *module_name, const char *class_name, size_t size, int strict);  /*proto*/
-
-static PyObject *__Pyx_ImportModule(const char *name); /*proto*/
-
-static void* __Pyx_GetVtable(PyObject *dict); /*proto*/
-
-static int __Pyx_SetVtable(PyObject *dict, void *vtable); /*proto*/
-
-typedef struct {
-    int code_line;
-    PyCodeObject* code_object;
-} __Pyx_CodeObjectCacheEntry;
-struct __Pyx_CodeObjectCache {
-    int count;
-    int max_count;
-    __Pyx_CodeObjectCacheEntry* entries;
-};
-static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
-static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
-static PyCodeObject *__pyx_find_code_object(int code_line);
-static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);
-
-static void __Pyx_AddTraceback(const char *funcname, int c_line,
-                               int py_line, const char *filename); /*proto*/
-
-static int __Pyx_InitStrings(__Pyx_StringTabEntry *t); /*proto*/
-
-
-/* Module declarations from 'libcpp.vector' */
-
-/* Module declarations from 'libc' */
-
-/* Module declarations from 'libc.string' */
-
-/* Module declarations from 'rads.enclosure.cppdefs' */
-
-/* Module declarations from 'rads.enclosure.cymapper' */
-static PyTypeObject *__pyx_ptype_4rads_9enclosure_8cymapper_Mapper = 0;
-
-/* Module declarations from 'ricker' */
-static PyTypeObject *__pyx_ptype_6ricker_RickerMapper = 0;
-#define __Pyx_MODULE_NAME "ricker"
-int __pyx_module_is_main_ricker = 0;
-
-/* Implementation of 'ricker' */
-static int __pyx_pf_6ricker_12RickerMapper___cinit__(struct __pyx_obj_6ricker_RickerMapper *__pyx_v_self); /* proto */
-static void __pyx_pf_6ricker_12RickerMapper_2__dealloc__(struct __pyx_obj_6ricker_RickerMapper *__pyx_v_self); /* proto */
-static char __pyx_k_1[] = "in RickernMapper cinit";
-static char __pyx_k____main__[] = "__main__";
-static char __pyx_k____test__[] = "__test__";
-static PyObject *__pyx_kp_s_1;
-static PyObject *__pyx_n_s____main__;
-static PyObject *__pyx_n_s____test__;
-
-/* Python wrapper */
-static int __pyx_pw_6ricker_12RickerMapper_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
-static int __pyx_pw_6ricker_12RickerMapper_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
-  int __pyx_r;
-  __Pyx_RefNannyDeclarations
-  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
-  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
-    __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return -1;}
-  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__cinit__", 0))) return -1;
-  __pyx_r = __pyx_pf_6ricker_12RickerMapper___cinit__(((struct __pyx_obj_6ricker_RickerMapper *)__pyx_v_self));
-  __Pyx_RefNannyFinishContext();
-  return __pyx_r;
-}
-
-/* "ricker.pyx":13
- * cdef class RickerMapper(Mapper):
- * 
- * 	def __cinit__(self):             # <<<<<<<<<<<<<<
- * 		print "in RickernMapper cinit"
- * 		self.mapper = <cMapper *>new_Ricker()
- */
-
-static int __pyx_pf_6ricker_12RickerMapper___cinit__(struct __pyx_obj_6ricker_RickerMapper *__pyx_v_self) {
-  int __pyx_r;
-  __Pyx_RefNannyDeclarations
-  int __pyx_lineno = 0;
-  const char *__pyx_filename = NULL;
-  int __pyx_clineno = 0;
-  __Pyx_RefNannySetupContext("__cinit__", 0);
-
-  /* "ricker.pyx":14
- * 
- * 	def __cinit__(self):
- * 		print "in RickernMapper cinit"             # <<<<<<<<<<<<<<
- * 		self.mapper = <cMapper *>new_Ricker()
- * 
- */
-  if (__Pyx_PrintOne(0, ((PyObject *)__pyx_kp_s_1)) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 14; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-
-  /* "ricker.pyx":15
- * 	def __cinit__(self):
- * 		print "in RickernMapper cinit"
- * 		self.mapper = <cMapper *>new_Ricker()             # <<<<<<<<<<<<<<
- * 
- * 	def __dealloc__(self):
- */
-  __pyx_v_self->__pyx_base.mapper = ((Mapper *)new RickerMapper());
-
-  __pyx_r = 0;
-  goto __pyx_L0;
-  __pyx_L1_error:;
-  __Pyx_AddTraceback("ricker.RickerMapper.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
-  __pyx_r = -1;
-  __pyx_L0:;
-  __Pyx_RefNannyFinishContext();
-  return __pyx_r;
-}
-
-/* Python wrapper */
-static void __pyx_pw_6ricker_12RickerMapper_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
-static void __pyx_pw_6ricker_12RickerMapper_3__dealloc__(PyObject *__pyx_v_self) {
-  __Pyx_RefNannyDeclarations
-  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
-  __pyx_pf_6ricker_12RickerMapper_2__dealloc__(((struct __pyx_obj_6ricker_RickerMapper *)__pyx_v_self));
-  __Pyx_RefNannyFinishContext();
-}
-
-/* "ricker.pyx":17
- * 		self.mapper = <cMapper *>new_Ricker()
- * 
- * 	def __dealloc__(self):             # <<<<<<<<<<<<<<
- * 		del_Ricker(<cRicker *>self.mapper)
- * 
- */
-
-static void __pyx_pf_6ricker_12RickerMapper_2__dealloc__(struct __pyx_obj_6ricker_RickerMapper *__pyx_v_self) {
-  __Pyx_RefNannyDeclarations
-  __Pyx_RefNannySetupContext("__dealloc__", 0);
-
-  /* "ricker.pyx":18
- * 
- * 	def __dealloc__(self):
- * 		del_Ricker(<cRicker *>self.mapper)             # <<<<<<<<<<<<<<
- * 
- */
-  delete(((RickerMapper *)__pyx_v_self->__pyx_base.mapper));
-
-  __Pyx_RefNannyFinishContext();
-}
-static struct __pyx_vtabstruct_6ricker_RickerMapper __pyx_vtable_6ricker_RickerMapper;
-
-static PyObject *__pyx_tp_new_6ricker_RickerMapper(PyTypeObject *t, PyObject *a, PyObject *k) {
-  struct __pyx_obj_6ricker_RickerMapper *p;
-  PyObject *o = __pyx_ptype_4rads_9enclosure_8cymapper_Mapper->tp_new(t, a, k);
-  if (!o) return 0;
-  p = ((struct __pyx_obj_6ricker_RickerMapper *)o);
-  p->__pyx_base.__pyx_vtab = (struct __pyx_vtabstruct_4rads_9enclosure_8cymapper_Mapper*)__pyx_vtabptr_6ricker_RickerMapper;
-  if (__pyx_pw_6ricker_12RickerMapper_1__cinit__(o, __pyx_empty_tuple, NULL) < 0) {
-    Py_DECREF(o); o = 0;
-  }
-  return o;
-}
-
-static void __pyx_tp_dealloc_6ricker_RickerMapper(PyObject *o) {
-  {
-    PyObject *etype, *eval, *etb;
-    PyErr_Fetch(&etype, &eval, &etb);
-    ++Py_REFCNT(o);
-    __pyx_pw_6ricker_12RickerMapper_3__dealloc__(o);
-    if (PyErr_Occurred()) PyErr_WriteUnraisable(o);
-    --Py_REFCNT(o);
-    PyErr_Restore(etype, eval, etb);
-  }
-  __pyx_ptype_4rads_9enclosure_8cymapper_Mapper->tp_dealloc(o);
-}
-
-static PyMethodDef __pyx_methods_6ricker_RickerMapper[] = {
-  {0, 0, 0, 0}
-};
-
-static PyNumberMethods __pyx_tp_as_number_RickerMapper = {
-  0, /*nb_add*/
-  0, /*nb_subtract*/
-  0, /*nb_multiply*/
-  #if PY_MAJOR_VERSION < 3
-  0, /*nb_divide*/
-  #endif
-  0, /*nb_remainder*/
-  0, /*nb_divmod*/
-  0, /*nb_power*/
-  0, /*nb_negative*/
-  0, /*nb_positive*/
-  0, /*nb_absolute*/
-  0, /*nb_nonzero*/
-  0, /*nb_invert*/
-  0, /*nb_lshift*/
-  0, /*nb_rshift*/
-  0, /*nb_and*/
-  0, /*nb_xor*/
-  0, /*nb_or*/
-  #if PY_MAJOR_VERSION < 3
-  0, /*nb_coerce*/
-  #endif
-  0, /*nb_int*/
-  #if PY_MAJOR_VERSION < 3
-  0, /*nb_long*/
-  #else
-  0, /*reserved*/
-  #endif
-  0, /*nb_float*/
-  #if PY_MAJOR_VERSION < 3
-  0, /*nb_oct*/
-  #endif
-  #if PY_MAJOR_VERSION < 3
-  0, /*nb_hex*/
-  #endif
-  0, /*nb_inplace_add*/
-  0, /*nb_inplace_subtract*/
-  0, /*nb_inplace_multiply*/
-  #if PY_MAJOR_VERSION < 3
-  0, /*nb_inplace_divide*/
-  #endif
-  0, /*nb_inplace_remainder*/
-  0, /*nb_inplace_power*/
-  0, /*nb_inplace_lshift*/
-  0, /*nb_inplace_rshift*/
-  0, /*nb_inplace_and*/
-  0, /*nb_inplace_xor*/
-  0, /*nb_inplace_or*/
-  0, /*nb_floor_divide*/
-  0, /*nb_true_divide*/
-  0, /*nb_inplace_floor_divide*/
-  0, /*nb_inplace_true_divide*/
-  #if PY_VERSION_HEX >= 0x02050000
-  0, /*nb_index*/
-  #endif
-};
-
-static PySequenceMethods __pyx_tp_as_sequence_RickerMapper = {
-  0, /*sq_length*/
-  0, /*sq_concat*/
-  0, /*sq_repeat*/
-  0, /*sq_item*/
-  0, /*sq_slice*/
-  0, /*sq_ass_item*/
-  0, /*sq_ass_slice*/
-  0, /*sq_contains*/
-  0, /*sq_inplace_concat*/
-  0, /*sq_inplace_repeat*/
-};
-
-static PyMappingMethods __pyx_tp_as_mapping_RickerMapper = {
-  0, /*mp_length*/
-  0, /*mp_subscript*/
-  0, /*mp_ass_subscript*/
-};
-
-static PyBufferProcs __pyx_tp_as_buffer_RickerMapper = {
-  #if PY_MAJOR_VERSION < 3
-  0, /*bf_getreadbuffer*/
-  #endif
-  #if PY_MAJOR_VERSION < 3
-  0, /*bf_getwritebuffer*/
-  #endif
-  #if PY_MAJOR_VERSION < 3
-  0, /*bf_getsegcount*/
-  #endif
-  #if PY_MAJOR_VERSION < 3
-  0, /*bf_getcharbuffer*/
-  #endif
-  #if PY_VERSION_HEX >= 0x02060000
-  0, /*bf_getbuffer*/
-  #endif
-  #if PY_VERSION_HEX >= 0x02060000
-  0, /*bf_releasebuffer*/
-  #endif
-};
-
-static PyTypeObject __pyx_type_6ricker_RickerMapper = {
-  PyVarObject_HEAD_INIT(0, 0)
-  __Pyx_NAMESTR("ricker.RickerMapper"), /*tp_name*/
-  sizeof(struct __pyx_obj_6ricker_RickerMapper), /*tp_basicsize*/
-  0, /*tp_itemsize*/
-  __pyx_tp_dealloc_6ricker_RickerMapper, /*tp_dealloc*/
-  0, /*tp_print*/
-  0, /*tp_getattr*/
-  0, /*tp_setattr*/
-  #if PY_MAJOR_VERSION < 3
-  0, /*tp_compare*/
-  #else
-  0, /*reserved*/
-  #endif
-  0, /*tp_repr*/
-  &__pyx_tp_as_number_RickerMapper, /*tp_as_number*/
-  &__pyx_tp_as_sequence_RickerMapper, /*tp_as_sequence*/
-  &__pyx_tp_as_mapping_RickerMapper, /*tp_as_mapping*/
-  0, /*tp_hash*/
-  0, /*tp_call*/
-  0, /*tp_str*/
-  0, /*tp_getattro*/
-  0, /*tp_setattro*/
-  &__pyx_tp_as_buffer_RickerMapper, /*tp_as_buffer*/
-  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE, /*tp_flags*/
-  0, /*tp_doc*/
-  0, /*tp_traverse*/
-  0, /*tp_clear*/
-  0, /*tp_richcompare*/
-  0, /*tp_weaklistoffset*/
-  0, /*tp_iter*/
-  0, /*tp_iternext*/
-  __pyx_methods_6ricker_RickerMapper, /*tp_methods*/
-  0, /*tp_members*/
-  0, /*tp_getset*/
-  0, /*tp_base*/
-  0, /*tp_dict*/
-  0, /*tp_descr_get*/
-  0, /*tp_descr_set*/
-  0, /*tp_dictoffset*/
-  0, /*tp_init*/
-  0, /*tp_alloc*/
-  __pyx_tp_new_6ricker_RickerMapper, /*tp_new*/
-  0, /*tp_free*/
-  0, /*tp_is_gc*/
-  0, /*tp_bases*/
-  0, /*tp_mro*/
-  0, /*tp_cache*/
-  0, /*tp_subclasses*/
-  0, /*tp_weaklist*/
-  0, /*tp_del*/
-  #if PY_VERSION_HEX >= 0x02060000
-  0, /*tp_version_tag*/
-  #endif
-};
-
-static PyMethodDef __pyx_methods[] = {
-  {0, 0, 0, 0}
-};
-
-#if PY_MAJOR_VERSION >= 3
-static struct PyModuleDef __pyx_moduledef = {
-    PyModuleDef_HEAD_INIT,
-    __Pyx_NAMESTR("ricker"),
-    0, /* m_doc */
-    -1, /* m_size */
-    __pyx_methods /* m_methods */,
-    NULL, /* m_reload */
-    NULL, /* m_traverse */
-    NULL, /* m_clear */
-    NULL /* m_free */
-};
-#endif
-
-static __Pyx_StringTabEntry __pyx_string_tab[] = {
-  {&__pyx_kp_s_1, __pyx_k_1, sizeof(__pyx_k_1), 0, 0, 1, 0},
-  {&__pyx_n_s____main__, __pyx_k____main__, sizeof(__pyx_k____main__), 0, 0, 1, 1},
-  {&__pyx_n_s____test__, __pyx_k____test__, sizeof(__pyx_k____test__), 0, 0, 1, 1},
-  {0, 0, 0, 0, 0, 0, 0}
-};
-static int __Pyx_InitCachedBuiltins(void) {
-  return 0;
-}
-
-static int __Pyx_InitCachedConstants(void) {
-  __Pyx_RefNannyDeclarations
-  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);
-  __Pyx_RefNannyFinishContext();
-  return 0;
-}
-
-static int __Pyx_InitGlobals(void) {
-  if (__Pyx_InitStrings(__pyx_string_tab) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
-  return 0;
-  __pyx_L1_error:;
-  return -1;
-}
-
-#if PY_MAJOR_VERSION < 3
-PyMODINIT_FUNC initricker(void); /*proto*/
-PyMODINIT_FUNC initricker(void)
-#else
-PyMODINIT_FUNC PyInit_ricker(void); /*proto*/
-PyMODINIT_FUNC PyInit_ricker(void)
-#endif
-{
-  PyObject *__pyx_t_1 = NULL;
-  __Pyx_RefNannyDeclarations
-  #if CYTHON_REFNANNY
-  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
-  if (!__Pyx_RefNanny) {
-      PyErr_Clear();
-      __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
-      if (!__Pyx_RefNanny)
-          Py_FatalError("failed to import 'refnanny' module");
-  }
-  #endif
-  __Pyx_RefNannySetupContext("PyMODINIT_FUNC PyInit_ricker(void)", 0);
-  if ( __Pyx_check_binary_version() < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_empty_tuple)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_bytes)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  #ifdef __Pyx_CyFunction_USED
-  if (__Pyx_CyFunction_init() < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  #endif
-  #ifdef __Pyx_FusedFunction_USED
-  if (__pyx_FusedFunction_init() < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  #endif
-  #ifdef __Pyx_Generator_USED
-  if (__pyx_Generator_init() < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  #endif
-  /*--- Library function declarations ---*/
-  /*--- Threads initialization code ---*/
-  #if defined(__PYX_FORCE_INIT_THREADS) && __PYX_FORCE_INIT_THREADS
-  #ifdef WITH_THREAD /* Python build with threading support? */
-  PyEval_InitThreads();
-  #endif
-  #endif
-  /*--- Module creation code ---*/
-  #if PY_MAJOR_VERSION < 3
-  __pyx_m = Py_InitModule4(__Pyx_NAMESTR("ricker"), __pyx_methods, 0, 0, PYTHON_API_VERSION);
-  #else
-  __pyx_m = PyModule_Create(&__pyx_moduledef);
-  #endif
-  if (!__pyx_m) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
-  #if PY_MAJOR_VERSION < 3
-  Py_INCREF(__pyx_m);
-  #endif
-  __pyx_b = PyImport_AddModule(__Pyx_NAMESTR(__Pyx_BUILTIN_MODULE_NAME));
-  if (!__pyx_b) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
-  if (__Pyx_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
-  /*--- Initialize various global constants etc. ---*/
-  if (unlikely(__Pyx_InitGlobals() < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  if (__pyx_module_is_main_ricker) {
-    if (__Pyx_SetAttrString(__pyx_m, "__name__", __pyx_n_s____main__) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
-  }
-  /*--- Builtin init code ---*/
-  if (unlikely(__Pyx_InitCachedBuiltins() < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  /*--- Constants init code ---*/
-  if (unlikely(__Pyx_InitCachedConstants() < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  /*--- Global init code ---*/
-  /*--- Variable export code ---*/
-  /*--- Function export code ---*/
-  /*--- Type init code ---*/
-  __pyx_ptype_4rads_9enclosure_8cymapper_Mapper = __Pyx_ImportType("rads.enclosure.cymapper", "Mapper", sizeof(struct __pyx_obj_4rads_9enclosure_8cymapper_Mapper), 1); if (unlikely(!__pyx_ptype_4rads_9enclosure_8cymapper_Mapper)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __pyx_vtabptr_4rads_9enclosure_8cymapper_Mapper = (struct __pyx_vtabstruct_4rads_9enclosure_8cymapper_Mapper*)__Pyx_GetVtable(__pyx_ptype_4rads_9enclosure_8cymapper_Mapper->tp_dict); if (unlikely(!__pyx_vtabptr_4rads_9enclosure_8cymapper_Mapper)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __pyx_vtabptr_6ricker_RickerMapper = &__pyx_vtable_6ricker_RickerMapper;
-  __pyx_vtable_6ricker_RickerMapper.__pyx_base = *__pyx_vtabptr_4rads_9enclosure_8cymapper_Mapper;
-  __pyx_type_6ricker_RickerMapper.tp_base = __pyx_ptype_4rads_9enclosure_8cymapper_Mapper;
-  if (PyType_Ready(&__pyx_type_6ricker_RickerMapper) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 11; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  if (__Pyx_SetVtable(__pyx_type_6ricker_RickerMapper.tp_dict, __pyx_vtabptr_6ricker_RickerMapper) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 11; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  if (__Pyx_SetAttrString(__pyx_m, "RickerMapper", (PyObject *)&__pyx_type_6ricker_RickerMapper) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 11; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __pyx_ptype_6ricker_RickerMapper = &__pyx_type_6ricker_RickerMapper;
-  /*--- Type import code ---*/
-  /*--- Variable import code ---*/
-  /*--- Function import code ---*/
-  /*--- Execution code ---*/
-
-  /* "ricker.pyx":1
- * from rads.enclosure.cppdefs cimport *             # <<<<<<<<<<<<<<
- * from rads.enclosure.cymapper cimport Mapper
- * 
- */
-  __pyx_t_1 = PyDict_New(); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __Pyx_GOTREF(((PyObject *)__pyx_t_1));
-  if (PyObject_SetAttr(__pyx_m, __pyx_n_s____test__, ((PyObject *)__pyx_t_1)) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
-  __Pyx_DECREF(((PyObject *)__pyx_t_1)); __pyx_t_1 = 0;
-  goto __pyx_L0;
-  __pyx_L1_error:;
-  __Pyx_XDECREF(__pyx_t_1);
-  if (__pyx_m) {
-    __Pyx_AddTraceback("init ricker", __pyx_clineno, __pyx_lineno, __pyx_filename);
-    Py_DECREF(__pyx_m); __pyx_m = 0;
-  } else if (!PyErr_Occurred()) {
-    PyErr_SetString(PyExc_ImportError, "init ricker");
-  }
-  __pyx_L0:;
-  __Pyx_RefNannyFinishContext();
-  #if PY_MAJOR_VERSION < 3
-  return;
-  #else
-  return __pyx_m;
-  #endif
-}
-
-/* Runtime support code */
-#if CYTHON_REFNANNY
-static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
-    PyObject *m = NULL, *p = NULL;
-    void *r = NULL;
-    m = PyImport_ImportModule((char *)modname);
-    if (!m) goto end;
-    p = PyObject_GetAttrString(m, (char *)"RefNannyAPI");
-    if (!p) goto end;
-    r = PyLong_AsVoidPtr(p);
-end:
-    Py_XDECREF(p);
-    Py_XDECREF(m);
-    return (__Pyx_RefNannyAPIStruct *)r;
-}
-#endif /* CYTHON_REFNANNY */
-
-static void __Pyx_RaiseArgtupleInvalid(
-    const char* func_name,
-    int exact,
-    Py_ssize_t num_min,
-    Py_ssize_t num_max,
-    Py_ssize_t num_found)
-{
-    Py_ssize_t num_expected;
-    const char *more_or_less;
-    if (num_found < num_min) {
-        num_expected = num_min;
-        more_or_less = "at least";
-    } else {
-        num_expected = num_max;
-        more_or_less = "at most";
-    }
-    if (exact) {
-        more_or_less = "exactly";
-    }
-    PyErr_Format(PyExc_TypeError,
-                 "%s() takes %s %"PY_FORMAT_SIZE_T"d positional argument%s (%"PY_FORMAT_SIZE_T"d given)",
-                 func_name, more_or_less, num_expected,
-                 (num_expected == 1) ? "" : "s", num_found);
-}
-
-static CYTHON_INLINE int __Pyx_CheckKeywordStrings(
-    PyObject *kwdict,
-    const char* function_name,
-    int kw_allowed)
-{
-    PyObject* key = 0;
-    Py_ssize_t pos = 0;
-    while (PyDict_Next(kwdict, &pos, &key, 0)) {
-        #if PY_MAJOR_VERSION < 3
-        if (unlikely(!PyString_CheckExact(key)) && unlikely(!PyString_Check(key)))
-        #else
-        if (unlikely(!PyUnicode_Check(key)))
-        #endif
-            goto invalid_keyword_type;
-    }
-    if ((!kw_allowed) && unlikely(key))
-        goto invalid_keyword;
-    return 1;
-invalid_keyword_type:
-    PyErr_Format(PyExc_TypeError,
-        "%s() keywords must be strings", function_name);
-    return 0;
-invalid_keyword:
-    PyErr_Format(PyExc_TypeError,
-    #if PY_MAJOR_VERSION < 3
-        "%s() got an unexpected keyword argument '%s'",
-        function_name, PyString_AsString(key));
-    #else
-        "%s() got an unexpected keyword argument '%U'",
-        function_name, key);
-    #endif
-    return 0;
-}
-
-#if PY_MAJOR_VERSION < 3
-static PyObject *__Pyx_GetStdout(void) {
-    PyObject *f = PySys_GetObject((char *)"stdout");
-    if (!f) {
-        PyErr_SetString(PyExc_RuntimeError, "lost sys.stdout");
-    }
-    return f;
-}
-static int __Pyx_Print(PyObject* f, PyObject *arg_tuple, int newline) {
-    PyObject* v;
-    int i;
-    if (!f) {
-        if (!(f = __Pyx_GetStdout()))
-            return -1;
-    }
-    for (i=0; i < PyTuple_GET_SIZE(arg_tuple); i++) {
-        if (PyFile_SoftSpace(f, 1)) {
-            if (PyFile_WriteString(" ", f) < 0)
-                return -1;
-        }
-        v = PyTuple_GET_ITEM(arg_tuple, i);
-        if (PyFile_WriteObject(v, f, Py_PRINT_RAW) < 0)
-            return -1;
-        if (PyString_Check(v)) {
-            char *s = PyString_AsString(v);
-            Py_ssize_t len = PyString_Size(v);
-            if (len > 0 &&
-                isspace(Py_CHARMASK(s[len-1])) &&
-                s[len-1] != ' ')
-                    PyFile_SoftSpace(f, 0);
-        }
-    }
-    if (newline) {
-        if (PyFile_WriteString("\n", f) < 0)
-            return -1;
-        PyFile_SoftSpace(f, 0);
-    }
-    return 0;
-}
-#else /* Python 3 has a print function */
-static int __Pyx_Print(PyObject* stream, PyObject *arg_tuple, int newline) {
-    PyObject* kwargs = 0;
-    PyObject* result = 0;
-    PyObject* end_string;
-    if (unlikely(!__pyx_print)) {
-        __pyx_print = __Pyx_GetAttrString(__pyx_b, "print");
-        if (!__pyx_print)
-            return -1;
-    }
-    if (stream) {
-        kwargs = PyDict_New();
-        if (unlikely(!kwargs))
-            return -1;
-        if (unlikely(PyDict_SetItemString(kwargs, "file", stream) < 0))
-            goto bad;
-        if (!newline) {
-            end_string = PyUnicode_FromStringAndSize(" ", 1);
-            if (unlikely(!end_string))
-                goto bad;
-            if (PyDict_SetItemString(kwargs, "end", end_string) < 0) {
-                Py_DECREF(end_string);
-                goto bad;
-            }
-            Py_DECREF(end_string);
-        }
-    } else if (!newline) {
-        if (unlikely(!__pyx_print_kwargs)) {
-            __pyx_print_kwargs = PyDict_New();
-            if (unlikely(!__pyx_print_kwargs))
-                return -1;
-            end_string = PyUnicode_FromStringAndSize(" ", 1);
-            if (unlikely(!end_string))
-                return -1;
-            if (PyDict_SetItemString(__pyx_print_kwargs, "end", end_string) < 0) {
-                Py_DECREF(end_string);
-                return -1;
-            }
-            Py_DECREF(end_string);
-        }
-        kwargs = __pyx_print_kwargs;
-    }
-    result = PyObject_Call(__pyx_print, arg_tuple, kwargs);
-    if (unlikely(kwargs) && (kwargs != __pyx_print_kwargs))
-        Py_DECREF(kwargs);
-    if (!result)
-        return -1;
-    Py_DECREF(result);
-    return 0;
-bad:
-    if (kwargs != __pyx_print_kwargs)
-        Py_XDECREF(kwargs);
-    return -1;
-}
-#endif
-
-#if PY_MAJOR_VERSION < 3
-static int __Pyx_PrintOne(PyObject* f, PyObject *o) {
-    if (!f) {
-        if (!(f = __Pyx_GetStdout()))
-            return -1;
-    }
-    if (PyFile_SoftSpace(f, 0)) {
-        if (PyFile_WriteString(" ", f) < 0)
-            return -1;
-    }
-    if (PyFile_WriteObject(o, f, Py_PRINT_RAW) < 0)
-        return -1;
-    if (PyFile_WriteString("\n", f) < 0)
-        return -1;
-    return 0;
-    /* the line below is just to avoid compiler
-     * compiler warnings about unused functions */
-    return __Pyx_Print(f, NULL, 0);
-}
-#else /* Python 3 has a print function */
-static int __Pyx_PrintOne(PyObject* stream, PyObject *o) {
-    int res;
-    PyObject* arg_tuple = PyTuple_New(1);
-    if (unlikely(!arg_tuple))
-        return -1;
-    Py_INCREF(o);
-    PyTuple_SET_ITEM(arg_tuple, 0, o);
-    res = __Pyx_Print(stream, arg_tuple, 1);
-    Py_DECREF(arg_tuple);
-    return res;
-}
-#endif
-
-static CYTHON_INLINE unsigned char __Pyx_PyInt_AsUnsignedChar(PyObject* x) {
-    const unsigned char neg_one = (unsigned char)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(unsigned char) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(unsigned char)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to unsigned char" :
-                    "value too large to convert to unsigned char");
-            }
-            return (unsigned char)-1;
-        }
-        return (unsigned char)val;
-    }
-    return (unsigned char)__Pyx_PyInt_AsUnsignedLong(x);
-}
-
-static CYTHON_INLINE unsigned short __Pyx_PyInt_AsUnsignedShort(PyObject* x) {
-    const unsigned short neg_one = (unsigned short)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(unsigned short) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(unsigned short)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to unsigned short" :
-                    "value too large to convert to unsigned short");
-            }
-            return (unsigned short)-1;
-        }
-        return (unsigned short)val;
-    }
-    return (unsigned short)__Pyx_PyInt_AsUnsignedLong(x);
-}
-
-static CYTHON_INLINE unsigned int __Pyx_PyInt_AsUnsignedInt(PyObject* x) {
-    const unsigned int neg_one = (unsigned int)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(unsigned int) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(unsigned int)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to unsigned int" :
-                    "value too large to convert to unsigned int");
-            }
-            return (unsigned int)-1;
-        }
-        return (unsigned int)val;
-    }
-    return (unsigned int)__Pyx_PyInt_AsUnsignedLong(x);
-}
-
-static CYTHON_INLINE char __Pyx_PyInt_AsChar(PyObject* x) {
-    const char neg_one = (char)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(char) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(char)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to char" :
-                    "value too large to convert to char");
-            }
-            return (char)-1;
-        }
-        return (char)val;
-    }
-    return (char)__Pyx_PyInt_AsLong(x);
-}
-
-static CYTHON_INLINE short __Pyx_PyInt_AsShort(PyObject* x) {
-    const short neg_one = (short)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(short) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(short)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to short" :
-                    "value too large to convert to short");
-            }
-            return (short)-1;
-        }
-        return (short)val;
-    }
-    return (short)__Pyx_PyInt_AsLong(x);
-}
-
-static CYTHON_INLINE int __Pyx_PyInt_AsInt(PyObject* x) {
-    const int neg_one = (int)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(int) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(int)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to int" :
-                    "value too large to convert to int");
-            }
-            return (int)-1;
-        }
-        return (int)val;
-    }
-    return (int)__Pyx_PyInt_AsLong(x);
-}
-
-static CYTHON_INLINE signed char __Pyx_PyInt_AsSignedChar(PyObject* x) {
-    const signed char neg_one = (signed char)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(signed char) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(signed char)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to signed char" :
-                    "value too large to convert to signed char");
-            }
-            return (signed char)-1;
-        }
-        return (signed char)val;
-    }
-    return (signed char)__Pyx_PyInt_AsSignedLong(x);
-}
-
-static CYTHON_INLINE signed short __Pyx_PyInt_AsSignedShort(PyObject* x) {
-    const signed short neg_one = (signed short)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(signed short) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(signed short)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to signed short" :
-                    "value too large to convert to signed short");
-            }
-            return (signed short)-1;
-        }
-        return (signed short)val;
-    }
-    return (signed short)__Pyx_PyInt_AsSignedLong(x);
-}
-
-static CYTHON_INLINE signed int __Pyx_PyInt_AsSignedInt(PyObject* x) {
-    const signed int neg_one = (signed int)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(signed int) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(signed int)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to signed int" :
-                    "value too large to convert to signed int");
-            }
-            return (signed int)-1;
-        }
-        return (signed int)val;
-    }
-    return (signed int)__Pyx_PyInt_AsSignedLong(x);
-}
-
-static CYTHON_INLINE int __Pyx_PyInt_AsLongDouble(PyObject* x) {
-    const int neg_one = (int)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-    if (sizeof(int) < sizeof(long)) {
-        long val = __Pyx_PyInt_AsLong(x);
-        if (unlikely(val != (long)(int)val)) {
-            if (!unlikely(val == -1 && PyErr_Occurred())) {
-                PyErr_SetString(PyExc_OverflowError,
-                    (is_unsigned && unlikely(val < 0)) ?
-                    "can't convert negative value to int" :
-                    "value too large to convert to int");
-            }
-            return (int)-1;
-        }
-        return (int)val;
-    }
-    return (int)__Pyx_PyInt_AsLong(x);
-}
-
-static CYTHON_INLINE unsigned long __Pyx_PyInt_AsUnsignedLong(PyObject* x) {
-    const unsigned long neg_one = (unsigned long)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-#if PY_VERSION_HEX < 0x03000000
-    if (likely(PyInt_Check(x))) {
-        long val = PyInt_AS_LONG(x);
-        if (is_unsigned && unlikely(val < 0)) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "can't convert negative value to unsigned long");
-            return (unsigned long)-1;
-        }
-        return (unsigned long)val;
-    } else
-#endif
-    if (likely(PyLong_Check(x))) {
-        if (is_unsigned) {
-            if (unlikely(Py_SIZE(x) < 0)) {
-                PyErr_SetString(PyExc_OverflowError,
-                                "can't convert negative value to unsigned long");
-                return (unsigned long)-1;
-            }
-            return (unsigned long)PyLong_AsUnsignedLong(x);
-        } else {
-            return (unsigned long)PyLong_AsLong(x);
-        }
-    } else {
-        unsigned long val;
-        PyObject *tmp = __Pyx_PyNumber_Int(x);
-        if (!tmp) return (unsigned long)-1;
-        val = __Pyx_PyInt_AsUnsignedLong(tmp);
-        Py_DECREF(tmp);
-        return val;
-    }
-}
-
-static CYTHON_INLINE unsigned PY_LONG_LONG __Pyx_PyInt_AsUnsignedLongLong(PyObject* x) {
-    const unsigned PY_LONG_LONG neg_one = (unsigned PY_LONG_LONG)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-#if PY_VERSION_HEX < 0x03000000
-    if (likely(PyInt_Check(x))) {
-        long val = PyInt_AS_LONG(x);
-        if (is_unsigned && unlikely(val < 0)) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "can't convert negative value to unsigned PY_LONG_LONG");
-            return (unsigned PY_LONG_LONG)-1;
-        }
-        return (unsigned PY_LONG_LONG)val;
-    } else
-#endif
-    if (likely(PyLong_Check(x))) {
-        if (is_unsigned) {
-            if (unlikely(Py_SIZE(x) < 0)) {
-                PyErr_SetString(PyExc_OverflowError,
-                                "can't convert negative value to unsigned PY_LONG_LONG");
-                return (unsigned PY_LONG_LONG)-1;
-            }
-            return (unsigned PY_LONG_LONG)PyLong_AsUnsignedLongLong(x);
-        } else {
-            return (unsigned PY_LONG_LONG)PyLong_AsLongLong(x);
-        }
-    } else {
-        unsigned PY_LONG_LONG val;
-        PyObject *tmp = __Pyx_PyNumber_Int(x);
-        if (!tmp) return (unsigned PY_LONG_LONG)-1;
-        val = __Pyx_PyInt_AsUnsignedLongLong(tmp);
-        Py_DECREF(tmp);
-        return val;
-    }
-}
-
-static CYTHON_INLINE long __Pyx_PyInt_AsLong(PyObject* x) {
-    const long neg_one = (long)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-#if PY_VERSION_HEX < 0x03000000
-    if (likely(PyInt_Check(x))) {
-        long val = PyInt_AS_LONG(x);
-        if (is_unsigned && unlikely(val < 0)) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "can't convert negative value to long");
-            return (long)-1;
-        }
-        return (long)val;
-    } else
-#endif
-    if (likely(PyLong_Check(x))) {
-        if (is_unsigned) {
-            if (unlikely(Py_SIZE(x) < 0)) {
-                PyErr_SetString(PyExc_OverflowError,
-                                "can't convert negative value to long");
-                return (long)-1;
-            }
-            return (long)PyLong_AsUnsignedLong(x);
-        } else {
-            return (long)PyLong_AsLong(x);
-        }
-    } else {
-        long val;
-        PyObject *tmp = __Pyx_PyNumber_Int(x);
-        if (!tmp) return (long)-1;
-        val = __Pyx_PyInt_AsLong(tmp);
-        Py_DECREF(tmp);
-        return val;
-    }
-}
-
-static CYTHON_INLINE PY_LONG_LONG __Pyx_PyInt_AsLongLong(PyObject* x) {
-    const PY_LONG_LONG neg_one = (PY_LONG_LONG)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-#if PY_VERSION_HEX < 0x03000000
-    if (likely(PyInt_Check(x))) {
-        long val = PyInt_AS_LONG(x);
-        if (is_unsigned && unlikely(val < 0)) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "can't convert negative value to PY_LONG_LONG");
-            return (PY_LONG_LONG)-1;
-        }
-        return (PY_LONG_LONG)val;
-    } else
-#endif
-    if (likely(PyLong_Check(x))) {
-        if (is_unsigned) {
-            if (unlikely(Py_SIZE(x) < 0)) {
-                PyErr_SetString(PyExc_OverflowError,
-                                "can't convert negative value to PY_LONG_LONG");
-                return (PY_LONG_LONG)-1;
-            }
-            return (PY_LONG_LONG)PyLong_AsUnsignedLongLong(x);
-        } else {
-            return (PY_LONG_LONG)PyLong_AsLongLong(x);
-        }
-    } else {
-        PY_LONG_LONG val;
-        PyObject *tmp = __Pyx_PyNumber_Int(x);
-        if (!tmp) return (PY_LONG_LONG)-1;
-        val = __Pyx_PyInt_AsLongLong(tmp);
-        Py_DECREF(tmp);
-        return val;
-    }
-}
-
-static CYTHON_INLINE signed long __Pyx_PyInt_AsSignedLong(PyObject* x) {
-    const signed long neg_one = (signed long)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-#if PY_VERSION_HEX < 0x03000000
-    if (likely(PyInt_Check(x))) {
-        long val = PyInt_AS_LONG(x);
-        if (is_unsigned && unlikely(val < 0)) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "can't convert negative value to signed long");
-            return (signed long)-1;
-        }
-        return (signed long)val;
-    } else
-#endif
-    if (likely(PyLong_Check(x))) {
-        if (is_unsigned) {
-            if (unlikely(Py_SIZE(x) < 0)) {
-                PyErr_SetString(PyExc_OverflowError,
-                                "can't convert negative value to signed long");
-                return (signed long)-1;
-            }
-            return (signed long)PyLong_AsUnsignedLong(x);
-        } else {
-            return (signed long)PyLong_AsLong(x);
-        }
-    } else {
-        signed long val;
-        PyObject *tmp = __Pyx_PyNumber_Int(x);
-        if (!tmp) return (signed long)-1;
-        val = __Pyx_PyInt_AsSignedLong(tmp);
-        Py_DECREF(tmp);
-        return val;
-    }
-}
-
-static CYTHON_INLINE signed PY_LONG_LONG __Pyx_PyInt_AsSignedLongLong(PyObject* x) {
-    const signed PY_LONG_LONG neg_one = (signed PY_LONG_LONG)-1, const_zero = 0;
-    const int is_unsigned = neg_one > const_zero;
-#if PY_VERSION_HEX < 0x03000000
-    if (likely(PyInt_Check(x))) {
-        long val = PyInt_AS_LONG(x);
-        if (is_unsigned && unlikely(val < 0)) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "can't convert negative value to signed PY_LONG_LONG");
-            return (signed PY_LONG_LONG)-1;
-        }
-        return (signed PY_LONG_LONG)val;
-    } else
-#endif
-    if (likely(PyLong_Check(x))) {
-        if (is_unsigned) {
-            if (unlikely(Py_SIZE(x) < 0)) {
-                PyErr_SetString(PyExc_OverflowError,
-                                "can't convert negative value to signed PY_LONG_LONG");
-                return (signed PY_LONG_LONG)-1;
-            }
-            return (signed PY_LONG_LONG)PyLong_AsUnsignedLongLong(x);
-        } else {
-            return (signed PY_LONG_LONG)PyLong_AsLongLong(x);
-        }
-    } else {
-        signed PY_LONG_LONG val;
-        PyObject *tmp = __Pyx_PyNumber_Int(x);
-        if (!tmp) return (signed PY_LONG_LONG)-1;
-        val = __Pyx_PyInt_AsSignedLongLong(tmp);
-        Py_DECREF(tmp);
-        return val;
-    }
-}
-
-static int __Pyx_check_binary_version(void) {
-    char ctversion[4], rtversion[4];
-    PyOS_snprintf(ctversion, 4, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
-    PyOS_snprintf(rtversion, 4, "%s", Py_GetVersion());
-    if (ctversion[0] != rtversion[0] || ctversion[2] != rtversion[2]) {
-        char message[200];
-        PyOS_snprintf(message, sizeof(message),
-                      "compiletime version %s of module '%.100s' "
-                      "does not match runtime version %s",
-                      ctversion, __Pyx_MODULE_NAME, rtversion);
-        #if PY_VERSION_HEX < 0x02050000
-        return PyErr_Warn(NULL, message);
-        #else
-        return PyErr_WarnEx(NULL, message, 1);
-        #endif
-    }
-    return 0;
-}
-
-#ifndef __PYX_HAVE_RT_ImportType
-#define __PYX_HAVE_RT_ImportType
-static PyTypeObject *__Pyx_ImportType(const char *module_name, const char *class_name,
-    size_t size, int strict)
-{
-    PyObject *py_module = 0;
-    PyObject *result = 0;
-    PyObject *py_name = 0;
-    char warning[200];
-    py_module = __Pyx_ImportModule(module_name);
-    if (!py_module)
-        goto bad;
-    py_name = __Pyx_PyIdentifier_FromString(class_name);
-    if (!py_name)
-        goto bad;
-    result = PyObject_GetAttr(py_module, py_name);
-    Py_DECREF(py_name);
-    py_name = 0;
-    Py_DECREF(py_module);
-    py_module = 0;
-    if (!result)
-        goto bad;
-    if (!PyType_Check(result)) {
-        PyErr_Format(PyExc_TypeError,
-            "%s.%s is not a type object",
-            module_name, class_name);
-        goto bad;
-    }
-    if (!strict && (size_t)((PyTypeObject *)result)->tp_basicsize > size) {
-        PyOS_snprintf(warning, sizeof(warning),
-            "%s.%s size changed, may indicate binary incompatibility",
-            module_name, class_name);
-        #if PY_VERSION_HEX < 0x02050000
-        if (PyErr_Warn(NULL, warning) < 0) goto bad;
-        #else
-        if (PyErr_WarnEx(NULL, warning, 0) < 0) goto bad;
-        #endif
-    }
-    else if ((size_t)((PyTypeObject *)result)->tp_basicsize != size) {
-        PyErr_Format(PyExc_ValueError,
-            "%s.%s has the wrong size, try recompiling",
-            module_name, class_name);
-        goto bad;
-    }
-    return (PyTypeObject *)result;
-bad:
-    Py_XDECREF(py_module);
-    Py_XDECREF(result);
-    return NULL;
-}
-#endif
-
-#ifndef __PYX_HAVE_RT_ImportModule
-#define __PYX_HAVE_RT_ImportModule
-static PyObject *__Pyx_ImportModule(const char *name) {
-    PyObject *py_name = 0;
-    PyObject *py_module = 0;
-    py_name = __Pyx_PyIdentifier_FromString(name);
-    if (!py_name)
-        goto bad;
-    py_module = PyImport_Import(py_name);
-    Py_DECREF(py_name);
-    return py_module;
-bad:
-    Py_XDECREF(py_name);
-    return 0;
-}
-#endif
-
-static void* __Pyx_GetVtable(PyObject *dict) {
-    void* ptr;
-    PyObject *ob = PyMapping_GetItemString(dict, (char *)"__pyx_vtable__");
-    if (!ob)
-        goto bad;
-#if PY_VERSION_HEX >= 0x02070000 && !(PY_MAJOR_VERSION==3&&PY_MINOR_VERSION==0)
-    ptr = PyCapsule_GetPointer(ob, 0);
-#else
-    ptr = PyCObject_AsVoidPtr(ob);
-#endif
-    if (!ptr && !PyErr_Occurred())
-        PyErr_SetString(PyExc_RuntimeError, "invalid vtable found for imported type");
-    Py_DECREF(ob);
-    return ptr;
-bad:
-    Py_XDECREF(ob);
-    return NULL;
-}
-
-static int __Pyx_SetVtable(PyObject *dict, void *vtable) {
-#if PY_VERSION_HEX >= 0x02070000 && !(PY_MAJOR_VERSION==3&&PY_MINOR_VERSION==0)
-    PyObject *ob = PyCapsule_New(vtable, 0, 0);
-#else
-    PyObject *ob = PyCObject_FromVoidPtr(vtable, 0);
-#endif
-    if (!ob)
-        goto bad;
-    if (PyDict_SetItemString(dict, "__pyx_vtable__", ob) < 0)
-        goto bad;
-    Py_DECREF(ob);
-    return 0;
-bad:
-    Py_XDECREF(ob);
-    return -1;
-}
-
-static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
-    int start = 0, mid = 0, end = count - 1;
-    if (end >= 0 && code_line > entries[end].code_line) {
-        return count;
-    }
-    while (start < end) {
-        mid = (start + end) / 2;
-        if (code_line < entries[mid].code_line) {
-            end = mid;
-        } else if (code_line > entries[mid].code_line) {
-             start = mid + 1;
-        } else {
-            return mid;
-        }
-    }
-    if (code_line <= entries[mid].code_line) {
-        return mid;
-    } else {
-        return mid + 1;
-    }
-}
-static PyCodeObject *__pyx_find_code_object(int code_line) {
-    PyCodeObject* code_object;
-    int pos;
-    if (unlikely(!code_line) || unlikely(!__pyx_code_cache.entries)) {
-        return NULL;
-    }
-    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
-    if (unlikely(pos >= __pyx_code_cache.count) || unlikely(__pyx_code_cache.entries[pos].code_line != code_line)) {
-        return NULL;
-    }
-    code_object = __pyx_code_cache.entries[pos].code_object;
-    Py_INCREF(code_object);
-    return code_object;
-}
-static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object) {
-    int pos, i;
-    __Pyx_CodeObjectCacheEntry* entries = __pyx_code_cache.entries;
-    if (unlikely(!code_line)) {
-        return;
-    }
-    if (unlikely(!entries)) {
-        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
-        if (likely(entries)) {
-            __pyx_code_cache.entries = entries;
-            __pyx_code_cache.max_count = 64;
-            __pyx_code_cache.count = 1;
-            entries[0].code_line = code_line;
-            entries[0].code_object = code_object;
-            Py_INCREF(code_object);
-        }
-        return;
-    }
-    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
-    if ((pos < __pyx_code_cache.count) && unlikely(__pyx_code_cache.entries[pos].code_line == code_line)) {
-        PyCodeObject* tmp = entries[pos].code_object;
-        entries[pos].code_object = code_object;
-        Py_DECREF(tmp);
-        return;
-    }
-    if (__pyx_code_cache.count == __pyx_code_cache.max_count) {
-        int new_max = __pyx_code_cache.max_count + 64;
-        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
-            __pyx_code_cache.entries, new_max*sizeof(__Pyx_CodeObjectCacheEntry));
-        if (unlikely(!entries)) {
-            return;
-        }
-        __pyx_code_cache.entries = entries;
-        __pyx_code_cache.max_count = new_max;
-    }
-    for (i=__pyx_code_cache.count; i>pos; i--) {
-        entries[i] = entries[i-1];
-    }
-    entries[pos].code_line = code_line;
-    entries[pos].code_object = code_object;
-    __pyx_code_cache.count++;
-    Py_INCREF(code_object);
-}
-
-#include "compile.h"
-#include "frameobject.h"
-#include "traceback.h"
-static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
-            const char *funcname, int c_line,
-            int py_line, const char *filename) {
-    PyCodeObject *py_code = 0;
-    PyObject *py_srcfile = 0;
-    PyObject *py_funcname = 0;
-    #if PY_MAJOR_VERSION < 3
-    py_srcfile = PyString_FromString(filename);
-    #else
-    py_srcfile = PyUnicode_FromString(filename);
-    #endif
-    if (!py_srcfile) goto bad;
-    if (c_line) {
-        #if PY_MAJOR_VERSION < 3
-        py_funcname = PyString_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
-        #else
-        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
-        #endif
-    }
-    else {
-        #if PY_MAJOR_VERSION < 3
-        py_funcname = PyString_FromString(funcname);
-        #else
-        py_funcname = PyUnicode_FromString(funcname);
-        #endif
-    }
-    if (!py_funcname) goto bad;
-    py_code = __Pyx_PyCode_New(
-        0,            /*int argcount,*/
-        0,            /*int kwonlyargcount,*/
-        0,            /*int nlocals,*/
-        0,            /*int stacksize,*/
-        0,            /*int flags,*/
-        __pyx_empty_bytes, /*PyObject *code,*/
-        __pyx_empty_tuple, /*PyObject *consts,*/
-        __pyx_empty_tuple, /*PyObject *names,*/
-        __pyx_empty_tuple, /*PyObject *varnames,*/
-        __pyx_empty_tuple, /*PyObject *freevars,*/
-        __pyx_empty_tuple, /*PyObject *cellvars,*/
-        py_srcfile,   /*PyObject *filename,*/
-        py_funcname,  /*PyObject *name,*/
-        py_line,      /*int firstlineno,*/
-        __pyx_empty_bytes  /*PyObject *lnotab*/
-    );
-    Py_DECREF(py_srcfile);
-    Py_DECREF(py_funcname);
-    return py_code;
-bad:
-    Py_XDECREF(py_srcfile);
-    Py_XDECREF(py_funcname);
-    return NULL;
-}
-static void __Pyx_AddTraceback(const char *funcname, int c_line,
-                               int py_line, const char *filename) {
-    PyCodeObject *py_code = 0;
-    PyObject *py_globals = 0;
-    PyFrameObject *py_frame = 0;
-    py_code = __pyx_find_code_object(c_line ? c_line : py_line);
-    if (!py_code) {
-        py_code = __Pyx_CreateCodeObjectForTraceback(
-            funcname, c_line, py_line, filename);
-        if (!py_code) goto bad;
-        __pyx_insert_code_object(c_line ? c_line : py_line, py_code);
-    }
-    py_globals = PyModule_GetDict(__pyx_m);
-    if (!py_globals) goto bad;
-    py_frame = PyFrame_New(
-        PyThreadState_GET(), /*PyThreadState *tstate,*/
-        py_code,             /*PyCodeObject *code,*/
-        py_globals,          /*PyObject *globals,*/
-        0                    /*PyObject *locals*/
-    );
-    if (!py_frame) goto bad;
-    py_frame->f_lineno = py_line;
-    PyTraceBack_Here(py_frame);
-bad:
-    Py_XDECREF(py_code);
-    Py_XDECREF(py_frame);
-}
-
-static int __Pyx_InitStrings(__Pyx_StringTabEntry *t) {
-    while (t->p) {
-        #if PY_MAJOR_VERSION < 3
-        if (t->is_unicode) {
-            *t->p = PyUnicode_DecodeUTF8(t->s, t->n - 1, NULL);
-        } else if (t->intern) {
-            *t->p = PyString_InternFromString(t->s);
-        } else {
-            *t->p = PyString_FromStringAndSize(t->s, t->n - 1);
-        }
-        #else  /* Python 3+ has unicode identifiers */
-        if (t->is_unicode | t->is_str) {
-            if (t->intern) {
-                *t->p = PyUnicode_InternFromString(t->s);
-            } else if (t->encoding) {
-                *t->p = PyUnicode_Decode(t->s, t->n - 1, t->encoding, NULL);
-            } else {
-                *t->p = PyUnicode_FromStringAndSize(t->s, t->n - 1);
-            }
-        } else {
-            *t->p = PyBytes_FromStringAndSize(t->s, t->n - 1);
-        }
-        #endif
-        if (!*t->p)
-            return -1;
-        ++t;
-    }
-    return 0;
-}
-
-
-/* Type Conversion Functions */
-
-static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
-   int is_true = x == Py_True;
-   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
-   else return PyObject_IsTrue(x);
-}
-
-static CYTHON_INLINE PyObject* __Pyx_PyNumber_Int(PyObject* x) {
-  PyNumberMethods *m;
-  const char *name = NULL;
-  PyObject *res = NULL;
-#if PY_VERSION_HEX < 0x03000000
-  if (PyInt_Check(x) || PyLong_Check(x))
-#else
-  if (PyLong_Check(x))
-#endif
-    return Py_INCREF(x), x;
-  m = Py_TYPE(x)->tp_as_number;
-#if PY_VERSION_HEX < 0x03000000
-  if (m && m->nb_int) {
-    name = "int";
-    res = PyNumber_Int(x);
-  }
-  else if (m && m->nb_long) {
-    name = "long";
-    res = PyNumber_Long(x);
-  }
-#else
-  if (m && m->nb_int) {
-    name = "int";
-    res = PyNumber_Long(x);
-  }
-#endif
-  if (res) {
-#if PY_VERSION_HEX < 0x03000000
-    if (!PyInt_Check(res) && !PyLong_Check(res)) {
-#else
-    if (!PyLong_Check(res)) {
-#endif
-      PyErr_Format(PyExc_TypeError,
-                   "__%s__ returned non-%s (type %.200s)",
-                   name, name, Py_TYPE(res)->tp_name);
-      Py_DECREF(res);
-      return NULL;
-    }
-  }
-  else if (!PyErr_Occurred()) {
-    PyErr_SetString(PyExc_TypeError,
-                    "an integer is required");
-  }
-  return res;
-}
-
-static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
-  Py_ssize_t ival;
-  PyObject* x = PyNumber_Index(b);
-  if (!x) return -1;
-  ival = PyInt_AsSsize_t(x);
-  Py_DECREF(x);
-  return ival;
-}
-
-static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t ival) {
-#if PY_VERSION_HEX < 0x02050000
-   if (ival <= LONG_MAX)
-       return PyInt_FromLong((long)ival);
-   else {
-       unsigned char *bytes = (unsigned char *) &ival;
-       int one = 1; int little = (int)*(unsigned char*)&one;
-       return _PyLong_FromByteArray(bytes, sizeof(size_t), little, 0);
-   }
-#else
-   return PyInt_FromSize_t(ival);
-#endif
-}
-
-static CYTHON_INLINE size_t __Pyx_PyInt_AsSize_t(PyObject* x) {
-   unsigned PY_LONG_LONG val = __Pyx_PyInt_AsUnsignedLongLong(x);
-   if (unlikely(val == (unsigned PY_LONG_LONG)-1 && PyErr_Occurred())) {
-       return (size_t)-1;
-   } else if (unlikely(val != (unsigned PY_LONG_LONG)(size_t)val)) {
-       PyErr_SetString(PyExc_OverflowError,
-                       "value too large to convert to size_t");
-       return (size_t)-1;
-   }
-   return (size_t)val;
-}
-
-
-#endif /* Py_PYTHON_H */
diff --git a/sandbox/ricker.h b/sandbox/ricker.h
deleted file mode 100644
index 6209f12..0000000
--- a/sandbox/ricker.h
+++ /dev/null
@@ -1,9 +0,0 @@
-#include "mapper.h"
-
-class RickerMapper : public Mapper
-{
-  enum param { r=0, d=1 };
-public:
-  RickerMapper();
-  IPoint map_point( const IPoint &curr ) const;
-};
diff --git a/sandbox/ricker.pyx b/sandbox/ricker.pyx
deleted file mode 100644
index 3430d07..0000000
--- a/sandbox/ricker.pyx
+++ /dev/null
@@ -1,19 +0,0 @@
-from rads.enclosure.cppdefs cimport *
-from rads.enclosure.cymapper cimport Mapper
-
-cdef extern from "ricker_cpp.h":
-	cdef cppclass cRicker "RickerMapper":
-		cRicker()
-		cIPoint map_point (cIPoint &v)
-	cRicker *new_Ricker "new RickerMapper" ()
-	void del_Ricker "delete" (cRicker *)
-
-cdef class RickerMapper(Mapper):
-
-	def __cinit__(self):
-		print "in RickernMapper cinit"
-		self.mapper = <cMapper *>new_Ricker()
-
-	def __dealloc__(self):
-		del_Ricker(<cRicker *>self.mapper)
-	
diff --git a/sandbox/ricker_cpp.cpp b/sandbox/ricker_cpp.cpp
deleted file mode 100644
index d5b5880..0000000
--- a/sandbox/ricker_cpp.cpp
+++ /dev/null
@@ -1,42 +0,0 @@
-#include "ricker_cpp.h"
-
-RickerMapper::RickerMapper() : Mapper( 3, "ricker" )
-{
-  params[r] = 5;
-  params[d] = 0.1;
-  param_names[r] = 'r';
-  param_names[d] = 'd';
-}
-
-IPoint RickerMapper::map_point(const IPoint &curr) const
-{
-    int row, col;
-    int d = dim();
-
-    // square set of patches of size dim x dim
-    IPoint w( d * d );
-    
-    // growth phase, can just run across array
-    for ( row = 0; row < d * d; row ++ )
-      {
-	w[ row ] = params[ r ] * curr[ row ] * exp( -curr[ row ] );
-      }
-
-    // dispersal phase
-    for ( row=0; row < d; row ++ )
-      for ( col=0; col < d; col ++ )
-	{
-	  // left and right dispersal
-	  if ( col != 0 )
-	    w[ d * row + (col-1) ] = params[ d ] * curr[ d * row + col] / 4.0;
-	  if ( col != d - 1 )
-	    w[ d * row + (col+1) ] = params[ d ] * curr[ d * row + col] / 4.0;
-	  // up and down dispersal
-	  if ( row != 0 )
-	    w[ d * (row - 1) + col ] = params[ d ] * curr[ d * row + col] / 4.0;
-	  if ( row != d - 1 )
-	    w[ d * (row + 1) + col ] = params[ d ] * curr[ d * row + col] / 4.0;
-	  // Now remove the dispersed mass from the current patch
-	  w[ d * row + col ] = ( 1 - params[ d ] ) * curr[ d * row + col ];    
-  return w;
-}
diff --git a/sandbox/test_index_map.py b/sandbox/test_index_map.py
deleted file mode 100644
index f5df8c0..0000000
--- a/sandbox/test_index_map.py
+++ /dev/null
@@ -1,152 +0,0 @@
-import numpy
-#from rads.symbolics.index_map_new import IndexMap
-from rads.symbolics.index_map_processor import IndexMapProcessor,IndexMap
-from rads.graphs import DiGraph
-from rads.misc import utils
-from rads.graphs import algorithms
-import matplotlib.pyplot as plt
-import networkx as nx
-
-
-if 0:
-      # column mapping: col idx --> row idx 
-        generators = numpy.matrix( [[0,0,0,1,0,0,0,0],
-                                    [0,0,0,0,1,0,0,0],
-                                    [0,0,0,0,1,0,0,0],
-                                    [0,0,0,0,0,1,0,0],
-                                    [-1,-1,0,0,0,0,0,0],
-                                    [0,0,0,0,0,0,-1,1],
-                                    [0,0,1,0,0,0,0,0],
-                                    [-1,0,0,0,0,0,0,0]]
-                                   ).T
-
-        # modified version 
-        # generators = numpy.matrix( [[0,0,0,1,0,0,0,0],
-        #                             [0,0,0,0,0,0,0,0],
-        #                             [0,0,0,0,1,0,0,0],
-        #                             [0,0,0,0,0,1,0,0],
-        #                             [-1,-1,0,0,0,0,0,0],
-        #                             [0,0,0,0,0,0,-1,1],
-        #                             [0,0,0,0,0,0,0,0],
-        #                             [-1,0,0,0,0,0,0,0]]
-        #                            ).T
-
-        regions = { 0 : [0],
-                    1 : [1,2],
-                    2 : [3],
-                    3 : [4],
-                    4 : [5],
-                    5 : [6,7]
-                    }
-
-        map_on_regions = numpy.matrix( [[0,0,1,0,0,0],
-                                        [0,0,0,1,0,0],
-                                        [0,0,0,0,1,0],
-                                        [1,1,0,0,0,0],
-                                        [0,0,0,0,0,1],
-                                        [1,1,0,0,0,0]]
-                                       )
-if 1:
-
-    hom_matrix = numpy.matrix( [[0,0,1,1,0],
-                                [0,0,0,0,1],
-                                [0,1,0,0,0],
-                                [0,0,1,1,-1],
-                                [0,0,-1,-1,1]]
-                               ).T
-
-    # A <--> 0, B <--> 1, etc.
-    region2gen = { 0 : [0,1],
-                   1 : [2],
-                   2 : [3,4]
-                   }
-
-    symbols = numpy.matrix( [[0,1,1],
-                             [1,0,0],
-                             [0,1,1]]
-                            )
-    map_on_regions = DiGraph()
-    map_on_regions.from_numpy_matrix( symbols )
-
-if 0:
-
-    hom_matrix = utils.load_matlab_matrix( 'henon_index.mat', 'hom_matrix' )
-    region2gen = utils.convert_matlab_gens( 'henon_gens.mat' )
-    map_on_regions = utils.index_map_to_region_map( hom_matrix, region2gen, shift=-1)
-
-if 0:
-    hom_matrix = utils.load_matlab_matrix( 'leslie_index.mat', 'hom_matrix' )
-    region2gen = utils.convert_matlab_gens( 'leslie_gens.mat' )
-    map_on_regions = utils.index_map_to_region_map( hom_matrix, region2gen, shift=-1)
-
-
-    ########################
-    #  
-    # APPEARS THAT BAD EDGE SETS ARE BEING THROWN INTO ONE (1) SET. CHECK THIS!!
-    #
-    ########################
-
-debug = True
-verbose = False
-
-scc_list, scc_components, recurrent_regions = algorithms.graph_mis( map_on_regions )
-# separate nodes by recurrent component
-nbunch = [ scc_components[i] for i in recurrent_regions ]
-recurrent_subgraphs = []
-for n in nbunch:
-    # ignore self-loops, no entropy
-    if len( n ) == 1:
-        continue
-    G = DiGraph()
-    G.graph = map_on_regions.graph.subgraph( n )
-    recurrent_subgraphs.append( G )
-
-# compute entropy for each scc in the symbolic system
-all_regions = []
-for scc in recurrent_subgraphs:
-    all_regions.append( IndexMapProcessor( hom_matrix, region2gen,
-                                           scc, debug=debug, verbose=verbose ) )
-
-# PARALLELIZE ME!
-for job in all_regions:
-    job.find_bad_edge_sets( 4 )  # argument == max path length
-    job.cut_bad_edge_sets()
-
-# print the best entropy for each SCC
-for imp in all_regions:
-    print imp.__repr__()
-    print "  Entropy for this region", imp.entropy
-    print ""
-
-   #  print ""
-#     print "  Drawing both transition graphs..."
-
-#     fig1 = plt.figure()
-#     ax1 = fig1.gca()
-#     ax1.set_title( "Original transition map on regions (subshift)" )
-#     pos1 = utils.nx.graphviz_layout( imp.map.graph )
-#     imp.unverified_symbolic_system.draw( ax=ax1, pos=pos1 )
-
-
-#     fig2 = plt.figure()
-#     ax2 = fig2.gca()
-#     ax2.set_title( "Best subshift found after trimming edges" )
-#     pos2 = utils.nx.graphviz_layout( imp.semi_conjugate_subshift.graph )
-#     imp.verified_symbolic_system.draw( ax=ax2, pos=pos2 )
-
-# plt.show()
-
-#IP = IndexMapProcessor( IM, debug=debug )
-
-# nbunch = [ scc_components[i] for i in recurrent_regions[:5] ] # just plot 5 SCC's
-# color = ['r', 'g', 'b', 'm', 'c']
-# for i,n in enumerate(nbunch):
-#     fig=plt.figure( i )
-#     ax = fig.gca()
-#     sg = IP.unverified_symbolic_system.graph.subgraph( nbunch=n )
-#     pos = nx.graphviz_layout( sg )
-#     print "s[",i,"] =", scc_components[i]
-#     nx.draw_networkx(  sg, pos=pos, node_color=color[i], ax=ax )
-#     fig.savefig( './figures/henon_symbol_map_scc'+str(i)+'.png' )
-#     #    IP.unverified_symbolic_system.draw( nodelist=n, node_color=color[i] )
-
diff --git a/sandbox/test_rigourous_entropy.py b/sandbox/test_rigourous_entropy.py
deleted file mode 100644
index 9f57791..0000000
--- a/sandbox/test_rigourous_entropy.py
+++ /dev/null
@@ -1,28 +0,0 @@
-from rads.symbolics.rigorous_entropy import RigorousEntropy
-
-# TEXT and NPY
-fname_npy = '/Users/jberwald/github/local/caja-matematica/rads/sandbox/leslie_index.npy'
-#fname_txt = '/Users/jberwald/github/local/caja-matematica/rads/sandbox/test_array.txt'
-
-reg_fname =  '/Users/jberwald/github/local/caja-matematica/rads/sandbox/leslie_gens.pkl'
-
-# MAT
-fname_mat = '/Users/jberwald/github/local/caja-matematica/rads/sandbox/leslie_index.mat'
-reg_mat = '/Users/jberwald/github/local/caja-matematica/rads/sandbox/leslie_gens.mat'
-matname = 'hom_matrix'
-
-# load from file
-re1 = RigorousEntropy()
-re1.load_from_file( fname_npy, reg_fname )
-re1.prepare_regions()
-re1.compute_entropy()
-
-
-# load from matrix and dict
-hom_matrix = utils.load_matlab_matrix( fname_mat, matname )
-region2gen = utils.convert_matlab_gens( reg_mat )
-
-re2 = RigorousEntropy( index_map=hom_matrix,
-                       reg2gen=region2gen )    
-re2.prepare_regions()
-re2.compute_entropy()
diff --git a/src/__init__.py b/src/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/src/rads/__init__.py b/src/rads/__init__.py
index 22a947b..54d5f85 100644
--- a/src/rads/__init__.py
+++ b/src/rads/__init__.py
@@ -1,11 +1,4 @@
-<<<<<<< HEAD
-__all__ = ["Graph", "DiGraph", "algorithms"]
+#__all__ = ["enclosure"]
 
-from graph import Graph
-from digraph import DiGraph
-import algorithms
-=======
-__all__ = ['gfx']
+#import enclosure
 
-import gfx
->>>>>>> adding-capd
diff --git a/src/rads/debug/bench_tree.py b/src/rads/debug/bench_tree.py
deleted file mode 100755
index f958f6a..0000000
--- a/src/rads/debug/bench_tree.py
+++ /dev/null
@@ -1,176 +0,0 @@
-#!/usr/bin/python
-
-import sys
-import numpy as np
-import numpy.random
-import matplotlib.pylab as plt
-from rads import UBoxSet,Tree,gfx
-import timeit
-
-def time_stuff(test_str,import_str,num_trials):
-	return timeit.Timer(test_str, import_str).timeit(number=num_trials)/num_trials
-
-
-dims = range(1,9)
-xbounds = {
-	1:(1,10),
- 	2:(1,8),
- 	3:(1,4),
- 	4:(1,3),
- 	5:(1,3),
- 	6:(1,3),
- 	7:(1,2),
-	8:(1,2),
-		}
-bounds = {
- 	1:(1,20),
-  	2:(1,12),
-  	3:(1,8),
-  	4:(1,6),
-  	5:(1,5),
-  	6:(1,4),
-  	7:(1,3),
- 	8:(1,3),
-	}
-
-results = {}
-funcs = ['insert','insert_box','search','search_box']
-trials_list = [1,1,1000,50]
-trials = {}
-
-def get_data(test):
-	np.random.seed(10)					# for consistency
-	d = {'insert':np.random.rand(10000,test['dim']),
-		 'insert_box':np.random.rand(1000,2,test['dim']),
-		 'search':np.random.rand(50,test['dim']),
-		 'search_box':np.random.rand(50,2,test['dim']),
-		 }
-	d['insert_box'][:,1] /= 2
-	d['search_box'][:,1] /= 2
-	return d
-			
-def get_tree(test):
-	bbox = np.tile([[0.0],[1]],test['dim'])		# unit cube
-	tree = Tree(bbox,depth=test['depth'],full=False)
-	return tree
-
-def bench(test,data):
-	print 'dimension %(dim)i at depth %(depth)i' % test;
-	test['results'] = {}
-	for f in funcs:
-		r = []
-		for i in range(len(data[f])):
-			t = time_stuff('tree.%s(data[\'%s\'][%i])' % (f,f,i),
-						   'from __main__ import tree, data',
-						   trials[f]) / trials[f]
-			r.append(t)
-		print '%12s: %6.8f' % (f,1000*np.mean(r))
-		test['results'][f] = r
-		results[f][test['dim']][test['depth']] = np.mean(r)
-
-def save_data(test,data):
-	for d in data:
-		if '_box' in d:
-			s = data[d].shape
-			data[d] = data[d].reshape(s[0]*s[1],s[2])
-		# print 'bench_%s_dim_%i_depth_%i.txt' % (d,test['dim'],test['depth'])
-		np.savetxt('bench_%s_dim_%i_depth_%i.txt' % (d,test['dim'],test['depth']),
-				   data[d])
-
-import pickle
-import time
-import scipy.io
-
-data = None
-tree = None
-print __name__
-if __name__ == "__main__":
-	tests = []
-	for dim in bounds:
-		tests += [{'dim':dim, 'depth':d}
-				  for d in
-				  range(bounds[dim][0],bounds[dim][1]+1)]
-	for t in range(len(trials_list)):
-		trials[funcs[t]] = trials_list[t]
-	for f in funcs:
-		results[f] = {}
-		for dim in bounds:
-			results[f][dim] = np.zeros(bounds[dim][1]+1)
-	print "running tests..."
-	for test in tests:
-		if tree:
-			del data
-			del tree
-		data = get_data(test)
-		tree = get_tree(test)
-		bench(test,data)
-		save_data(test,data)
-	datestr = time.strftime("%Y-%m-%d-%H-%M-%S")
-	pickle.dump(results,file('bench-results-%s.pickle' % (datestr),'w'))
-	pickle.dump(results,file('bench-results.pickle','w'))
-else:
-	results = pickle.load(file('bench-results.pickle','r'))
-	mat = scipy.io.loadmat('bench-tree.mat')['R'][0]
-	# matlab indices are: [dim,depth,func]
-
-
-	fgcolor = np.array([20,50,100])/255.
-	bgcolor = 0.9 + 0.1*fgcolor
-	plt.rcdefaults()
-	plt.rcParams['figure.subplot.right']='0.9'
-	plt.rcParams['figure.subplot.left']='0.2'
-	plt.rcParams['figure.subplot.top']='0.8'
-	plt.rcParams['ytick.major.pad']='10'
-	plt.rcParams['ytick.color']=fgcolor
-	plt.rcParams['xtick.color']=fgcolor
-	plt.rcParams['ytick.major.size']=4
-	plt.rcParams['xtick.major.size']=4
-	plt.rc('lines', linewidth=2)
-	plt.rc('text', color=fgcolor)
-	plt.rc('axes', linewidth=2, facecolor=bgcolor, edgecolor=fgcolor, labelcolor=fgcolor)
-	plt.show()
-
-	plotfuncs = [1,3]
-	labels = ['Insert','Search']
-	colors = [np.array([120,20,10])/255.,np.array([98,158,31])/255.]
-
-	plt.close('all')
-	fig = plt.figure(frameon=False)
-#	plt.title('depth 3')
-	depth = 3
-	for pf in range(len(plotfuncs)):
-		f = plotfuncs[pf]
-		x = dims
-		y = [-np.log(results[funcs[f]][dims[i]][depth-1] / mat[i][depth-1,f]) for i in range(len(dims))]
-		plt.plot(x,y,color=colors[pf])
-		plt.xlabel('dimension',size='large')
-		plt.ylabel('log(speedup) = log(matlab/python)',size='large')
-	plt.ylim(-0.5,6.5)
-	lg = plt.legend(labels,loc='upper left')
-	lg.get_frame().set_fill(False)
-	plt.savefig('/home/raf/Dropbox/cs262a/report/trees.pdf',bbox_inches='tight')
-
-	screwup
-
-
-# 		for f in range(len(funcs)):
-# 			fig = plt.figure()
-# 			plt.title(funcs[f])
-# 			for d in range(len(dims)):
-# 				x = np.arange(bounds[dims[d]][0],bounds[dims[d]][1]+1)
-# 				y = results[funcs[f]][dims[d]][bounds[dims[d]][0]:] / mat[d][:,f]
-# 				plt.plot(x,y)
-# 			plt.legend(dims)
-# 			plt.xlabel('depth')
-# 			plt.ylabel('py / mat')
-
-# 	fig = plt.figure()
-# #	plt.title('dimension 3')
-# 	d = 2    # dimension 3
-# 	for f in range(len(funcs)):
-# 		x = np.arange(bounds[dims[d]][0],bounds[dims[d]][1]+1)
-# 		y = results[funcs[f]][dims[d]][bounds[dims[d]][0]:] / mat[d][:,f]
-# 		plt.plot(x,y)
-# 		plt.xlabel('depth')
-# 		plt.ylabel('Python / Matlab')
-# 	plt.legend(funcs)
diff --git a/src/rads/debug/debug_tree.py b/src/rads/debug/debug_tree.py
deleted file mode 100644
index 96f895d..0000000
--- a/src/rads/debug/debug_tree.py
+++ /dev/null
@@ -1,45 +0,0 @@
-#!/usr/bin/python
-
-import sys
-sys.path.append("cython/build/")
-
-from rads import *
-from rads import gfx
-import numpy as np
-import numpy.random as random
-import matplotlib.pylab as plt
-
-box = np.array([[0.0,0],[8,8]])
-tree = Tree(box)
-tree.insert(np.array([1,1]))
-tree.subdivide()
-# tree.insert(np.array([1,1]))
-# tree.insert(np.array([5,1]))
-# tree.insert(np.array([1,5]))
-# tree.insert(np.array([5,5]))
-
-boxes = tree.boxes()
-print tree
-print boxes
-s = tree.search(np.array([[1,1],[1,4]]))
-print "tree.search(np.array([[1,1],[1,4]])) =", s
-print "should be [0,2]"
-s = tree.search(np.array([[1,1],[4,1]]))
-print "tree.search(np.array([[1,1],[4,1]])) =", s
-print "should be [0,1]"
-
-for i in range(0):
-	v = random.rand(2)*4 - 1
-	w = random.rand(2)*3
-	box = np.array([v,w])
-	s = tree.search(box)
-	print v,w,':',s
-	gfx.show_uboxes(boxes)
-	gfx.show_uboxes(boxes, S=s, col='r')
-	gfx.show_box(box,col='g')
-	plt.show()
-	plt.draw()
-	if raw_input("Press enter when done!")==0:
-		break
-	plt.close()
-
diff --git a/src/rads/enclosure/cymapper.pyx b/src/rads/enclosure/cymapper.pyx
index d868cec..e4f1062 100644
--- a/src/rads/enclosure/cymapper.pyx
+++ b/src/rads/enclosure/cymapper.pyx
@@ -7,6 +7,7 @@ cdef class Mapper:
 		print "in Mapper cinit"
 
 	def set_params(self,object dict):
+		print "here"
 		cdef vector[std_string] names = self.mapper.get_param_names()
 		cdef cIPoint p = self.mapper.get_params()	# so we can only overwrite a few and leave the rest
 		for k in dict.keys():
@@ -15,6 +16,7 @@ cdef class Mapper:
 					p.set(i,array2interval(dict[k]))
 					break
 		self.mapper.set_params(p)
+		print "set params..."
 
 	def get_params(self):
 		cdef cIPoint p = self.mapper.get_params()	# so we can only overwrite a few and leave the rest
diff --git a/src/rads/graphs/algorithms.py b/src/rads/graphs/algorithms.py
index 839ca72..8bc6bf6 100644
--- a/src/rads/graphs/algorithms.py
+++ b/src/rads/graphs/algorithms.py
@@ -35,15 +35,26 @@ def condensation( G, components ):
 				cG.add_edge(mapping[u], mapping[v])
 	return cG
 
-def graph_mis( G ):
+def condensation_nx( G, components) :
+	"""
+	G : DiGraph object. the nx.DiGraph attribute is extracted from this.
+
+	components : 	Given components C_1 .. C_k which partition the nodes of G, the
+	condensation graph cG has nodes <C_1> .. <C_k> and has edge
+	(<C_i>,<C_j>) iff there was an edge in G from a node in C_i to a
+	node in C_j.
+	"""
+	cG = DiGraph()
+	cG.graph = nx.condensation( G, components )
+	return cG
+
+def graph_mis( G, return_rsccs=False ):
 	"""Return the maximal invariant set of a graph G.
 
 	Given a graph G, the maximal invariant set (MIS) is the maximal
 	subset S of nodes such that for every node v in S, there exists a
 	bi-infinite walk in G which passes through v.
 
-	NOTE: UNTESTED!!
-
 	Parameters
 	----------
 	G : DiGraph
@@ -56,21 +67,32 @@ def graph_mis( G ):
 	if len(G)==0:
 		return []
 	sccs,rsccs = scc_raf( G )
-	C = condensation( G,sccs )
-	forward = set( descendants( C,rsccs ) )
-	
-	# need to construct new DiGraph() wrapper around reversed
-	# C. Otherwise, rC.graph ends up null because the revered copy
-	# is an NX object, and NX.Graph.graph holds the *name* of the
-	# graph.
-	rC = C.reverse( copy=True )
-	rG = DiGraph() # new reversed DiGraph
-	rG.graph = rC
-	backward = set( descendants( rG,rsccs ) )
-
-	# backward = set( descendants( C.reverse( copy=False ),rsccs ) )
+	#C = condensation( G, sccs )
+	C = condensation_nx( G.graph, sccs )
+	forward = set( descendants( C, rsccs ) )
+	C.reverse()
+	backward = set( descendants( C, rsccs ) )
 	cnodes = forward & backward
-	return list(itertools.chain(*[sccs[c] for c in cnodes])) #, sccs, rsccs
+	if return_rsccs:
+		return list(itertools.chain(*[sccs[c] for c in cnodes])), sccs, rsccs
+	else:
+		return list(itertools.chain(*[sccs[c] for c in cnodes]))
+def descendants(G,S):
+	"""Decendents of S (subset of nodes) in G"""
+	G_nx = G.graph # get right to nx
+	n = len(G_nx)
+	G_nx.add_node(n)
+	for s in S:
+		G_nx.add_edge(n,s)
+	d = list( nx.algorithms.dfs_postorder_nodes(G_nx,n) )
+	d.remove(n)		# TODO: make more efficient!
+	# JJB - since dfs_postorder_nodes return a generator, we must
+	# keep the 'star' node n in until the generator is complete
+	# RMF - casting to a list for now, for simplicity
+	# JJB - when casting to a list, make sure to close your parens ;)
+	G_nx.remove_node(n)
+	return d
+                
 
 def first_return_times( k, backwards=False ):
 	"""
@@ -137,7 +159,7 @@ def scc_raf(G):
 	scc_found={}
 	scc_queue = []
 	scc_list=[]
-	real_scc_inds=[]					# RAF
+	real_scc_inds=[]	# RAF
 	i=0		# Preorder counter
 	for source in G_nx:
 		if source not in scc_found:
@@ -179,24 +201,7 @@ def scc_raf(G):
 						scc_queue.append(v)
 	# RAF: removed sorting... don't really need it
 	# scc_list.sort(key=len,reverse=True)			
-	return scc_list,real_scc_inds
-
-def descendants(G,S):
-	"""Decendents of S (subset of nodes) in G"""
-	G_nx = G.graph # get right to nx
-	n = len(G_nx)
-	G_nx.add_node(n)
-	for s in S:
-		G_nx.add_edge(n,s)
-	d = list(nx.algorithms.dfs_postorder_nodes(G_nx,n))
-	d.remove(n)		# TODO: make more efficient!
-	# JJB - since dfs_postorder_nodes return a generator, we must
-	# keep the 'star' node n in until the generator is complete
-	# RMF - casting to a list for now, for simplicity
-	# JJB - when casting to a list, make sure to close your parens ;)
-	G_nx.remove_node(n)
-	return d
-                
+	return scc_list, real_scc_inds
 	
 def blockmodel(G,partitions,multigraph=False):
     """
diff --git a/src/rads/graphs/digraph.py b/src/rads/graphs/digraph.py
index 72ad2c0..665b406 100644
--- a/src/rads/graphs/digraph.py
+++ b/src/rads/graphs/digraph.py
@@ -52,13 +52,14 @@ class DiGraph( Graph ):
         """Return a list of predecessor nodes of n."""
         return self.graph.predecessors(n)
 
-    # def number_of_nodes(self):
-    #     """Return the number nodes in a graph."""
-    #     return self.graph.number_of_nodes()
-
-    # def number_of_edges(self):
-    #     """Return number of edges in a graph."""
-    #     return self.graph.number_of_edges()
+    def subgraph( self, nbunch ):
+        """
+        Return DiGraph on nbunch nodes. See Graph object of NetworkX.
+        """ 
+        subG = self.graph.subgraph( nbunch )
+        S = DiGraph()
+        S.graph = subG
+        return S
 
     def from_numpy_matrix( self, mat ):
         """
@@ -66,9 +67,9 @@ class DiGraph( Graph ):
         """
         self.graph = nx.from_numpy_matrix( mat, create_using=self.graph )
 
-    def reverse( self, copy=True ):
+    def reverse( self, copy=False ):
         """
-        Return the reverse of the graph.
+        Return the reverse of the graph. 
 
         The reverse is a graph with the same nodes and edges
         but with the directions of the edges reversed.
@@ -77,10 +78,18 @@ class DiGraph( Graph ):
         ----------
         copy : bool optional (default=True)
             If True, return a new DiGraph holding the reversed edges.
-            If False, reverse the reverse graph is created using
-            the original graph (this changes the original graph).
+            If False, reverse the reverse graph is created using the
+            original graph (this changes the original graph). Returns
+            a new RADS DiGraph if True.
         """
-        return self.graph.reverse( copy=copy )
+        if copy:
+            Rnx = self.graph.reverse( copy=copy )
+            RG = DiGraph()
+            RG.graph = Rnx
+            return RG
+        else:
+            Rnx = self.graph.reverse()
+            self.graph = Rnx
 
     def copy( self ):
 	"""
diff --git a/src/rads/graphs/graph.py b/src/rads/graphs/graph.py
index 435a1c7..3905cb5 100644
--- a/src/rads/graphs/graph.py
+++ b/src/rads/graphs/graph.py
@@ -441,6 +441,26 @@ class Graph( object ):
 		"""
 		return self.graph.edges_iter( nbunch, data )
 
+        def subgraph( self, nbunch ):
+		"""
+		Return the subgraph induced on nodes in nbunch in the
+		form of a Graph() object.
+
+		Parameters
+		----------
+		nbunch : list, iterable
+		   A container of nodes that will be iterated through once (thus
+		   it should be an iterator or be iterable).  Each element of the
+		   container should be a valid node type: any hashable type except
+		   None.  If nbunch is None, return all edges data in the graph.
+		   Nodes in nbunch that are not in the graph will be (quietly)
+		   ignored.
+		"""
+		subG = self.graph.subgraph( nbunch )
+		S = Graph()
+		S.graph = subG
+		return S
+
 	def clear(self):
 		"""Remove all nodes and edges from the graph.
 
diff --git a/src/rads/graphs/graphs.py b/src/rads/graphs/graphs.py
deleted file mode 100644
index 64d1bbb..0000000
--- a/src/rads/graphs/graphs.py
+++ /dev/null
@@ -1,121 +0,0 @@
-import networkx as nx
-import itertools
-
-def scc_raf(G):
-	"""Return nodes in strongly connected components of graph.
-
-	Parameters
-	----------
-	G : NetworkX Graph
-	   An directed graph.
-
-	Returns
-	-------
-	comp : list of lists
-	   A list of nodes for each component of G.
-	   The list is ordered from largest connected component to smallest.
-
-	See Also	   
-	--------
-	connected_components
-
-	Notes
-	-----
-	Uses Tarjan's algorithm with Nuutila's modifications.
-	Nonrecursive version of algorithm.
-	"""
-	preorder={}
-	lowlink={}	 
-	scc_found={}
-	scc_queue = []
-	scc_list=[]
-	real_scc_inds=[]					# RAF
-	i=0		# Preorder counter
-	for source in G:
-		if source not in scc_found:
-			queue=[source]
-			while queue:
-				v=queue[-1]
-				if v not in preorder:
-					i=i+1
-					preorder[v]=i
-				done=1
-				v_nbrs=G[v]
-				for w in v_nbrs:
-					if w not in preorder:
-						queue.append(w)
-						done=0
-						break
-				if done==1:
-					lowlink[v]=preorder[v]
-					for w in v_nbrs:
-						if w not in scc_found:
-							if preorder[w]>preorder[v]:
-								lowlink[v]=min([lowlink[v],lowlink[w]])
-							else:
-								lowlink[v]=min([lowlink[v],preorder[w]])
-					queue.pop()
-					if lowlink[v]==preorder[v]:
-						scc_found[v]=True
-						scc=[v]
-						while scc_queue and preorder[scc_queue[-1]]>preorder[v]:
-							k=scc_queue.pop()
-							scc_found[k]=True
-							scc.append(k)
-						# RAF: changed here to exclude 'transient' SCCs
-						# thus, single vertices are SCCs iff they are loops
-						scc_list.append(scc)
-						if len(scc)>1 or G.has_edge(scc[0],scc[0]):
-							real_scc_inds.append(len(scc_list)-1) # index of the scc
-					else:
-						scc_queue.append(v)
-	# RAF: removed sorting... don't really need it
-	# scc_list.sort(key=len,reverse=True)			
-	return scc_list,real_scc_inds
-
-def condensation(G,sccs):
-	"""Returns the condensation of G.
-
-	The condensation of G is the graph with each of the strongly connected
-	components contracted into a single node.
-
-	Parameters
-	----------
-	G : NetworkX Graph
-	   A directed graph.
-
-	Returns
-	-------
-	cG : NetworkX DiGraph
-	   The condensation of G.
-
-	Notes
-	-----
-	After contracting all strongly connected components to a single node,
-	the resulting graph is a directed acyclic graph.
-
-	"""
-	mapping = dict([(n,c) for c in range(len(sccs)) for n in sccs[c]])
-	cG = nx.DiGraph()
-	for u in mapping:
-		cG.add_node(mapping[u])
-		for _,v,d in G.edges_iter(u, data=True):
-			if v not in sccs[mapping[u]]:
-				cG.add_edge(mapping[u], mapping[v])
-	return cG
-
-def graph_mis(G):
-	sccs,rsccs = scc_raf(G)
-	C = condensation(G,sccs)
-	cnodes = set(descendents(C,rsccs)) & set(descendents(C.reverse(copy=False),rsccs))
-	return list(itertools.chain(*[sccs[c] for c in cnodes]))
-
-def descendents(G,S):
-	n = len(G)
-	G.add_node(n)
-	for s in S:
-		G.add_edge(n,s)
-	d = nx.algorithms.dfs_postorder(G,n)
-	G.remove_node(n)
-	return d[:-1]
-
diff --git a/src/rads/graphs/im_graph.py b/src/rads/graphs/im_graph.py
deleted file mode 100644
index 6c8be11..0000000
--- a/src/rads/graphs/im_graph.py
+++ /dev/null
@@ -1,225 +0,0 @@
-"""
-im_graphs.py
-
-Opened: Feb. 10, 2012
-
-Author: Jesse Berwald
-
-Module containing wrappers and algorithms for index map information
-and subroutines. Index_Map is a wrapper around the DiGraph class,
-which inherits from NetworkX's DiGraph class, with (probably) some
-conversion methods.
-"""
-from graphs import digraph
-
-  
-####################
-## INDEX_MAP
-####################
-class Index_Map( digraph.DiGraph ):
-    """
-    A representation of the map induced on homology. That is,
-
-    f_{P*} : H_{*}(P_1,P_0) ---> H_{*}(P_1,P_0),
-
-    where (P_1,P_0) form an index pair. 
-
-    Inherits from
-    ----------
-
-    DiGraph
-
-    Parameters
-    ---------
-
-    See DiGraph class
-    """
-    def __init__( self, **kwargs ):        
-        fargs = {'graph' : None,
-                 'generators' : None,
-                 'genfile' : None,
-                 'name' : 'Index Map on homology',
-                 'debug' : False
-                 }
-        fargs.update( kwargs )
-
-        # initialize DiGraph
-        digraph.DiGraph.__init__( self, **fargs )
-        self.debug = fargs['debug']
-
-        # set the info attribute
-        self._update_info()
-                    
-    def __repr__( self ):
-        return self.info
-
-    def _update_info( self ):
-        self.info = "Index map on "+ str( len(self) )+" generators."
-                
-    def trim_generators( self, genfile=None ):
-        """
-        Trim generators to get rid of those that have been removed
-        (i.e. the non-invariant generators).  Generators are stored in
-        a dictionary keyed by region. Each region is a disjoint index
-        pair that is a component of the isolating neighborhood
-        computed by the analysis on the original map F on phase space.
-
-        Eg.,
-
-        {0: set([1]),
-        1: set([2, 3]),
-        2: set([4])}
-
-        lists a potential generators 1,2,3,4, that are supported on
-        regions N_0, N_1, and N_2.
-
-        Parameters
-        ---------
-
-        genfile : path to a dictionary or matlab cell array containing
-        the generator hash.
-        """
-        # fill this in later
-        if not self.generators:
-            pass
-        # generators have already been initialized
-        else:
-            pop = []
-            for k in self.generators:
-                try:
-                    gens = self.generators[k].difference( self.non_mis_nodes )
-                    # record transient gen keys; can't pop them here
-                    # or it changes dict length mid-loop
-                    if len( gens )==0:
-                        pop.append( k )
-                # quietly pass over regions with no generators. 
-                except AttributeError:
-                    continue
-            # Get rid of keys associated with transient generators
-            for k in pop: self.generators.pop( k )
-
-    def _generators2regions( self ):
-        """
-        Map the region number that each generator/node resides in to a
-        node property. This maps the keys of self.generators to the
-        nodes.
-        """
-        for region in self.generators:
-            for gen in self.generators[region]:
-                self.node[gen] = {'region': region}
-                
-    def remove_transient_generators( self, copy=False,  only_scc=False ):
-        """
-        Construct a graph that is asymtotically 'similar' to the
-        original. If the index map F is represented by a matrix, we
-        seek a change of basis that yields a matrix that is shift
-        equivalent to the orginal index map F. Graphically, this is
-        equivalent to 1) finding the strongly connected components; 2)
-        trimming the nodes that are not both forward and backward
-        invariant. (This uses the graph algorithms developed in Lemmas
-        3.2-3.4 of Day, et al., to arrive at a graph representation of
-        the matrix A.
-
-        Parameters
-        ---------
-
-        k : maximum length of path forward and backward paths to
-        search. Default=-1, corresponds to infintiy.
-
-        copy : copy the old index map graph to self.full_index_map prior to 
-
-        only_scc : Only find the strongly conected components and list
-        of indices with single nodes removed.
-        """
-        # first find the strongly connected components
-        if only_scc:
-            self.scc_list, self.scc_idx = GM.scc_raf( self )
-        elif copy:
-            # store the original, full index map before performing
-            # shift equivalence reduction
-            self.full_index_map = self.copy()
-        # use graph algorithms to find the invariant regions and
-        # corresponding shift equivalence
-        mis_nodes = self.graph_mis()
-        # trim off noninvariant nodes
-        non_mis_nodes = set( [u for u in self
-                              if u not in mis_nodes] )
-        self.remove_nodes_from( non_mis_nodes )
-        # update the __repr__ information
-        self._update_info()
-        
-     
-    def contract_index_map( self ):
-        """
-        Create a block model of the Index Map by contracting
-        nodes/generators based on regions in which they reside. I.e.,
-        if generators i and j are both from region r, contract nodes i
-        and j to a single node.
-
-        Returns Index_Map graph of the block model of self
-        """
-        # map the regions to the nodes
-        self._generators2regions()
-        node_map = nx.get_node_attributes( self, 'region' )
-        inv_map = {}
-        for k, v in node_map.iteritems():
-            inv_map[v] = inv_map.get(v, [])
-            inv_map[v].append(k)
-        self.blocks = list( chain(inv_map.itervalues()) )
-        # use modified blockmodel() from utils
-        return DiGraph( graph=utils.blockmodel( self, self.blocks ),
-                        name='Contracted Map' )
-    
-
-if __name__ == "__main__":
-
-    import numpy as np
-    from pylab import *
-
-    matlab = False
-    npy = True
-    graph=False
-    make_plot = False
-    
-    if matlab:
-        matfile = '/Users/jberwald/Dropbox/Projects/entropy/ds.bak/hom_map.mat'
-        genfile =  '/Users/jberwald/Dropbox/Projects/entropy/ds.bak/gens.mat'
-        IM = Index_Map( matfile=matfile, genfile=genfile )     
-    elif npy:
-        idxfile = '/Users/jberwald/Dropbox/Projects/entropy/rads/src/'\
-            'symbolics/debug/index_map.npy'
-        genfile =  '/Users/jberwald/Dropbox/Projects/entropy/ds.bak/gens.mat'
-        print "creating Index_Map object from", idxfile
-        print ""
-        IM = Index_Map( npyfile=idxfile, genfile=genfile )
-    elif graph:
-        print "creating Index_Map object from", G
-        print ""
-        IM = Index_Map( graph=G )
-
-    print "index map constructed with", len(IM), "generators"
-    # draw the graph before finding shift equivalence
-    if make_plot:
-        fig = figure()
-        ax = fig.gca()
-        #IM.draw_graph( ax=ax )
-        pos = nx.spring_layout( IM )
-        G = IM.copy()
-        nx.draw_networkx( G, pos=pos, ax=ax, alpha=0.7 )
-
-    # Compute shift equivalence 
-    IM.remove_transient_generators( copy=True )
-    IM.trim_generators()
-    cim = IM.contract_index_map()
-    print "index map after shift equivalence now has", len(IM), "generators"
-    # draw the new, condensed graph
-    if make_plot:
-        nx.draw_networkx_nodes( G, pos=pos, nodelist=IM.nodes(), node_color='g', alpha=0.8 )
-        fig2 = figure()
-        ax2 = fig2.gca()
-        IM.draw_graph( ax=ax2, nodelist=IM.nodes(), node_color='g', alpha=0.7 )
-
-        figure()
-        cim.draw_graph( node_color='b', alpha=0.7 )
-        
-        show()
diff --git a/src/rads/graphs/simple_cycles.py b/src/rads/graphs/simple_cycles.py
deleted file mode 100644
index 4993cd1..0000000
--- a/src/rads/graphs/simple_cycles.py
+++ /dev/null
@@ -1,249 +0,0 @@
-import networkx as nx
-import numpy as np
-from collections import defaultdict
-
-
-
-def simple_cycles_jjb( G ):
-    """Find simple cycles (elementary circuits) of a directed graph.
-    
-    An simple cycle, or elementary circuit, is a closed path where no 
-    node appears twice, except that the first and last node are the same. 
-    Two elementary circuits are distinct if they are not cyclic permutations 
-    of each other.
-
-    Parameters
-    ----------
-    G : NetworkX DiGraph
-       A directed graph
-
-    Returns
-    -------
-    A list of circuits, where each circuit is a list of nodes, with the first 
-    and last node being the same.
-    
-    Example:
-    >>> G = nx.DiGraph([(0, 0), (0, 1), (0, 2), (1, 2), (2, 0), (2, 1), (2, 2)])
-    >>> nx.simple_cycles(G)
-    [[0, 0], [0, 1, 2, 0], [0, 2, 0], [1, 2, 1], [2, 2]]
-    
-    See Also
-    --------
-    cycle_basis (for undirected graphs)
-    
-    Notes
-    -----
-    The implementation follows pp. 79-80 in [1]_.
-
-    The time complexity is O((n+e)(c+1)) for n nodes, e edges and c
-    elementary circuits.
-
-    References
-    ----------
-    .. [1] Finding all the elementary circuits of a directed graph.
-       D. B. Johnson, SIAM Journal on Computing 4, no. 1, 77-84, 1975. 
-       http://dx.doi.org/10.1137/0204007
-
-    See Also
-    --------
-    cycle_basis
-    """
-    # Jon Olav Vik, 2010-08-09
-    def _unblock(thisnode):
-        """Recursively unblock and remove nodes from B[thisnode]."""
-        if blocked[thisnode]:
-            blocked[thisnode] = False
-            while B[thisnode]:
-                _unblock(B[thisnode].pop())
-
-    # JJB -- 2012-05-15
-    def _zero_trace( mat ):
-        try:
-            if np.trace( mat ) == 0:
-                return True
-            else:
-                return False
-        except ValueError:
-            if mat == 0:
-                return True
-            else:
-                return False       
-
-    # JJB -- 2012-05-15
-    def _zero_product( mat ):
-        nz = mat.nonzero()
-        # nonzero() return nz elements by axes, so if anything is
-        # nonzero, the first axis will show up with length > 0
-        if nz[0].size > 0:
-            return True
-        else:
-            return False
-    
-    def circuit(thisnode, startnode, component, genmap=1):
-        closed = False # set to True if elementary path is closed
-        path.append(thisnode)
-        blocked[thisnode] = True
-
-        # JJB -- 2012-05-15, added map_on_gen
-        print "thisnode", thisnode
-        for nextnode, map_on_gen in component[thisnode].items(): # direct successors of thisnode
-            print "  nextnode", nextnode
-            try:
-                gen_products.append( map_on_gen['gen'] * gen_products[-1] )
-            except ValueError:
-                gen_products.append( map_on_gen['gen'] * gen_products[-2] )
-            # This path contains a prohibited edge, move on
-            if not _zero_product( gen_products[-1] ):
-                print "  zero, path", path
-                print "    product", gen_products
-                # print "*********"
-                # print "ZERO"
-                # print "*********"
-                # get rid of the last zero product so it's not used in further calculations
-                gen_products.pop()
-                continue
-            if nextnode == startnode:
-                # This cycle is not verifiable
-                if _zero_trace( gen_products[-1] ):
-                    continue
-                else:
-                    result.append(path + [startnode])
-                    print "RESULT", result[-1]
-                    print "matrix product", gen_products[-1]
-                    print ""
-                closed = True
-            elif not blocked[nextnode]:
-                if circuit(nextnode, startnode, component, genmap=gen_products[-1]):
-                    closed = True
-        if closed:
-            _unblock(thisnode)
-        else:
-            for nextnode in component[thisnode]:
-                if thisnode not in B[nextnode]: # TODO: use set for speedup?
-                    B[nextnode].append(thisnode)
-        path.pop() # remove thisnode from path
-        return closed
-    
-    if not G.is_directed():
-        raise nx.NetworkXError(\
-            "simple_cycles() not implemented for undirected graphs.")
-    path = [] # stack of nodes in current path
-    blocked = defaultdict(bool) # vertex: blocked from search?
-    B = defaultdict(list) # graph portions that yield no elementary circuit
-    result = [] # list to accumulate the circuits found
-    # Johnson's algorithm requires some ordering of the nodes.
-    # They might not be sortable so we assign an arbitrary ordering.
-    ordering=dict(zip(G,range(len(G))))
-    for s in ordering:
-        # Build the subgraph induced by s and following nodes in the ordering
-        subgraph = G.subgraph(node for node in G 
-                              if ordering[node] >= ordering[s])
-        # Find the strongly connected component in the subgraph 
-        # that contains the least node according to the ordering
-        strongcomp = nx.strongly_connected_components(subgraph)
-        mincomp=min(strongcomp, 
-                    key=lambda nodes: min(ordering[n] for n in nodes))
-        component = G.subgraph(mincomp)
-        if component:
-            # new generator product
-            gen_products = [1]
-            # smallest node in the component according to the ordering
-            startnode = min(component,key=ordering.__getitem__) 
-            for node in component:
-                blocked[node] = False
-                B[node][:] = []
-            dummy=circuit(startnode, startnode, component)
-    
-    return result
-
-def create_subshift_matrix( cycles, num_regions ):
-    """
-    From verified cycles, construct appropiate adjacency matrix.
-    """
-    subshift = np.zeros( (num_regions, num_regions), dtype=np.int )
-    for cycle in cycles:
-        c = zip( cycle[:-1], cycle[1:] )
-        for e in c:
-            subshift[e] = 1
-    return subshift.T
-
-
-if __name__ == "__main__":
-
-    #import index_map as IM
-    import index_processor as IP
-
-    if 1:
-        map_on_generators = np.matrix( [[0,0,0,0,-1,0,0,-1],
-                                        [0,0,0,0,-1,0,0,0],
-                                        [0, 0, 0, 0, 0, 0, 1, 0],
-                                        [1, 0, 0, 0, 0, 0, 0, 0],
-                                        [ 0 ,1, 1, 0, 0, 0, 0, 0],
-                                        [0, 0, 0, 1, 0, 0, 0, 0],
-                                        [0, 0, 0, 0, 0, -1, 0,0],
-                                        [0, 0, 0, 0, 0, 1, 0,0]]
-                                        ).T
-
-        # have to adjust for mutiple generators in each region
-        # nodes refer to regions, and index ranges give generators within
-        # said region
-        A = map_on_generators
-        index_edges = { (0,2): A[0,3].T,
-                        (1,3): A[1:3,4].T,
-                        (2,4): A[3,5].T,
-                        (3,0): A[4,0].T,
-                        (3,1): A[4,1:3].T,
-                        (4,5): A[5,6:8].T,
-                        (5,0): A[6:8,0].T,
-                        (5,1): A[6:8,1:3].T
-                        }
-
-        map_on_regions = np.matrix( [[0,0,0,1,0,1],
-                                     [0, 0, 0, 1, 0, 1],
-                                     [1,0, 0, 0, 0, 0],
-                                     [0, 1, 0, 0, 0, 0],
-                                     [0,0,1,0,0,0],
-                                     [0,0,0,0,1,0]]
-                                     ).T
-
-        G = nx.DiGraph()
-        nx.from_numpy_matrix( map_on_regions, create_using=G )
-        for e, gmap in index_edges.items():
-            G[ e[0] ][ e[1] ][ 'gen' ] = gmap
-
-        cycles = simple_cycles_jjb( G )
-        print ""
-        print "cycles", cycles
-
-        T = create_subshift_matrix( cycles, num_regions=len(G) )
-
-        spectral_radius = np.abs( np.linalg.eigvals( T ).max() )
-        entropy = np.log( spectral_radius )
-        print "entropy", entropy
-
-    if 0:
-        map_on_generators = np.matrix([[0,1],[1,1]])
-
-        A = map_on_generators
-
-        index_edges = { (0,0): A[0,0].T,
-                        (0,1): A[0,1],
-                        (1,0): A[1,0],
-                        (1,1): A[1,1]
-                        }
-
-        map_on_regions = np.matrix( [[1,1],[1,1]] )
-        G = nx.DiGraph()
-        nx.from_numpy_matrix( map_on_regions, create_using=G )
-        for e, gmap in index_edges.items():
-            G[ e[0] ][ e[1] ][ 'gen' ] = gmap
-
-        cycles = simple_cycles_jjb( G )
-        print ""
-        print "cycles", cycles
-
-        T = create_subshift_matrix( cycles, num_regions=len(G) )
-
-        spectral_radius = np.abs( np.linalg.eigvals( T ).max() )
-        entropy = np.log( spectral_radius )
-        print "entropy", entropy
diff --git a/src/rads/homology/__init__.py b/src/rads/homology/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/src/rads/homology/homology.py b/src/rads/homology/homology.py
new file mode 100644
index 0000000..a592fa5
--- /dev/null
+++ b/src/rads/homology/homology.py
@@ -0,0 +1,294 @@
+import networkx as nx
+from rads.graphs import algorithms
+from rads.misc import utils
+import numpy as np
+import random, time
+import subprocess as sp
+
+debug = True
+
+# from SO http://stackoverflow.com/questions/6800193
+factors = lambda n: set(reduce(list.__add__, 
+                  ([i, n//i] for i in range(1, int(n**0.5) + 1)
+                   if n % i == 0)))
+
+
+def get_cycles( P, max_period=2 ):
+    """
+    P : Directed graph
+
+    P will be converted to sparse transition matrix for multiplication
+    and cycle detection.
+    """
+    C = utils.to_sparse( P )
+    nodes = P.nodes()
+    nodes.sort()
+
+    # Create a node map, index --> node number.  The graph
+    # representation typically respects the original box ordering (at
+    # least at that depth of the tree), whereas the sparse matrix
+    # indexing is 0,...,len(nbunch).  The hash allows a quick link
+    # between a sparse matrix representation of a combinatorial map
+    # and a graph representation.
+    # Note: searching a dictionary (eg. x in d) is O(1), while search
+    # for containment in a list is O(n). Test using %timeit x in d ==>
+    # 23.5 us (list), 70.6 ns (dict).
+    nodemap = utils.make_node_hash( nodes )
+
+    # convert to compressed sparse row format for efficiency
+    #C = sp.tocsr()
+    # period 1,2,..., max_period. This dict format will make plotting
+    # different cycles and connections easier in the future.
+    if debug:
+        print "looking for cycles..."
+    cycles = {}
+    for k in range( 1, max_period+1 ):
+        Ck = C**k 
+        pk = set( np.where( Ck.diagonal() )[0] )
+
+        # don't repeat multiples of cycles
+        if k > 1:
+            # find all factors of k
+            facs = list( factors( k ) )[:-1]
+            # remove all nodes from cycles of length j < k if j is a
+            # factor of k (excluding k itself)
+            for j in range( 1, k ):
+                # if a shorter cycle of length j is a factor of the
+                # cycles length k then we want to exclude it. see
+                # above.
+                if j in facs:
+                    pk.difference_update( cycles[ j ] )
+        if len( pk ) == 0:
+            continue
+        cycles[ k ] = pk
+
+    Pcycles = {}
+    for k,cyc in cycles.iteritems():
+        pk = set()
+        for c in cyc:
+            # apply the node map
+            pk.add( nodemap[ c ] )
+        Pcycles[ k ] = pk
+        
+    if debug:
+        print "Cycle stats:\n"
+        ckeys = cycles.keys()
+        ckeys.sort()
+        for c in ckeys:
+            print "    "+str(len(cycles[c]))+" period "+str( c )+\
+                " cycles."
+        print ""
+    return Pcycles
+
+def connect_cycles( A, B, P ):
+    """
+    A : set of period k orbits
+
+    B : a set of period k' orbits
+
+    P : transition graph
+
+    TODO : Split up and choose only one node/box from each cycle. This
+    is redundant as it loops through the cycles.
+    """
+    C = set()
+    for u in A:
+        for v in B:
+            if u != v:
+                # conns holds connecting nodes in path, but not the
+                # start/end nodes.
+                conn = connections( P, u, v )
+                C.update( conn )
+    return C
+
+def connections( G, u, v ):
+    """
+    Find connections from one set of nodes to another (preds and
+    succs, resp.).
+    """
+    conns = nx.dijkstra_path( G.graph, u, v )
+    return conns[1:-1] # trim endpoints
+        
+def isolated( A, oI, S ):
+    """
+    Check whether the maximal invariant set is in the interior of oI.
+    
+    A : adjacency graph
+    
+    oI : one box neighborhood
+
+    S : maximal invariant set
+    """
+    inv_map = A.inv_nodemap #convert.invert_dictionary( A.nodemap )
+    # does the inv_set have any one-box neighbors that are not in oI?
+    # Find adjacent boxes in order to figure this out.
+    oI_adj = set( [inv_map[u] for u in oI] )
+    S_adj = set( [inv_map[u] for u in S] )
+    # Are there any neighbors of u in S that are not in oI?  If
+    # so, then S can't be in the interior.
+    for u in S_adj:
+        nbrs_u = set( A.graph.neighbors( u ) )
+        if not nbrs_u.issubset( oI_adj ):
+            return False
+    else:
+        return True
+
+def grow_iso( S, A, P ):
+    """
+    S : index set of boxes in invariant set
+    
+    P : transition graph
+
+    A : Adjacency graph
+
+    Grow a combinatorial isolating neighborhood N containing S. Return
+    None if condition is not met.
+
+    Algorithm 1 in Day, et al, 2008.
+    """
+    while 1:							
+        N = set( algorithms.graph_mis( P.subgraph( S ) ) )
+        oN = get_onebox( N, A )
+
+        # print "in grow_iso"
+        # print oN - N
+        # print ""
+        
+        if N.issubset( oN ):
+            return oN
+        N = oN
+    
+def get_onebox( S, A ):
+    """
+    Return an isolating, one-box neighborhood around the boxes in
+    S. (This rather inefficiently includes S itself. There should be a
+    nice way to keep S, and just add to it.)
+    
+    S : box indices corresponding to nodes in transition map
+
+    A : adjacency graph
+
+    Returns S \cup combinatorial neighborhood of S
+    """
+    # container for (x,y) box tuples
+    thehood = set()
+    oS = S.copy()
+    # loop over nodes contained in S, keep only those that are
+    # adjacent but not already in S.
+    for idx in oS:
+        nbrs = A.neighbors( idx )
+        thehood.update( nbrs )
+    oS.update( thehood )
+    return oS
+
+def max_inv_set( P, I ):
+    """
+    Restrict the map P to the maximal isolated invariant neighborhood.
+
+    Return indices of nodes in the maximal invariant set.
+    """
+    R = nx.subgraph( P.graph, I )
+    S = algorithms.graph_mis( R )
+    return set( S )
+
+def build_ip( P, A, I ):
+    """
+    Building modified combinatorial index pairs for the combinatorial
+    isolating neighborhood I.
+
+    P : combinatorial map object
+
+    A : adjacency matrix (spacial)
+
+    I : invariant set. List or set object
+
+    Returns the index pair X,A
+    """
+    # create one box nhd about the invariant set
+    I = set( I )
+    oI = get_onebox( I, A )
+
+    print "oI - I", oI - I
+    
+    # initial X as the invariant set
+    X = I.copy()
+    
+    # map the invariant set forward, F(I)
+    print len(X)
+    for u in I:
+        X.update( P.neighbors( u ) )
+    # just keep the image that intersects the one box nhd
+    X = X & oI
+        
+    # initial exit set A
+    A = X - I
+    onebox = oI - I
+
+    print "A init", A
+    
+    # grow the exit set
+    while 1:
+        FA = set()
+        # image of exit set, eg., F(A)
+        for u in A:
+            FA.update( P.neighbors( u ) )
+        # only keep images that intersect the one box 'hood            
+        FA = FA & onebox # oI
+        if FA.intersection( I ):
+            print "eek!", len( FA.intersection( I ) )
+        # images we haven't seen in the one box 'hood
+        new_boxes = FA - A
+        # print "new boxes", len(new_boxes)
+        A.update( new_boxes )
+        if not new_boxes:
+            break
+    X = I.union(A)
+    return X,A,oI
+
+def computeYB( X, I, P ):
+    """
+    Returns F(X) and F(X)\I
+    """
+    X_ = X.copy()
+    I = set(I).copy()
+    FX = set()
+    # Find F(X)
+    for u in X:
+        FX.update( P.neighbors( u ) )
+    Y = X_.union(FX)
+    B = Y - I
+    return Y,B
+
+
+def run_homcubes( prefix,
+                  full_path='/Users/jberwald/Dropbox/Projects/entropy/lorenz/' ):
+    """
+    Sample command:
+
+    homcubes -i henon.map henon-X.dat henon-A.dat henon-Y.dat henon-B.dat -R
+
+    where prefix='henon' == full path to data.
+    """
+    space = ' '
+    prefix = full_path+prefix
+    command = space.join( ['homcubes', '-i', prefix+'.map',\
+                           prefix+'-X.dat', prefix+'-A.dat',\
+                           prefix+'-Y.dat', prefix+'-B.dat',\
+                           '-R', '-g', prefix+'.gen',\
+                           '>'+prefix+'.out'] )
+    print "homcubes called with the following command:"
+    print command
+    p=sp.call( command, shell=True )
+
+def make_index_pair( P, A, I ):
+    """
+    P : transition graph on phase space
+
+    A : adjacency graph on boxes in phase space
+
+    I : list (set) of boxes in isolated neighborhood.
+    """
+    N = grow_iso( I, A )
+    X,A = build_ip( P, Adj, I )
+    Y,B = computeYB( X, I, P )
+    return X,A,Y,B
diff --git a/src/rads/homology/index_map.py b/src/rads/homology/index_map.py
deleted file mode 100644
index 76573e7..0000000
--- a/src/rads/homology/index_map.py
+++ /dev/null
@@ -1,114 +0,0 @@
-"""
-Process cubical files A \subset B, X \subset Y, for
-
-F : (X,A) --> (Y,B)
-"""
-import numpy as np
-import subprocess as sp
-
-def index_map_call( fmap, xname, aname, yname, bname, gname=None ):
-    """
-    Calls homcubes_rads (specialized version of homcubes (R), Pawel
-    Pilarczyk), with flag -g in order to write generator regions to
-    gname file.
-
-    fmap : Text file, must be of form
-
-    ...
-    (-143,-52)  -> {(-148,-43) (-147,-43) (-146,-43) (-145,-43) (-144,-43) }
-    ...
-
-    xname : Text file, must be of form
-
-    dimension 2
-    (-145,-52)
-    (-147,-44)
-    ...
-
-    yname, aname, bname : see xname
-
-    gname : path to files in which to write cubical generator homology
-    generators of X
-
-    Returns name of temp file to which map homology is saved (i.e. the index map)
-    """
-    # Assume that *name files have same prefix, with .cub or .map ending
-    prefix = fmap[:-3]
-
-    if not gname:
-        gname = prefix + 'gen'
-    cmd = [ 'homcubes_rads', '-i', '-a',
-            fmap, xname, aname, yname, bname,
-            '-g', gname ]
-
-    out = sp.check_output( cmd, stderr=sp.STDOUT)
-
-    #return out
-    idxmap = _homout2pydict( out )    
-    return idxmap
-
-def _homout2pydict( out ):
-    """
-    Converts homcubes_rads output to a python dictionary.
-    """
-    # Homcubes still gives a little extra output, so strip it off
-    s = out.split( '\n' )[2:-1]
-    d = ''.join( s )
-    return eval( d )
-    
-def index_map_to_matrix( idxmap, level ):
-    """
-    Convert dict format to a numpy array.
-
-    idxmap : dictionary containing map on homology at each homology level.
-
-    level : dimension/homology level at which to construct the map.
-
-    Matrix is constructed as follows: For generator g_i, eg, idx[i] =
-    [(a1,j1), (a2,j2)], then fill in column i so that the (j1,i) = a1
-    and (j2,i) = a2.
-    """
-    idxmap = idxmap[ level ]
-    size = len( idxmap ) 
-    M = np.zeros( (size,size), dtype=np.int8 )
-
-    print "M SHAPE", M.shape
-
-    for gen in idxmap:
-        # each key is a single generator (preimage)
-        # homcubes numbers generators from 1..
-        gnum = gen.keys()[0] - 1 
-        imgs = gen.values()
-        # put the images in the right slot
-        for img in imgs:
-            print img
-            if len( img ) == 0:
-                continue
-            for y in img:
-                print y
-                M[ y[1]-1, gnum ] = y[0]
-    return M
-
-def save_index_map( idxmap, fname ):
-    """
-    idxmap : numpy array
-
-    fname : full path to save idxmap to.
-    """
-    np.save( fname, idxmap )
-        
-    
-
-if __name__ == "__main__":
-
-    p = '/Users/jberwald/src/chomp/examples/tmp-AwHXVh-tutorialhenon-'
-    fmap = p + 'map.dat'
-    xname = p + 'X.dat'
-    aname = p + 'A.dat'
-    yname = p + 'Y.dat'
-    bname = p + 'B.dat'
-
-    idx = index_map_call( fmap, xname, aname, yname, bname ) 
-    
-        
-    
diff --git a/src/rads/maps/henon.so.bak b/src/rads/maps/henon.so.bak
deleted file mode 100755
index 590928d..0000000
Binary files a/src/rads/maps/henon.so.bak and /dev/null differ
diff --git a/src/rads/maps/ricker.pyx b/src/rads/maps/ricker.pyx
index 41e7241..1358bda 100644
--- a/src/rads/maps/ricker.pyx
+++ b/src/rads/maps/ricker.pyx
@@ -4,7 +4,7 @@ from rads.enclosure.cymapper cimport Mapper
 cdef extern from "ricker_cpp.h":
 	cdef cppclass cRicker "RickerMapper":
 		cRicker()
-		cIPoint map_point (cIPoint &v)
+		cIPoint map_point (cIPoint &curr)
 	cRicker *new_Ricker "new RickerMapper" ()
 	void del_Ricker "delete" (cRicker *)
 
diff --git a/src/rads/maps/ricker_cpp.cpp b/src/rads/maps/ricker_cpp.cpp
index d91a014..cf7469a 100644
--- a/src/rads/maps/ricker_cpp.cpp
+++ b/src/rads/maps/ricker_cpp.cpp
@@ -1,45 +1,63 @@
 #include "ricker_cpp.h"
 
-RickerMapper::RickerMapper() : Mapper( 3, "ricker" )
+
+RickerMapper::RickerMapper() : Mapper( 2, "ricker" )
 {
-  params[r] = 5;
-  params[d] = 0.1;
+  params[r] = 5.0;
+  params[d] = 0.0;
   param_names[r] = 'r';
   param_names[d] = 'd';
 }
 
-IPoint RickerMapper::map_point(const IPoint &curr) const
+IPoint RickerMapper::map_point(const IPoint &v) const
 {
-    int row, col;
-    int d = dim();
+    int i, row, col;
+    int sysdim = dim(); 
 
     // square set of patches of size dim x dim
-    IPoint w( d * d );
-    
-    // growth phase, can just run across array
-    for ( row = 0; row < d * d; row ++ )
+    IPoint w( sysdim );
+
+    // Just a single patch
+    if ( sysdim == 1 )
       {
-	w[ row ] = params[ r ] * curr[ row ] * exp( -curr[ row ] );
+	w[ 0 ] = params[ r ] * v[ 0 ] * exp( -v[ 0 ] );
       }
 
-    // dispersal phase
-    for ( row=0; row < d; row ++ )
+    // n > 1 patches
+    else
       {
-	for ( col=0; col < d; col ++ )
+	// growth phase, can just run across array
+	for ( i = 0; i < sysdim; i ++ )
 	  {
-	    // left and right dispersal
-	    if ( col != 0 )
-	      w[ d * row + (col-1) ] = params[ d ] * curr[ d * row + col] / 4.0;
-	    if ( col != d - 1 )
-	      w[ d * row + (col+1) ] = params[ d ] * curr[ d * row + col] / 4.0;
-	    // up and down dispersal
-	    if ( row != 0 )
-	      w[ d * (row - 1) + col ] = params[ d ] * curr[ d * row + col] / 4.0;
-	    if ( row != d - 1 )
-	      w[ d * (row + 1) + col ] = params[ d ] * curr[ d * row + col] / 4.0;
-	    // Now remove the dispersed mass from the current patch
-	    w[ d * row + col ] = ( 1 - params[ d ] ) * curr[ d * row + col ];    
-	  } // end for col
-      } // end for row
+	    w[ i ] = params[ r ] * v[ i ] * exp( -v[ i ] );
+	  }	
+	// dispersal phase
+	if ( params[ d ] != 0 )
+	  {
+	    for ( row=0; row < dim(); row ++ )
+	      {
+		for ( col=0; col < dim(); col ++ )
+		  {
+		    // left and right dispersal
+		    if ( col != 0 )
+		      w[ dim() * row + (col-1) ] = params[ d ] * v[ dim() * row + col] / 4.0;
+		    
+		    if ( col != dim() - 1 )
+		      w[ dim() * row + (col+1) ] = params[ d ] * v[ dim() * row + col] / 4.0;
+		    
+		    // up and down dispersal
+		    if ( row != 0 )
+		      w[ dim() * (row - 1) + col ] = params[ d ] * v[ dim() * row + col] / 4.0;
+		    
+		    if ( row != dim() - 1 )
+		      w[ dim() * (row + 1) + col ] = params[ d ] * v[ dim() * row + col] / 4.0;
+		    
+		    // Now remove the dispersed mass from the vent patch
+		    w[ dim() * row + col ] = ( 1 - params[ d ] ) * v[ dim() * row + col ];    
+		  } // end for col
+	      } // end for row
+	  } // end if
+      } // end else
+
   return w;
 }
diff --git a/src/rads/maps/ricker_cpp.h b/src/rads/maps/ricker_cpp.h
index 6209f12..734c68a 100644
--- a/src/rads/maps/ricker_cpp.h
+++ b/src/rads/maps/ricker_cpp.h
@@ -2,8 +2,16 @@
 
 class RickerMapper : public Mapper
 {
-  enum param { r=0, d=1 };
-public:
-  RickerMapper();
-  IPoint map_point( const IPoint &curr ) const;
+  // fitness ('r') and dispersal ('d')
+    enum param { r=1, d=0 };
+
+    public:
+    RickerMapper();
+    /* RickerMapper( int fitness, int dispersal ) */
+    /*   { */
+    /* 	param[r] = fitness; */
+    /* 	param[d] = disperal; */
+    /*   } */
+
+  IPoint map_point( const IPoint &v ) const;
 };
diff --git a/src/rads/misc/gfx.py b/src/rads/misc/gfx.py
index 7e9b42e..ac729d6 100644
--- a/src/rads/misc/gfx.py
+++ b/src/rads/misc/gfx.py
@@ -7,7 +7,7 @@ import matplotlib.path as mpath
 import matplotlib.patches as mpatches
 import matplotlib.lines as mlines
 
-def show_uboxes(uboxes,S=None,col='b',ecol='k'):
+def show_uboxes(uboxes,S=None,col='b',ecol='k', fig=None):
 	if uboxes.dim != 2:
 		raise Exception("show_uboxes: dimension must be 2")
 	if S is None:
@@ -18,6 +18,34 @@ def show_uboxes(uboxes,S=None,col='b',ecol='k'):
 		art = mpatches.Rectangle(uboxes.corners[i],uboxes.width[0],uboxes.width[1])
 		patches.append(art)
 
+	if not fig:
+		fig = plt.figure()
+	ax = fig.gca()
+	ax.hold(True)
+	collection = PatchCollection(patches)
+	collection.set_facecolor(col)
+	collection.set_edgecolor(ecol)
+	ax.add_collection(collection,autolim=True)
+	ax.autoscale_view()
+	plt.show()
+	
+	return fig
+
+def show_uboxes_corners( corners, width, S=None, col='b', ecol='k' ):
+	"""
+	This version takes the corners and width arrays as arguments
+	instead.
+	"""
+	if corners.ndim != 2:
+		raise Exception("show_uboxes_corners: dimension must be 2")
+	if S is None:
+		S = range( len(corners) )
+
+	patches = []
+	for i in S:
+		art = mpatches.Rectangle( corners[i], width[0], width[1] )
+		patches.append(art)
+
 	fig = plt.figure()
 	ax = fig.gca()
 	ax.hold(True)
diff --git a/src/rads/misc/utils.py b/src/rads/misc/utils.py
index 39cee90..3578182 100644
--- a/src/rads/misc/utils.py
+++ b/src/rads/misc/utils.py
@@ -4,6 +4,8 @@ utils.py
 Author: Jesse Berwald
 
 Opened: Feb. 15, 2012
+
+A wrapper for various utility functions. Meant to be subclassed.
 """
 import networkx as nx
 import numpy as np
@@ -151,7 +153,21 @@ def index_map_to_region_map( hom_mat, reg2gen, shift=0 ):
                     G.add_edge( k, Rinv[glist][0] )
     # return the graph so that we have access to the nodes labels that
     # correspond directly to regions with generators.
-    return G  
+    return G
+
+def make_node_hash( nbunch ):
+    """
+    Create a mapping from the boxes --> indices listed in the nodes of
+    the directed graph.
+    """
+    idx = range( len( nbunch ) )
+    d = dict()
+    #d.fromkeys( idx )
+    #d.fromkeys( nbunch )
+    for i in idx:
+        d[i] = nbunch[i]
+    return d
+    
 
 def invert_dictionary( d ):
     inv_map = {}
@@ -164,48 +180,25 @@ def invert_dictionary( d ):
             inv_map[v] = inv_map.get(v, [])
             inv_map[v].append(k)
     return inv_map
-    
-# =======
-# from scipy.io import loadmat
-
-# class Utils( object ):
-
-#     def convert_matlab_gens( self, genfile ):
-#         """
-#         Convert a Matlab (R) cell array to a dictionary. 
-#         """
-#         try:
-#             from scipy.io import loadmat
-#         except ImportError( "scipy.io.loadmat not found. Is scipy installed?" ):
-#             raise
-#         cell_array = loadmat( genfile )
-#         return self.cell2dict( cell_array )
-    
-#     def cell2dict( self, ca ):
-#         """
-#         Parameters:
-#         -----------
-
-#         ca : cell array from Matlab, loaded using scipy.io.loadmat()
-
-#         Returns a Python dictionary
-#         """
-#         keys = ca.keys()
-#         # there should only be one name for the cell array, the other keys
-#         # should be metadata (eg., '__globals__', etc.)
-#         name = [ k for k in keys if not k.startswith('__') ][0]
-#         gens = ca[name][0]
-#         gdict = {}
-#         for r,gen in enumerate( gens ):
-#             # Don't record regions with no generators
-#             if gen.shape == (0,0):
-#                 #gdict[r] = None
-#                 continue
-#             else:
-#                 # shift to align with 0-index
-#                 g = gen[0] -1
-#                 if len( g )==0:
-#                     continue
-#                 gdict[r] = set( g )
-#         return gdict
-# >>>>>>> adding-capd
+
+def array2chomp( arr, savename ):
+    """
+    Convert an array to chomp format, ( , , ). Write the resulting
+    column of numbers to disk. Formatted for use with chomp-rutgers
+    (see https://code.google.com/p/chomp-rutgers/)
+    """
+    rows = map( lambda x: str(x)+'\n', map( tuple, iter( arr ) ) ) 
+    with open( savename, 'w' ) as fh:
+        fh.writelines( rows )
+
+
+def to_sparse( G ):
+    """
+    DiGraph to scipy sparse matrix.
+    """
+    try:
+        return nx.to_scipy_sparse_matrix( G.graph, dtype=int, format='csr' )
+    # in case one sends in G.graph instead.
+    except AttributeError:
+        return nx.to_scipy_sparse_matrix( G, dtype=int, format='csr' )        
+
diff --git a/src/rads/symbolics/rigorous_entropy.py b/src/rads/symbolics/rigorous_entropy.py
index 6a1ddf1..b374a36 100644
--- a/src/rads/symbolics/rigorous_entropy.py
+++ b/src/rads/symbolics/rigorous_entropy.py
@@ -18,10 +18,13 @@ import argparse
 
 class RigorousEntropy( object ):
     """
-    Entry point for consfor working with multiple IMP's if/when there are multiple
+    Entry point for working with multiple IMP's if/when there are multiple
     disjoint strongly connected components in the map among regions in
     phase space.
 
+    Data format: index_map is a matrix representation of a directed
+    graph on generators of homology at level *.
+
     Example:
 
     index_map = numpy.matrix( [[0,0,1,1,0],
@@ -56,7 +59,7 @@ class RigorousEntropy( object ):
         map f : X --> X on phase space.
         
         generator_map : dictionary -- Map that associates regions in
-        phase space to generators. Indices in index_map must align with
+        phase to generators. Indices in index_map must align with
         """
         self.index_map = index_map
         self.region2gen = reg2gen
diff --git a/src/rads/test/bench_tree.py b/src/rads/test/bench_tree.py
deleted file mode 100755
index f958f6a..0000000
--- a/src/rads/test/bench_tree.py
+++ /dev/null
@@ -1,176 +0,0 @@
-#!/usr/bin/python
-
-import sys
-import numpy as np
-import numpy.random
-import matplotlib.pylab as plt
-from rads import UBoxSet,Tree,gfx
-import timeit
-
-def time_stuff(test_str,import_str,num_trials):
-	return timeit.Timer(test_str, import_str).timeit(number=num_trials)/num_trials
-
-
-dims = range(1,9)
-xbounds = {
-	1:(1,10),
- 	2:(1,8),
- 	3:(1,4),
- 	4:(1,3),
- 	5:(1,3),
- 	6:(1,3),
- 	7:(1,2),
-	8:(1,2),
-		}
-bounds = {
- 	1:(1,20),
-  	2:(1,12),
-  	3:(1,8),
-  	4:(1,6),
-  	5:(1,5),
-  	6:(1,4),
-  	7:(1,3),
- 	8:(1,3),
-	}
-
-results = {}
-funcs = ['insert','insert_box','search','search_box']
-trials_list = [1,1,1000,50]
-trials = {}
-
-def get_data(test):
-	np.random.seed(10)					# for consistency
-	d = {'insert':np.random.rand(10000,test['dim']),
-		 'insert_box':np.random.rand(1000,2,test['dim']),
-		 'search':np.random.rand(50,test['dim']),
-		 'search_box':np.random.rand(50,2,test['dim']),
-		 }
-	d['insert_box'][:,1] /= 2
-	d['search_box'][:,1] /= 2
-	return d
-			
-def get_tree(test):
-	bbox = np.tile([[0.0],[1]],test['dim'])		# unit cube
-	tree = Tree(bbox,depth=test['depth'],full=False)
-	return tree
-
-def bench(test,data):
-	print 'dimension %(dim)i at depth %(depth)i' % test;
-	test['results'] = {}
-	for f in funcs:
-		r = []
-		for i in range(len(data[f])):
-			t = time_stuff('tree.%s(data[\'%s\'][%i])' % (f,f,i),
-						   'from __main__ import tree, data',
-						   trials[f]) / trials[f]
-			r.append(t)
-		print '%12s: %6.8f' % (f,1000*np.mean(r))
-		test['results'][f] = r
-		results[f][test['dim']][test['depth']] = np.mean(r)
-
-def save_data(test,data):
-	for d in data:
-		if '_box' in d:
-			s = data[d].shape
-			data[d] = data[d].reshape(s[0]*s[1],s[2])
-		# print 'bench_%s_dim_%i_depth_%i.txt' % (d,test['dim'],test['depth'])
-		np.savetxt('bench_%s_dim_%i_depth_%i.txt' % (d,test['dim'],test['depth']),
-				   data[d])
-
-import pickle
-import time
-import scipy.io
-
-data = None
-tree = None
-print __name__
-if __name__ == "__main__":
-	tests = []
-	for dim in bounds:
-		tests += [{'dim':dim, 'depth':d}
-				  for d in
-				  range(bounds[dim][0],bounds[dim][1]+1)]
-	for t in range(len(trials_list)):
-		trials[funcs[t]] = trials_list[t]
-	for f in funcs:
-		results[f] = {}
-		for dim in bounds:
-			results[f][dim] = np.zeros(bounds[dim][1]+1)
-	print "running tests..."
-	for test in tests:
-		if tree:
-			del data
-			del tree
-		data = get_data(test)
-		tree = get_tree(test)
-		bench(test,data)
-		save_data(test,data)
-	datestr = time.strftime("%Y-%m-%d-%H-%M-%S")
-	pickle.dump(results,file('bench-results-%s.pickle' % (datestr),'w'))
-	pickle.dump(results,file('bench-results.pickle','w'))
-else:
-	results = pickle.load(file('bench-results.pickle','r'))
-	mat = scipy.io.loadmat('bench-tree.mat')['R'][0]
-	# matlab indices are: [dim,depth,func]
-
-
-	fgcolor = np.array([20,50,100])/255.
-	bgcolor = 0.9 + 0.1*fgcolor
-	plt.rcdefaults()
-	plt.rcParams['figure.subplot.right']='0.9'
-	plt.rcParams['figure.subplot.left']='0.2'
-	plt.rcParams['figure.subplot.top']='0.8'
-	plt.rcParams['ytick.major.pad']='10'
-	plt.rcParams['ytick.color']=fgcolor
-	plt.rcParams['xtick.color']=fgcolor
-	plt.rcParams['ytick.major.size']=4
-	plt.rcParams['xtick.major.size']=4
-	plt.rc('lines', linewidth=2)
-	plt.rc('text', color=fgcolor)
-	plt.rc('axes', linewidth=2, facecolor=bgcolor, edgecolor=fgcolor, labelcolor=fgcolor)
-	plt.show()
-
-	plotfuncs = [1,3]
-	labels = ['Insert','Search']
-	colors = [np.array([120,20,10])/255.,np.array([98,158,31])/255.]
-
-	plt.close('all')
-	fig = plt.figure(frameon=False)
-#	plt.title('depth 3')
-	depth = 3
-	for pf in range(len(plotfuncs)):
-		f = plotfuncs[pf]
-		x = dims
-		y = [-np.log(results[funcs[f]][dims[i]][depth-1] / mat[i][depth-1,f]) for i in range(len(dims))]
-		plt.plot(x,y,color=colors[pf])
-		plt.xlabel('dimension',size='large')
-		plt.ylabel('log(speedup) = log(matlab/python)',size='large')
-	plt.ylim(-0.5,6.5)
-	lg = plt.legend(labels,loc='upper left')
-	lg.get_frame().set_fill(False)
-	plt.savefig('/home/raf/Dropbox/cs262a/report/trees.pdf',bbox_inches='tight')
-
-	screwup
-
-
-# 		for f in range(len(funcs)):
-# 			fig = plt.figure()
-# 			plt.title(funcs[f])
-# 			for d in range(len(dims)):
-# 				x = np.arange(bounds[dims[d]][0],bounds[dims[d]][1]+1)
-# 				y = results[funcs[f]][dims[d]][bounds[dims[d]][0]:] / mat[d][:,f]
-# 				plt.plot(x,y)
-# 			plt.legend(dims)
-# 			plt.xlabel('depth')
-# 			plt.ylabel('py / mat')
-
-# 	fig = plt.figure()
-# #	plt.title('dimension 3')
-# 	d = 2    # dimension 3
-# 	for f in range(len(funcs)):
-# 		x = np.arange(bounds[dims[d]][0],bounds[dims[d]][1]+1)
-# 		y = results[funcs[f]][dims[d]][bounds[dims[d]][0]:] / mat[d][:,f]
-# 		plt.plot(x,y)
-# 		plt.xlabel('depth')
-# 		plt.ylabel('Python / Matlab')
-# 	plt.legend(funcs)
diff --git a/src/rads/test/debug_tree.py b/src/rads/test/debug_tree.py
deleted file mode 100644
index 96f895d..0000000
--- a/src/rads/test/debug_tree.py
+++ /dev/null
@@ -1,45 +0,0 @@
-#!/usr/bin/python
-
-import sys
-sys.path.append("cython/build/")
-
-from rads import *
-from rads import gfx
-import numpy as np
-import numpy.random as random
-import matplotlib.pylab as plt
-
-box = np.array([[0.0,0],[8,8]])
-tree = Tree(box)
-tree.insert(np.array([1,1]))
-tree.subdivide()
-# tree.insert(np.array([1,1]))
-# tree.insert(np.array([5,1]))
-# tree.insert(np.array([1,5]))
-# tree.insert(np.array([5,5]))
-
-boxes = tree.boxes()
-print tree
-print boxes
-s = tree.search(np.array([[1,1],[1,4]]))
-print "tree.search(np.array([[1,1],[1,4]])) =", s
-print "should be [0,2]"
-s = tree.search(np.array([[1,1],[4,1]]))
-print "tree.search(np.array([[1,1],[4,1]])) =", s
-print "should be [0,1]"
-
-for i in range(0):
-	v = random.rand(2)*4 - 1
-	w = random.rand(2)*3
-	box = np.array([v,w])
-	s = tree.search(box)
-	print v,w,':',s
-	gfx.show_uboxes(boxes)
-	gfx.show_uboxes(boxes, S=s, col='r')
-	gfx.show_box(box,col='g')
-	plt.show()
-	plt.draw()
-	if raw_input("Press enter when done!")==0:
-		break
-	plt.close()
-
diff --git a/src/rads/test/test_cytree.py b/src/rads/test/test_cytree.py
index 739e51e..14530b9 100644
--- a/src/rads/test/test_cytree.py
+++ b/src/rads/test/test_cytree.py
@@ -3,18 +3,24 @@
 import sys
 sys.path.append("cython/build/")
 
-from rads.enclosure import UBoxSet # cyboxset
-from rads.enclosure import Tree # cytree
+#import cyboxset
+from rads.enclosure import UBoxSet
+#import cytree
+from rads.enclosure import Tree
+from rads.misc import gfx
 import numpy as np
 
+
 box = np.array([[0.0,0],[8,8]])
 t = Tree(box)
 t.subdivide()
 t.subdivide()
 t.subdivide()
-print "insert", t.insert(box/8 + 0.5)
-print "insert", t.insert(np.array([[4,4],[1,1]]))
-print "insert [3,3]", t.insert(np.array([3,3]))
-print "search [3,3]", t.search(np.array([3,3]))
+print t.insert(box/8 + 0.5)
+print t.insert(np.array([[4,4],[1,1]]))
+print t.insert(np.array([3,3]))
+print t.search(np.array([3,3]))
 ubs = t.boxes()
 print ubs
+
+gfx.show_uboxes(ubs, col='c', ecol='b')
diff --git a/src/rads/test/test_henon.py b/src/rads/test/test_henon.py
index 4408570..8b74985 100644
--- a/src/rads/test/test_henon.py
+++ b/src/rads/test/test_henon.py
@@ -2,11 +2,11 @@
 
 import numpy as np
 from rads.enclosure import CombEnc,Tree
-from rads.maps.henon import HenonMapper
+from rads.maps import HenonMapper
 from rads.graphs.algorithms import graph_mis
 from rads.misc import gfx
 
-depth = 5
+depth = 8
 
 # main bounding box
 box = np.array([[-2.0,-2],[4,4]])
@@ -14,6 +14,12 @@ box = np.array([[-2.0,-2],[4,4]])
 # our tree, mapper, enclosure
 tree = Tree(box,full=True)
 m = HenonMapper()
+
+p = m.get_params()
+p['a'][:] = 1.2
+p['b'][:] = 0.2
+m.set_params( p )
+
 ce = CombEnc(tree,m)
 
 for d in range(depth):
@@ -23,9 +29,13 @@ for d in range(depth):
 	ce.update()
 	print 'enclosure updated'
 	I = graph_mis(ce.mvm)
-	print 'len(I) = ', len(I[0]) # fix the extra stuff returned by graph_mis
+	print 'len(I) = ', len(I)
 	# now remove all boxes not in I (the maximal invariant set)
-	ce.tree.remove(list(set(range(ce.tree.size))-set(I[0])))
+	nodes = set(range(ce.tree.size))
+	ce.tree.remove(list(nodes-set(I)))
+
+# remove nodes not in I
+ce.mvm.remove_nodes_from( list(nodes-set(I)) )
 
 # now display the tree!
 boxes = ce.tree.boxes()
diff --git a/src/rads/test/test_henon2.py b/src/rads/test/test_henon2.py
new file mode 100644
index 0000000..723cd0b
--- /dev/null
+++ b/src/rads/test/test_henon2.py
@@ -0,0 +1,102 @@
+#!/usr/bin/python
+
+import numpy as np
+from rads.enclosure import CombEnc,Tree
+from rads.maps import HenonMapper
+from rads.graphs.algorithms import graph_mis
+from rads.misc import gfx
+from rads.homology import homology
+from rads.graphs import DiGraph
+import sys
+from itertools import combinations
+
+if len( sys.argv ) == 1:
+	depth = 7
+else:
+	depth = int( sys.argv[1] )
+
+
+max_cycle = 2
+
+# main bounding box
+box = np.array([[-2.0,-2],[4,4]])
+
+# our tree, mapper, enclosure
+tree = Tree(box,full=True)
+m = HenonMapper()
+
+p = m.get_params()
+p['a'][:] = 1.4
+p['b'][:] = 0.3
+m.set_params( p )
+
+ce = CombEnc(tree,m)
+
+for d in range(depth):
+	print 'at depth', d
+	ce.tree.subdivide()
+	print 'subdivided:', ce.tree.size, 'boxes'
+	ce.update()
+	print 'enclosure updated'
+	I,s,r = graph_mis(ce.mvm, return_rsccs=True)
+	
+	print 'len(I) = ', len(I)
+	# now remove all boxes not in I (the maximal invariant set)
+	nodes = set(range(ce.tree.size))
+	#ce.tree.remove(list(nodes-set(I)))
+	print ""
+
+# remove nodes not in I
+#ce.mvm.remove_nodes_from( list(nodes-set(I)) )
+
+# If len(r)>1, then there must be two SCC's. For now we ignore the
+# fact that SCC's of size==1 will have zero entropy and just create a
+# mapping between r and s:
+components = dict().fromkeys( r )
+for u in components:
+	# subgraph of the MVM containing nodes from the SCC
+	G = ce.mvm.subgraph( s[u] )
+	# H = DiGraph()
+	# H.graph = G
+	components[u] = G
+
+
+# now display the tree!
+boxes = ce.tree.boxes()
+gfx.show_uboxes(boxes, col='c', ecol='b')
+
+
+# for each component find some cycles and connect them
+#cycles = dict().fromkeys( components.keys() )
+for u,subH in components.iteritems():
+	#C = homology.get_cycles( ce.mvm, 4 )
+
+	# Don't bother with single node SCC's
+	if len( subH ) == 1:
+		continue
+	cycles = homology.get_cycles( subH, max_cycle )
+	cycle_combs = combinations( cycles, 2 )
+	
+	# Here we need to explore various combinations of cycle
+	# lengths and nodes to connect between the sets
+	cycles_conns = set()
+	for comb in cycle_combs:
+		c = homology.connect_cycles( cycles[comb[0]],
+					     cycles[comb[1]],
+					     subH )
+		cycles_conns.update( c )
+
+	for c in cycles.values():
+		cycles_conns.update( c ) 
+
+	# grow isolated invariant set
+	N = homology.grow_iso( cycles_conns, ce.adj, ce.mvm )
+
+	# # build index pair
+	X, A,oI = homology.build_ip( ce.mvm, ce.adj , N )
+
+	# # construct Y and B as well
+	Y, B = homology.computeYB( X, N, ce.mvm )
+
+# path = '/data/entropy/sandbox/'
+# homology.run_homcubes( 'test_henon', full_path=path )
diff --git a/src/rads/test/test_ricker.py b/src/rads/test/test_ricker.py
index c57fe9d..7ae88f4 100644
--- a/src/rads/test/test_ricker.py
+++ b/src/rads/test/test_ricker.py
@@ -2,18 +2,33 @@
 
 import numpy as np
 from rads.enclosure import CombEnc,Tree
-from rads.maps.ricker import RickerMapper
+from rads.maps.ricker import RickerMapper # for some reason must have .ricker (??)
 from rads.graphs.algorithms import graph_mis
-from rads.misc import gfx
+from rads.misc import gfx, utils
 
-depth = 5
+depth = 6
+rval = 12
 
-# main bounding box
-box = np.array([[0.0,0],[4,4]])
+# main root box -- make sure that dimension align with that in
+# ricker_cpp.cpp. Eg. if Mapper( dim, 'ricker' ), then system
+# dimension is dim => if dim=2, just two regions. But for larger
+# simulations with dispersal > 0, assumption is that the region is
+# square, so dim must be a square.
+#box = np.array([[0.],[4]])
+box = np.array( [[0.1,0.1],[6,6]] )
+
+print "Initial bounding box"
+print box
 
 # our tree, mapper, enclosure
 tree = Tree(box,full=True)
 m = RickerMapper()
+
+# change params -- leave d alone for now
+p = m.get_params()
+p['r'][:] = rval
+m.set_params( p )
+
 ce = CombEnc(tree,m)
 
 for d in range(depth):
@@ -24,11 +39,34 @@ for d in range(depth):
 	print 'enclosure updated'
 	I = graph_mis(ce.mvm)
 	print 'len(I) = ', len(I) # fix the extra stuff returned by graph_mis
+
 	# now remove all boxes not in I (the maximal invariant set)
-	
-	ce.tree.remove(list(set(range(ce.tree.size))-set(I[0])))
+	nodes = set(range(ce.tree.size))
+	ce.tree.remove(list(nodes-set(I)))
 
-# now display the tree!
+# remove nodes not in I from the mvm
+ce.mvm.remove_nodes_from( list(nodes-set(I)) )
 boxes = ce.tree.boxes()
-gfx.show_uboxes(boxes, col='c', ecol='b')
 
+# now display the tree!
+if box.shape[1] == 2:
+	gfx.show_uboxes(boxes, col='c', ecol='b')
+
+P = ce.mvm.to_numpy_matrix()
+p2 = P*P
+p2diag = p2.diagonal()
+w = np.where( p2diag != 0 )[1] 
+fp = boxes.corners[ w ][0]
+fig = gfx.show_uboxes_corners( fp, boxes.width )
+fig.savefig( 'ricker_per2_r'+str( int(rval) ) + '_depth' + str( depth ) + '.png' )
+
+
+utils.array2chomp( fp,
+		   'ricker_per2_r'+str( int(rval) ) + '_depth' + str( depth ) + '.cub' )
+
+
+# check homology of the 
+# utils.array2chomp( boxes.corners,
+# 		   'ricker_r'+str( int(rval) ) + '_depth' + str( depth ) + '.cub' )
+		   
+		
diff --git a/src/rads/test/test_tree.py b/src/rads/test/test_tree.py
index ce8d24e..7c6d50f 100644
--- a/src/rads/test/test_tree.py
+++ b/src/rads/test/test_tree.py
@@ -54,7 +54,9 @@ def rand_test_int(event=None):
 	box = np.array([v,w])
 	test_one_box(box,tree,True,rand_test)
 
-rand_test()
+# rand_test()
+rand_test_int()
+
 
 # for i in range(500):
 # #	print "rand_test"
diff --git a/src/symbolics/__init__.py b/src/symbolics/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/src/symbolics/index_map.py b/src/symbolics/index_map.py
new file mode 100644
index 0000000..febaae7
--- /dev/null
+++ b/src/symbolics/index_map.py
@@ -0,0 +1,123 @@
+"""
+index_map.py
+
+Author: Jesse Berwald
+
+Opened: Feb. 23, 2012
+
+High-level interface to create and modify an index map on
+homology.
+
+Usage:
+------
+
+   In [1]: import index_map as im
+   Out [1]: IM = im.IndexMap( data='my_index_map.npy' )
+
+   In [2]: IM.shift_equivalence()
+
+   In [3]: IM.....
+
+   In [4]: IM.compute_entropy()
+"""
+from graphs import digraph
+import convert
+import index_processor as IP
+
+class IndexMap( IP.IndexMapProcessor ):
+    """
+    Base class for graphical index map computations.
+
+    Inherits from IP.IndexMapProcessor.
+
+    Usage:
+    ------
+    
+    Construction of an IndexMap representing the map on homology for a
+    kixed k
+
+         f: H_{k}(P,P') -> H_{k}(P,P')
+
+    for the index pair (P,P'):
+
+    Two objects are necessary, a directed graph (equivalently an
+    adjacency matrix) and a representation of generators by disjoint
+    regions within the index pair.
+
+    Initialization:
+    ---------------
+
+    1) One can create an empty IndexMap. Later, populate it with nodes
+    (generators) and edges (maps between generators). A map from
+    disjoint regions in the invariant set to the generators within
+    those regions must also be provided.
+
+    2) Using the kwarg 'indexmap', the user can provide an adjacency
+    matrix defining the map on generators the graph structure.
+
+    2') The kwarg 'genmap' provides a dictionary keyed by region that
+    maps region N_i to the generators on that region. 
+    
+    args:
+    ----
+
+    indexmap : adjacency matrix (array or path to file)
+               Represents map on homology.
+
+    genmap : map from disjoint regions in index pair to the generators
+             that live on those regions.
+
+    """
+    def __init__( self, **kwargs ):
+        # Inherit from IndexMapProcessor: functions for reducing the
+        # number of symbols, verifying cycles, etc.
+        IP.IndexMapProcessor.__init__( self )
+        fargs = {'debug': False,
+                 'indexmap': None,
+                 'genmat': None
+                 }
+        fargs.update( kwargs )
+
+        self.debug = fargs['debug']
+
+        # load the index map graph and initialize the graph
+        if fargs['indexmap']:
+            self.adj_matrix = convert.load_index_map( fargs['indexmap'] )
+            self.graph = digraph.DiGraph( data=self.adj_matrix )
+
+    def shift_equivalent_map( self ):
+        """
+        Graphical representation of the shift equivalence proved in
+        Theorem 3.1 and Lemmas 3.2-3.4.
+
+        The required sets of nodes V1, V2, and V3 are computed as
+        follows:
+            Given G = (V,E), with V = {V1,V2,V3},
+
+            1. Find strongly connected components (scc) of G. Labeled
+            by nodes V2.
+
+            2. Perform a forward depth-first search; then perform
+            backward depth-first search by reversing the orientation
+            on the edges. This locates generators that are not
+            connected to cycles. Labeled by nodes V1 \cup V3.
+
+            3. Trim self.graph to include only those nodes in
+                     V2 = V\(V1 \cup V3)
+
+            4. The nodes in V1 \cup V3 are stored in the attrribute
+            'non_mis_nodes'.
+
+        args:
+        -----
+
+        copy : store the shift equivalent map in a new graph
+        """
+        
+
+    def verify_cycles( self, max_length=10 ):
+        """
+        """
+        pass
+
+
